{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ea1c4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.i2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "        self.h2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "\n",
    "    def forward(self, x, prev_c, prev_h):\n",
    "        gates = self.i2h(x) + self.h2h(prev_h)\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        ingate = torch.sigmoid(ingate)\n",
    "        forgetgate = torch.sigmoid(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = torch.sigmoid(outgate)\n",
    "        cy = (forgetgate * prev_c) + (ingate * cellgate)\n",
    "        hy = outgate * torch.tanh(cy)  # n_b x hidden_dim\n",
    "        return cy, hy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, opt, input_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        self.lstm = LSTM(self.opt)\n",
    "    def forward(self, input_src, prev_c, prev_h):\n",
    "        src_emb = self.embedding(input_src) # batch_size x src_length x emb_size\n",
    "        prev_cy, prev_hy = self.lstm(src_emb, prev_c, prev_h)\n",
    "        return prev_cy, prev_hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, opt, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
    "        self.lstm = LSTM(self.opt)\n",
    "        self.linear = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, prev_c, prev_h):\n",
    "        output = self.embedding(input)\n",
    "        next_c, next_h = self.lstm(output, prev_c, prev_h)\n",
    "        h2y = self.linear(next_h)\n",
    "        pred = self.softmax(h2y)\n",
    "        return pred, next_c, next_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.rnn_size = 50\n",
    "        self.dropout = False\n",
    "        self.init_weight = 0.08\n",
    "        self.decay_rate = 0.985\n",
    "        self.learning_rate = 0.01\n",
    "        \n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fh):\n",
    "    for line in fh:\n",
    "        sentence, lf = line.strip().split(\"\\t\")\n",
    "        sentence = sentence.split()\n",
    "        lf = lf.split()\n",
    "        yield sentence, lf\n",
    "\n",
    "def read_vocab(filename):\n",
    "    t2i = {\"<s>\": 0, \"</s>\":1, \"UNK\": 2}\n",
    "    with open(filename) as target:\n",
    "        for line in target:\n",
    "            token = line.strip().split()[0]\n",
    "            if token not in t2i:\n",
    "                t2i[token] = len(t2i)\n",
    "    return t2i\n",
    "\n",
    "def is_equal(gold, predictions):\n",
    "    total_correct = 0.0\n",
    "    if len(gold) == len(predictions):\n",
    "        equal = True\n",
    "        for g, p in zip(gold, predictions):\n",
    "            if g != p:\n",
    "                equal = False\n",
    "        return equal\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprare_data(file_name):\n",
    "    shuffledData = None\n",
    "    with open(TRAIN_FILE, 'r') as train:\n",
    "        shuffledData = list(read_data(train))\n",
    "        random.shuffle(shuffledData)\n",
    "    sentence_index_tensors = []\n",
    "    form_index_tensors = []\n",
    "    for sentence in shuffledData:\n",
    "        text_tensor = torch.zeros((1, len(sentence[0]) + 2), dtype=torch.long)\n",
    "        text_tensor[0][0] = w2i[\"<s>\"]\n",
    "        for idx, word in enumerate(sentence[0]):\n",
    "            word_index = w2i[word] if word in w2i else w2i[\"UNK\"]\n",
    "            text_tensor[0][idx+1] = word_index\n",
    "        text_tensor[0][-1] = w2i[\"</s>\"]\n",
    "        sentence_index_tensors.append(text_tensor)\n",
    "        form_tensor = torch.zeros((1, len(sentence[1]) + 2), dtype=torch.long)\n",
    "        form_tensor[0][0] = lf2i[\"<s>\"]\n",
    "        for idx, form in enumerate(sentence[1]):\n",
    "            form_index = lf2i[form] if form in lf2i else lf2i[\"UNK\"]\n",
    "            form_tensor[0][idx+1] = form_index\n",
    "        form_tensor[0][-1] = lf2i[\"</s>\"]\n",
    "        form_index_tensors.append(form_tensor)\n",
    "    return shuffledData, sentence_index_tensors, form_index_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, encoder_optimizer, decoder_optimizer, encoder, decoder, s1, f1):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "\n",
    "    #for dec_in in f1:\n",
    "    loss = 0\n",
    "    for i in range(f1.size(1)-1):\n",
    "        pred, c, h = decoder(f1[:, i], c, h)\n",
    "        loss += criterion(pred, f1[:, i+1])\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(opt, s1, lf2i, encoder, decoder):\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "\n",
    "    prev = torch.tensor([lf2i['<s>']], dtype=torch.long)\n",
    "    predicted_form = []\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        pred, c, h = decoder(prev, c, h)\n",
    "        form_id = pred.argmax().item()\n",
    "        prev = torch.tensor([form_id], dtype=torch.long)\n",
    "        if form_id == lf2i[\"</s>\"] or counter >= 100:\n",
    "            break\n",
    "        predicted_form.append(form_id)\n",
    "    return predicted_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_FILE = \"data/test.txt\"\n",
    "TRAIN_FILE = \"data/train.txt\"\n",
    "WHOLE_FILE = \"data/whole.txt\"\n",
    "F_VOCAB_FILE = \"data/vocab.f.txt\"\n",
    "Q_VOCAB_FILE = \"data/vocab.q.txt\"\n",
    "\n",
    "w2i = read_vocab(Q_VOCAB_FILE)\n",
    "lf2i = read_vocab(F_VOCAB_FILE)\n",
    "i2lf = {lf2i[i] : i for i in lf2i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(opt, len(w2i))\n",
    "decoder = DecoderRNN(opt, len(lf2i))\n",
    "\n",
    "for name, param in encoder.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "for name, param in decoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "\n",
    "optim_state = {\"learningRate\" : opt.learning_rate, \"alpha\" :  opt.decay_rate}\n",
    "encoder_optimizer = optim.RMSprop(encoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "decoder_optimizer = optim.RMSprop(decoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    train_data, sentence_index_tensors_train, form_index_tensors_train = preprare_data(TRAIN_FILE)\n",
    "    test_data, sentence_index_tensors_test, form_index_tensors_test = preprare_data(TEST_FILE)\n",
    "\n",
    "    EPOCH_NUM = 30\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        print(\"---Epoch {}---\\n\".format(epoch+1))\n",
    "        print(\"Training...\")\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        loss = 0\n",
    "        for index, (sentence, form) in enumerate(zip(sentence_index_tensors_train, form_index_tensors_train)):\n",
    "            loss += train(opt, encoder_optimizer, decoder_optimizer, encoder, decoder, sentence, form)\n",
    "            if index % 50 == 0:\n",
    "                print(\"Index {} Loss {}\".format(index, loss/(index+1)))\n",
    "                \n",
    "        print(\"Predicting..\")\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        correct = 0.0\n",
    "        for index, (sentence, form) in enumerate(zip(sentence_index_tensors_test, form_index_tensors_test)):\n",
    "            prediction = predict(opt, sentence, lf2i, encoder, decoder)\n",
    "            prediction = [i2lf[p] for p in prediction]\n",
    "            #print(test_data[index][1])\n",
    "            #print(prediction)\n",
    "            same = True\n",
    "            for g, p in zip(test_data[index][1], prediction):\n",
    "                if g != p:\n",
    "                    same = False\n",
    "            if same:\n",
    "                correct += 1\n",
    "                #print(\"Correct match \", prediction)\n",
    "        accuracy = 100*(correct/len(test_data))\n",
    "        print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.44290542602539\n",
      "Index 50 Loss 6.246608734130859\n",
      "Index 100 Loss 6.586971282958984\n",
      "Index 150 Loss 7.199075698852539\n",
      "Index 200 Loss 6.89987850189209\n",
      "Index 250 Loss 6.614319324493408\n",
      "Index 300 Loss 6.813511371612549\n",
      "Index 350 Loss 6.847531795501709\n",
      "Index 400 Loss 6.925313472747803\n",
      "Index 450 Loss 6.873419761657715\n",
      "Index 500 Loss 6.678918838500977\n",
      "Index 550 Loss 6.796503067016602\n",
      "Predicting..\n",
      "Accuracy:  24.5\n",
      "---Epoch 2---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 11.227838516235352\n",
      "Index 50 Loss 6.821059226989746\n",
      "Index 100 Loss 6.8647332191467285\n",
      "Index 150 Loss 7.330733776092529\n",
      "Index 200 Loss 6.865607738494873\n",
      "Index 250 Loss 6.5261993408203125\n",
      "Index 300 Loss 6.574824333190918\n",
      "Index 350 Loss 6.552728176116943\n",
      "Index 400 Loss 6.615856647491455\n",
      "Index 450 Loss 6.501195430755615\n",
      "Index 500 Loss 6.291408538818359\n",
      "Index 550 Loss 6.357675075531006\n",
      "Predicting..\n",
      "Accuracy:  25.333333333333336\n",
      "---Epoch 3---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.560908317565918\n",
      "Index 50 Loss 6.069122314453125\n",
      "Index 100 Loss 6.236077785491943\n",
      "Index 150 Loss 6.583311557769775\n",
      "Index 200 Loss 6.197269439697266\n",
      "Index 250 Loss 5.910892009735107\n",
      "Index 300 Loss 6.044905662536621\n",
      "Index 350 Loss 6.053366661071777\n",
      "Index 400 Loss 6.129753589630127\n",
      "Index 450 Loss 5.994085788726807\n",
      "Index 500 Loss 5.788723468780518\n",
      "Index 550 Loss 5.83878231048584\n",
      "Predicting..\n",
      "Accuracy:  28.166666666666668\n",
      "---Epoch 4---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 13.737298011779785\n",
      "Index 50 Loss 5.811695575714111\n",
      "Index 100 Loss 5.9984917640686035\n",
      "Index 150 Loss 6.547032833099365\n",
      "Index 200 Loss 6.220925807952881\n",
      "Index 250 Loss 5.8955535888671875\n",
      "Index 300 Loss 6.025707721710205\n",
      "Index 350 Loss 6.027938365936279\n",
      "Index 400 Loss 6.049343109130859\n",
      "Index 450 Loss 5.886782169342041\n",
      "Index 500 Loss 5.658304214477539\n",
      "Index 550 Loss 5.7315521240234375\n",
      "Predicting..\n",
      "Accuracy:  20.166666666666664\n",
      "---Epoch 5---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 14.95974349975586\n",
      "Index 50 Loss 6.041959762573242\n",
      "Index 100 Loss 6.1041975021362305\n",
      "Index 150 Loss 6.261146545410156\n",
      "Index 200 Loss 5.8658576011657715\n",
      "Index 250 Loss 5.578784465789795\n",
      "Index 300 Loss 5.680609226226807\n",
      "Index 350 Loss 5.660660743713379\n",
      "Index 400 Loss 5.705735206604004\n",
      "Index 450 Loss 5.5746989250183105\n",
      "Index 500 Loss 5.380251884460449\n",
      "Index 550 Loss 5.472411155700684\n",
      "Predicting..\n",
      "Accuracy:  25.833333333333336\n",
      "---Epoch 6---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 11.103633880615234\n",
      "Index 50 Loss 5.370691776275635\n",
      "Index 100 Loss 5.68294095993042\n",
      "Index 150 Loss 5.916088104248047\n",
      "Index 200 Loss 5.5102763175964355\n",
      "Index 250 Loss 5.27432918548584\n",
      "Index 300 Loss 5.372565269470215\n",
      "Index 350 Loss 5.37245512008667\n",
      "Index 400 Loss 5.435509204864502\n",
      "Index 450 Loss 5.3117170333862305\n",
      "Index 500 Loss 5.093803405761719\n",
      "Index 550 Loss 5.15651273727417\n",
      "Predicting..\n",
      "Accuracy:  39.666666666666664\n",
      "---Epoch 7---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 12.064191818237305\n",
      "Index 50 Loss 5.434751033782959\n",
      "Index 100 Loss 5.670726776123047\n",
      "Index 150 Loss 5.972533702850342\n",
      "Index 200 Loss 5.469500541687012\n",
      "Index 250 Loss 5.190545558929443\n",
      "Index 300 Loss 5.284453392028809\n",
      "Index 350 Loss 5.281808376312256\n",
      "Index 400 Loss 5.319065570831299\n",
      "Index 450 Loss 5.180416584014893\n",
      "Index 500 Loss 4.990837574005127\n",
      "Index 550 Loss 5.044430255889893\n",
      "Predicting..\n",
      "Accuracy:  38.333333333333336\n",
      "---Epoch 8---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.781993865966797\n",
      "Index 50 Loss 5.091314792633057\n",
      "Index 100 Loss 5.220183849334717\n",
      "Index 150 Loss 5.691151142120361\n",
      "Index 200 Loss 5.292997360229492\n",
      "Index 250 Loss 4.9796552658081055\n",
      "Index 300 Loss 5.135412693023682\n",
      "Index 350 Loss 5.1609649658203125\n",
      "Index 400 Loss 5.273624420166016\n",
      "Index 450 Loss 5.1504998207092285\n",
      "Index 500 Loss 4.933873176574707\n",
      "Index 550 Loss 4.996038913726807\n",
      "Predicting..\n",
      "Accuracy:  35.5\n",
      "---Epoch 9---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 11.5516939163208\n",
      "Index 50 Loss 5.126149654388428\n",
      "Index 100 Loss 5.184305667877197\n",
      "Index 150 Loss 5.512175559997559\n",
      "Index 200 Loss 5.073879718780518\n",
      "Index 250 Loss 4.8051934242248535\n",
      "Index 300 Loss 4.913974761962891\n",
      "Index 350 Loss 4.909452438354492\n",
      "Index 400 Loss 4.953943729400635\n",
      "Index 450 Loss 4.852597713470459\n",
      "Index 500 Loss 4.642722129821777\n",
      "Index 550 Loss 4.724875450134277\n",
      "Predicting..\n",
      "Accuracy:  43.166666666666664\n",
      "---Epoch 10---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 10.023907661437988\n",
      "Index 50 Loss 4.68056583404541\n",
      "Index 100 Loss 5.078403472900391\n",
      "Index 150 Loss 5.241521835327148\n",
      "Index 200 Loss 4.883747577667236\n",
      "Index 250 Loss 4.700708866119385\n",
      "Index 300 Loss 4.818356513977051\n",
      "Index 350 Loss 4.898566246032715\n",
      "Index 400 Loss 4.951627731323242\n",
      "Index 450 Loss 4.878726482391357\n",
      "Index 500 Loss 4.696142196655273\n",
      "Index 550 Loss 4.745741367340088\n",
      "Predicting..\n",
      "Accuracy:  37.333333333333336\n",
      "---Epoch 11---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 10.648788452148438\n",
      "Index 50 Loss 4.674976825714111\n",
      "Index 100 Loss 5.0392632484436035\n",
      "Index 150 Loss 5.428847312927246\n",
      "Index 200 Loss 4.930111885070801\n",
      "Index 250 Loss 4.832108020782471\n",
      "Index 300 Loss 4.946877479553223\n",
      "Index 350 Loss 4.970741271972656\n",
      "Index 400 Loss 4.9999003410339355\n",
      "Index 450 Loss 4.823988914489746\n",
      "Index 500 Loss 4.620460510253906\n",
      "Index 550 Loss 4.6965765953063965\n",
      "Predicting..\n",
      "Accuracy:  31.833333333333336\n",
      "---Epoch 12---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 10.485464096069336\n",
      "Index 50 Loss 4.981772422790527\n",
      "Index 100 Loss 5.152820110321045\n",
      "Index 150 Loss 5.339565277099609\n",
      "Index 200 Loss 4.925974369049072\n",
      "Index 250 Loss 4.618403434753418\n",
      "Index 300 Loss 4.685715675354004\n",
      "Index 350 Loss 4.741019248962402\n",
      "Index 400 Loss 4.855444431304932\n",
      "Index 450 Loss 4.71097993850708\n",
      "Index 500 Loss 4.495279312133789\n",
      "Index 550 Loss 4.536620616912842\n",
      "Predicting..\n",
      "Accuracy:  42.333333333333336\n",
      "---Epoch 13---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 11.572458267211914\n",
      "Index 50 Loss 5.501704692840576\n",
      "Index 100 Loss 5.528983116149902\n",
      "Index 150 Loss 5.532315254211426\n",
      "Index 200 Loss 5.045690536499023\n",
      "Index 250 Loss 4.734321594238281\n",
      "Index 300 Loss 4.8214335441589355\n",
      "Index 350 Loss 4.838399410247803\n",
      "Index 400 Loss 4.902368068695068\n",
      "Index 450 Loss 4.7419962882995605\n",
      "Index 500 Loss 4.539187908172607\n",
      "Index 550 Loss 4.631529331207275\n",
      "Predicting..\n",
      "Accuracy:  48.16666666666667\n",
      "---Epoch 14---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.961542129516602\n",
      "Index 50 Loss 4.3453545570373535\n",
      "Index 100 Loss 4.606939792633057\n",
      "Index 150 Loss 4.899166107177734\n",
      "Index 200 Loss 4.7261738777160645\n",
      "Index 250 Loss 4.4264302253723145\n",
      "Index 300 Loss 4.539400577545166\n",
      "Index 350 Loss 4.613058090209961\n",
      "Index 400 Loss 4.6337809562683105\n",
      "Index 450 Loss 4.512030124664307\n",
      "Index 500 Loss 4.264256954193115\n",
      "Index 550 Loss 4.3124165534973145\n",
      "Predicting..\n",
      "Accuracy:  42.333333333333336\n",
      "---Epoch 15---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 10.620744705200195\n",
      "Index 50 Loss 4.568228244781494\n",
      "Index 100 Loss 4.802006244659424\n",
      "Index 150 Loss 4.875776290893555\n",
      "Index 200 Loss 4.53943395614624\n",
      "Index 250 Loss 4.383666038513184\n",
      "Index 300 Loss 4.46352481842041\n",
      "Index 350 Loss 4.473304748535156\n",
      "Index 400 Loss 4.532739639282227\n",
      "Index 450 Loss 4.476418972015381\n",
      "Index 500 Loss 4.2683186531066895\n",
      "Index 550 Loss 4.383110046386719\n",
      "Predicting..\n",
      "Accuracy:  46.666666666666664\n",
      "---Epoch 16---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 6.8825273513793945\n",
      "Index 50 Loss 4.456534385681152\n",
      "Index 100 Loss 4.870774269104004\n",
      "Index 150 Loss 4.99342679977417\n",
      "Index 200 Loss 4.614619731903076\n",
      "Index 250 Loss 4.4811859130859375\n",
      "Index 300 Loss 4.6000213623046875\n",
      "Index 350 Loss 4.5213141441345215\n",
      "Index 400 Loss 4.583175182342529\n",
      "Index 450 Loss 4.440239906311035\n",
      "Index 500 Loss 4.211316108703613\n",
      "Index 550 Loss 4.282988548278809\n",
      "Predicting..\n",
      "Accuracy:  45.0\n",
      "---Epoch 17---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.936759948730469\n",
      "Index 50 Loss 4.364870071411133\n",
      "Index 100 Loss 4.706321716308594\n",
      "Index 150 Loss 4.843319892883301\n",
      "Index 200 Loss 4.5695109367370605\n",
      "Index 250 Loss 4.35368013381958\n",
      "Index 300 Loss 4.349843978881836\n",
      "Index 350 Loss 4.34279203414917\n",
      "Index 400 Loss 4.357726097106934\n",
      "Index 450 Loss 4.275602340698242\n",
      "Index 500 Loss 4.056519508361816\n",
      "Index 550 Loss 4.097185134887695\n",
      "Predicting..\n",
      "Accuracy:  53.5\n",
      "---Epoch 18---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 7.514220237731934\n",
      "Index 50 Loss 4.213794231414795\n",
      "Index 100 Loss 4.969578742980957\n",
      "Index 150 Loss 5.069305419921875\n",
      "Index 200 Loss 4.668404579162598\n",
      "Index 250 Loss 4.457363128662109\n",
      "Index 300 Loss 4.562115669250488\n",
      "Index 350 Loss 4.547881126403809\n",
      "Index 400 Loss 4.5799760818481445\n",
      "Index 450 Loss 4.517792701721191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 500 Loss 4.308001518249512\n",
      "Index 550 Loss 4.379534721374512\n",
      "Predicting..\n",
      "Accuracy:  49.833333333333336\n",
      "---Epoch 19---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 7.376361846923828\n",
      "Index 50 Loss 4.811140060424805\n",
      "Index 100 Loss 4.671398639678955\n",
      "Index 150 Loss 4.790704250335693\n",
      "Index 200 Loss 4.548469543457031\n",
      "Index 250 Loss 4.296502590179443\n",
      "Index 300 Loss 4.383448600769043\n",
      "Index 350 Loss 4.462375640869141\n",
      "Index 400 Loss 4.527151584625244\n",
      "Index 450 Loss 4.39990234375\n",
      "Index 500 Loss 4.21815299987793\n",
      "Index 550 Loss 4.320772171020508\n",
      "Predicting..\n",
      "Accuracy:  48.5\n",
      "---Epoch 20---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 13.02700424194336\n",
      "Index 50 Loss 5.282227993011475\n",
      "Index 100 Loss 5.159090995788574\n",
      "Index 150 Loss 5.240074634552002\n",
      "Index 200 Loss 4.793017864227295\n",
      "Index 250 Loss 4.4663166999816895\n",
      "Index 300 Loss 4.456430435180664\n",
      "Index 350 Loss 4.406853199005127\n",
      "Index 400 Loss 4.422591686248779\n",
      "Index 450 Loss 4.349965572357178\n",
      "Index 500 Loss 4.120241165161133\n",
      "Index 550 Loss 4.254065036773682\n",
      "Predicting..\n",
      "Accuracy:  41.333333333333336\n",
      "---Epoch 21---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 8.166921615600586\n",
      "Index 50 Loss 4.2832207679748535\n",
      "Index 100 Loss 4.359752178192139\n",
      "Index 150 Loss 4.545660972595215\n",
      "Index 200 Loss 4.18726110458374\n",
      "Index 250 Loss 4.03110933303833\n",
      "Index 300 Loss 4.1711578369140625\n",
      "Index 350 Loss 4.206462383270264\n",
      "Index 400 Loss 4.268015384674072\n",
      "Index 450 Loss 4.155780792236328\n",
      "Index 500 Loss 3.970318555831909\n",
      "Index 550 Loss 4.094534397125244\n",
      "Predicting..\n",
      "Accuracy:  48.833333333333336\n",
      "---Epoch 22---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 7.167825222015381\n",
      "Index 50 Loss 4.989462852478027\n",
      "Index 100 Loss 4.874176979064941\n",
      "Index 150 Loss 4.738571643829346\n",
      "Index 200 Loss 4.344254970550537\n",
      "Index 250 Loss 4.197847366333008\n",
      "Index 300 Loss 4.267863750457764\n",
      "Index 350 Loss 4.296916961669922\n",
      "Index 400 Loss 4.27923059463501\n",
      "Index 450 Loss 4.141837120056152\n",
      "Index 500 Loss 3.9419867992401123\n",
      "Index 550 Loss 4.0101847648620605\n",
      "Predicting..\n",
      "Accuracy:  36.5\n",
      "---Epoch 23---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 8.693990707397461\n",
      "Index 50 Loss 4.75761079788208\n",
      "Index 100 Loss 4.571020603179932\n",
      "Index 150 Loss 4.4457292556762695\n",
      "Index 200 Loss 4.181878566741943\n",
      "Index 250 Loss 3.973458766937256\n",
      "Index 300 Loss 4.0774970054626465\n",
      "Index 350 Loss 4.099567413330078\n",
      "Index 400 Loss 4.123732566833496\n",
      "Index 450 Loss 4.006827354431152\n",
      "Index 500 Loss 3.816829204559326\n",
      "Index 550 Loss 3.8857028484344482\n",
      "Predicting..\n",
      "Accuracy:  43.166666666666664\n",
      "---Epoch 24---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 5.726531982421875\n",
      "Index 50 Loss 4.412289619445801\n",
      "Index 100 Loss 4.611557960510254\n",
      "Index 150 Loss 4.499342918395996\n",
      "Index 200 Loss 4.143947601318359\n",
      "Index 250 Loss 3.9482505321502686\n",
      "Index 300 Loss 3.9589271545410156\n",
      "Index 350 Loss 3.9905765056610107\n",
      "Index 400 Loss 4.016111373901367\n",
      "Index 450 Loss 3.934133768081665\n",
      "Index 500 Loss 3.7208757400512695\n",
      "Index 550 Loss 3.7665953636169434\n",
      "Predicting..\n",
      "Accuracy:  39.166666666666664\n",
      "---Epoch 25---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 5.4864678382873535\n",
      "Index 50 Loss 4.37963342666626\n",
      "Index 100 Loss 4.7318220138549805\n",
      "Index 150 Loss 4.772799968719482\n",
      "Index 200 Loss 4.400232791900635\n",
      "Index 250 Loss 4.136905670166016\n",
      "Index 300 Loss 4.231929779052734\n",
      "Index 350 Loss 4.3096208572387695\n",
      "Index 400 Loss 4.3882269859313965\n",
      "Index 450 Loss 4.257505893707275\n",
      "Index 500 Loss 4.031844139099121\n",
      "Index 550 Loss 4.147345542907715\n",
      "Predicting..\n",
      "Accuracy:  45.5\n",
      "---Epoch 26---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 7.50952672958374\n",
      "Index 50 Loss 4.452977657318115\n",
      "Index 100 Loss 4.462201118469238\n",
      "Index 150 Loss 4.439926624298096\n",
      "Index 200 Loss 4.233939170837402\n",
      "Index 250 Loss 4.043941020965576\n",
      "Index 300 Loss 4.131411075592041\n",
      "Index 350 Loss 4.137196063995361\n",
      "Index 400 Loss 4.197683811187744\n",
      "Index 450 Loss 4.0503010749816895\n",
      "Index 500 Loss 3.866079330444336\n",
      "Index 550 Loss 3.9505443572998047\n",
      "Predicting..\n",
      "Accuracy:  47.5\n",
      "---Epoch 27---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 6.953599452972412\n",
      "Index 50 Loss 4.193816661834717\n",
      "Index 100 Loss 4.59159517288208\n",
      "Index 150 Loss 4.679917812347412\n",
      "Index 200 Loss 4.308079719543457\n",
      "Index 250 Loss 4.027088165283203\n",
      "Index 300 Loss 4.151206016540527\n",
      "Index 350 Loss 4.195199966430664\n",
      "Index 400 Loss 4.234992504119873\n",
      "Index 450 Loss 4.1005144119262695\n",
      "Index 500 Loss 3.8956520557403564\n",
      "Index 550 Loss 3.948098659515381\n",
      "Predicting..\n",
      "Accuracy:  45.166666666666664\n",
      "---Epoch 28---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 9.055365562438965\n",
      "Index 50 Loss 4.726620197296143\n",
      "Index 100 Loss 4.620638847351074\n",
      "Index 150 Loss 4.464865684509277\n",
      "Index 200 Loss 4.093202590942383\n",
      "Index 250 Loss 3.8444020748138428\n",
      "Index 300 Loss 3.968816041946411\n",
      "Index 350 Loss 4.01027250289917\n",
      "Index 400 Loss 4.125403881072998\n",
      "Index 450 Loss 4.001796245574951\n",
      "Index 500 Loss 3.8301477432250977\n",
      "Index 550 Loss 3.9229907989501953\n",
      "Predicting..\n",
      "Accuracy:  58.5\n",
      "---Epoch 29---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 5.516279697418213\n",
      "Index 50 Loss 4.022765159606934\n",
      "Index 100 Loss 4.359269618988037\n",
      "Index 150 Loss 4.4755330085754395\n",
      "Index 200 Loss 4.088834285736084\n",
      "Index 250 Loss 3.829481601715088\n",
      "Index 300 Loss 3.8757081031799316\n",
      "Index 350 Loss 3.9779233932495117\n",
      "Index 400 Loss 4.094391822814941\n",
      "Index 450 Loss 3.982928991317749\n",
      "Index 500 Loss 3.80759334564209\n",
      "Index 550 Loss 3.881532907485962\n",
      "Predicting..\n",
      "Accuracy:  46.666666666666664\n",
      "---Epoch 30---\n",
      "\n",
      "Training...\n",
      "Index 0 Loss 13.30517578125\n",
      "Index 50 Loss 4.000565528869629\n",
      "Index 100 Loss 4.287912368774414\n",
      "Index 150 Loss 4.7441020011901855\n",
      "Index 200 Loss 4.491353988647461\n",
      "Index 250 Loss 4.162731170654297\n",
      "Index 300 Loss 4.259432792663574\n",
      "Index 350 Loss 4.216461181640625\n",
      "Index 400 Loss 4.270013332366943\n",
      "Index 450 Loss 4.103151798248291\n",
      "Index 500 Loss 3.9542274475097656\n",
      "Index 550 Loss 4.043903827667236\n",
      "Predicting..\n",
      "Accuracy:  43.833333333333336\n"
     ]
    }
   ],
   "source": [
    "train_and_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
