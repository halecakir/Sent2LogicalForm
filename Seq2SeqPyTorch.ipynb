{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_FILE = \"data/test.txt\"\n",
    "TRAIN_FILE = \"data/train.txt\"\n",
    "WHOLE_FILE = \"data/whole.txt\"\n",
    "F_VOCAB_FILE = \"data/vocab.f.txt\"\n",
    "Q_VOCAB_FILE = \"data/vocab.q.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.rnn_size = 50\n",
    "        self.dropout = False\n",
    "        self.init_weight = 0.08\n",
    "        self.decay_rate = 0.985\n",
    "        self.learning_rate = 0.01\n",
    "        self.plot_every = 10\n",
    "        self.print_every = 50\n",
    "        self.grad_clip = 5\n",
    "        self.dropout = 0\n",
    "        self.dropoutrec = 0\n",
    "        self.learning_rate_decay = 0.985\n",
    "        self.learning_rate_decay_after = 5\n",
    "        \n",
    "        \n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.i2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "        self.h2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "        if opt.dropoutrec > 0:\n",
    "            self.dropout = nn.Dropout(opt.droputrec)\n",
    "            \n",
    "    def forward(self, x, prev_c, prev_h):\n",
    "        gates = self.i2h(x) + self.h2h(prev_h)\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        ingate = torch.sigmoid(ingate)\n",
    "        forgetgate = torch.sigmoid(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = torch.sigmoid(outgate)\n",
    "        if self.opt.dropoutrec > 0:\n",
    "            cellgate = self.dropout(cellgate)\n",
    "        cy = (forgetgate * prev_c) + (ingate * cellgate)\n",
    "        hy = outgate * torch.tanh(cy)  # n_b x hidden_dim\n",
    "        return cy, hy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, opt, input_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        self.lstm = LSTM(self.opt)\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.__initParameters()\n",
    "\n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "                \n",
    "    def forward(self, input_src, prev_c, prev_h):\n",
    "        src_emb = self.embedding(input_src) # batch_size x src_length x emb_size\n",
    "        if self.opt.dropout > 0:\n",
    "            src_emb = self.dropout(src_emb)\n",
    "        prev_cy, prev_hy = self.lstm(src_emb, prev_c, prev_h)\n",
    "        return prev_cy, prev_hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, opt, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
    "        self.lstm = LSTM(self.opt)\n",
    "        self.linear = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.__initParameters()\n",
    "\n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "                \n",
    "    def forward(self, input, prev_c, prev_h):\n",
    "        output = self.embedding(input)\n",
    "        if self.opt.dropout > 0:\n",
    "            output = self.dropout(output)\n",
    "        next_c, next_h = self.lstm(output, prev_c, prev_h)\n",
    "        if self.opt.dropout > 0:\n",
    "            next_h = self.dropout(next_h)\n",
    "        h2y = self.linear(next_h)\n",
    "        pred = self.softmax(h2y)\n",
    "        return pred, next_c, next_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fh):\n",
    "    for line in fh:\n",
    "        sentence, lf = line.strip().split(\"\\t\")\n",
    "        sentence = sentence.split()\n",
    "        lf = lf.split()\n",
    "        yield sentence, lf\n",
    "\n",
    "def read_vocab(filename):\n",
    "    t2i = {\"<s>\": 0, \"</s>\":1, \"UNK\": 2}\n",
    "    with open(filename) as target:\n",
    "        for line in target:\n",
    "            token = line.strip().split()[0]\n",
    "            if token not in t2i:\n",
    "                t2i[token] = len(t2i)\n",
    "    return t2i\n",
    "\n",
    "def is_equal(gold, predictions):\n",
    "    total_correct = 0.0\n",
    "    if len(gold) == len(predictions):\n",
    "        equal = True\n",
    "        for g, p in zip(gold, predictions):\n",
    "            if g != p:\n",
    "                equal = False\n",
    "        return equal\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprare_data(file_name):\n",
    "    shuffledData = None\n",
    "    with open(TRAIN_FILE, 'r') as train:\n",
    "        shuffledData = list(read_data(train))\n",
    "        random.shuffle(shuffledData)\n",
    "    sentence_index_tensors = []\n",
    "    form_index_tensors = []\n",
    "    for sentence in shuffledData:\n",
    "        text_tensor = torch.zeros((1, len(sentence[0]) + 2), dtype=torch.long)\n",
    "        text_tensor[0][0] = w2i[\"<s>\"]\n",
    "        for idx, word in enumerate(sentence[0]):\n",
    "            word_index = w2i[word] if word in w2i else w2i[\"UNK\"]\n",
    "            text_tensor[0][idx+1] = word_index\n",
    "        text_tensor[0][-1] = w2i[\"</s>\"]\n",
    "        sentence_index_tensors.append(text_tensor)\n",
    "        form_tensor = torch.zeros((1, len(sentence[1]) + 2), dtype=torch.long)\n",
    "        form_tensor[0][0] = lf2i[\"<s>\"]\n",
    "        for idx, form in enumerate(sentence[1]):\n",
    "            form_index = lf2i[form] if form in lf2i else lf2i[\"UNK\"]\n",
    "            form_tensor[0][idx+1] = form_index\n",
    "        form_tensor[0][-1] = lf2i[\"</s>\"]\n",
    "        form_index_tensors.append(form_tensor)\n",
    "    return shuffledData, sentence_index_tensors, form_index_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(opt, criterion, encoder_optimizer, decoder_optimizer, encoder, decoder, s1, f1):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "\n",
    "    #for dec_in in f1:\n",
    "    loss = 0\n",
    "    for i in range(f1.size(1)-1):\n",
    "        pred, c, h = decoder(f1[:, i], c, h)\n",
    "        loss += criterion(pred, f1[:, i+1])\n",
    "    loss.backward()\n",
    "    if opt.grad_clip != -1:\n",
    "        torch.nn.utils.clip_grad_value_(encoder.parameters(),opt.grad_clip)\n",
    "        torch.nn.utils.clip_grad_value_(decoder.parameters(),opt.grad_clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(opt, s1, lf2i, encoder, decoder):\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "\n",
    "    prev = torch.tensor([lf2i['<s>']], dtype=torch.long)\n",
    "    predicted_form = []\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        pred, c, h = decoder(prev, c, h)\n",
    "        form_id = pred.argmax().item()\n",
    "        prev = torch.tensor([form_id], dtype=torch.long)\n",
    "        if form_id == lf2i[\"</s>\"] or counter >= 100:\n",
    "            break\n",
    "        predicted_form.append(form_id)\n",
    "    return predicted_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "def showPlot(points, fig_name, extra_info):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.title(extra_info) \n",
    "    plt.plot(points)\n",
    "    plt.savefig(\"{}.png\".format(fig_name))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_num, directory):\n",
    "    train_data, sentence_index_tensors_train, form_index_tensors_train = preprare_data(TRAIN_FILE)\n",
    "    test_data, sentence_index_tensors_test, form_index_tensors_test = preprare_data(TEST_FILE)\n",
    "    \n",
    "    encoder = Encoder(opt, len(w2i))\n",
    "    decoder = Decoder(opt, len(lf2i))\n",
    "\n",
    "    optim_state = {\"learningRate\" : opt.learning_rate, \"alpha\" :  opt.decay_rate}\n",
    "    encoder_optimizer = optim.RMSprop(encoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "    decoder_optimizer = optim.RMSprop(decoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "    criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "    losses = []\n",
    "    max_acc = 0\n",
    "    maxAccEpochId = 0\n",
    "    accuracies = []\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"---Epoch {}---\\n\".format(epoch+1))\n",
    "        print(\"Training...\")\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        plot_data = []\n",
    "        for index, (sentence, form) in enumerate(zip(sentence_index_tensors_train, form_index_tensors_train)):\n",
    "            loss = train(opt, criterion, encoder_optimizer, decoder_optimizer, encoder, decoder, sentence, form)\n",
    "            if index != 0:\n",
    "                if index % opt.plot_every == 0:     \n",
    "                    plot_data.append(np.mean(losses[epoch*len(train_data)+index-opt.plot_every:]))\n",
    "                if index % opt.print_every == 0:\n",
    "                    print(\"Index {} Loss {}\".format(index, np.mean(losses[epoch*len(train_data)+index-opt.print_every:])))\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        if opt.learning_rate_decay < 1:\n",
    "            if epoch >= opt.learning_rate_decay_after:\n",
    "                decay_factor = opt.learning_rate_decay\n",
    "                optim_state[\"learningRate\"] = optim_state[\"learningRate\"] * decay_factor #decay it\n",
    "                for param_group in encoder_optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "                for param_group in decoder_optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "        \n",
    "        print(\"Predicting..\")\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        correct = 0.0\n",
    "        with torch.no_grad():\n",
    "            for index, (sentence, form) in enumerate(zip(sentence_index_tensors_test, form_index_tensors_test)):\n",
    "                prediction = predict(opt, sentence, lf2i, encoder, decoder)\n",
    "                prediction = [i2lf[p] for p in prediction]\n",
    "                #print(test_data[index][1])\n",
    "                #print(prediction)\n",
    "                same = True\n",
    "                for g, p in zip(test_data[index][1], prediction):\n",
    "                    if g != p:\n",
    "                        same = False\n",
    "                if same:\n",
    "                    correct += 1\n",
    "                    #print(\"Correct match \", prediction)\n",
    "                    \n",
    "        accuracy = 100*(correct/len(test_data))\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > max_acc:\n",
    "            max_acc = accuracy\n",
    "            maxAccEpochId = epoch\n",
    "            \n",
    "        print(\"Accuracy: {} Max Accuracy {}\".format(accuracy, max_acc))\n",
    "        \n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "        file_name = \"{}/epoch.{}\".format(directory, epoch)\n",
    "        extra = \"Mean Loss {0:.2f}\".format(np.mean(losses))\n",
    "        showPlot(plot_data, file_name, extra)\n",
    "        \n",
    "    file_name = \"{}/{}\".format(directory, \"accuracies\")\n",
    "    extra = \"Maximum Accuracy {0:.2f} at epoch {1}\".format(np.max(accuracies), maxAccEpochId)\n",
    "    showPlot(accuracies, file_name, extra)\n",
    "    file_name = \"{}/{}\".format(directory, \"all_losses\")\n",
    "    \n",
    "    extra = \"Mean Loss {0:.2f}\".format(np.mean(losses))\n",
    "    showPlot(losses, file_name, extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = read_vocab(Q_VOCAB_FILE)\n",
    "lf2i = read_vocab(F_VOCAB_FILE)\n",
    "i2lf = {lf2i[i] : i for i in lf2i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 37.2561768913269\n",
      "Index 100 Loss 19.44763627052307\n",
      "Index 150 Loss 18.315035662651063\n",
      "Index 200 Loss 14.876395363807678\n",
      "Index 250 Loss 11.175154457092285\n",
      "Index 300 Loss 13.80512481212616\n",
      "Index 350 Loss 13.507837109565735\n",
      "Index 400 Loss 15.254737734794617\n",
      "Index 450 Loss 13.086537480354309\n",
      "Index 500 Loss 13.567912964820861\n",
      "Index 550 Loss 10.704102435111999\n",
      "Predicting..\n",
      "Accuracy: 0.0 Max Accuracy 0\n",
      "---Epoch 2---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 14.09244921207428\n",
      "Index 100 Loss 10.579448757171631\n",
      "Index 150 Loss 11.842061352729797\n",
      "Index 200 Loss 10.05725989818573\n",
      "Index 250 Loss 7.757682881355286\n",
      "Index 300 Loss 9.947220759391785\n",
      "Index 350 Loss 10.450408263206482\n",
      "Index 400 Loss 12.043740105628967\n",
      "Index 450 Loss 10.402203435897826\n",
      "Index 500 Loss 11.001408300399781\n",
      "Index 550 Loss 8.704847469329835\n",
      "Predicting..\n",
      "Accuracy: 14.000000000000002 Max Accuracy 14.000000000000002\n",
      "---Epoch 3---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 11.739828634262086\n",
      "Index 100 Loss 8.768062434196473\n",
      "Index 150 Loss 10.095608582496643\n",
      "Index 200 Loss 8.799127826690674\n",
      "Index 250 Loss 6.423045735359192\n",
      "Index 300 Loss 8.382940120697022\n",
      "Index 350 Loss 8.653993649482727\n",
      "Index 400 Loss 9.939756474494935\n",
      "Index 450 Loss 8.355191807746888\n",
      "Index 500 Loss 9.504219679832458\n",
      "Index 550 Loss 7.320843391418457\n",
      "Predicting..\n",
      "Accuracy: 18.333333333333332 Max Accuracy 18.333333333333332\n",
      "---Epoch 4---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 10.554799571037293\n",
      "Index 100 Loss 7.565467863082886\n",
      "Index 150 Loss 8.787509841918945\n",
      "Index 200 Loss 7.711814892292023\n",
      "Index 250 Loss 5.769207062721253\n",
      "Index 300 Loss 7.370440273284912\n",
      "Index 350 Loss 8.095698251724244\n",
      "Index 400 Loss 8.845929203033448\n",
      "Index 450 Loss 7.817317924499512\n",
      "Index 500 Loss 9.144123549461364\n",
      "Index 550 Loss 6.797590727806091\n",
      "Predicting..\n",
      "Accuracy: 21.666666666666668 Max Accuracy 21.666666666666668\n",
      "---Epoch 5---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 9.714579119682313\n",
      "Index 100 Loss 6.849479854106903\n",
      "Index 150 Loss 8.000048103332519\n",
      "Index 200 Loss 6.961791007518769\n",
      "Index 250 Loss 5.129230630397797\n",
      "Index 300 Loss 6.199978077411652\n",
      "Index 350 Loss 7.523035256862641\n",
      "Index 400 Loss 8.235923795700073\n",
      "Index 450 Loss 7.272380819320679\n",
      "Index 500 Loss 7.995215306282043\n",
      "Index 550 Loss 6.402939383983612\n",
      "Predicting..\n",
      "Accuracy: 22.166666666666668 Max Accuracy 22.166666666666668\n",
      "---Epoch 6---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 9.218228936195374\n",
      "Index 100 Loss 6.450325472354889\n",
      "Index 150 Loss 7.414891993999481\n",
      "Index 200 Loss 6.252600774765015\n",
      "Index 250 Loss 4.53590015411377\n",
      "Index 300 Loss 5.616934816837311\n",
      "Index 350 Loss 6.522444086074829\n",
      "Index 400 Loss 7.687281589508057\n",
      "Index 450 Loss 6.655838787555695\n",
      "Index 500 Loss 7.167799696922303\n",
      "Index 550 Loss 5.740405848026276\n",
      "Predicting..\n",
      "Accuracy: 21.666666666666668 Max Accuracy 22.166666666666668\n",
      "---Epoch 7---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 8.474633715152741\n",
      "Index 100 Loss 5.848685762882233\n",
      "Index 150 Loss 6.580549178123474\n",
      "Index 200 Loss 5.871076927185059\n",
      "Index 250 Loss 4.104924240112305\n",
      "Index 300 Loss 5.54813185095787\n",
      "Index 350 Loss 5.959378159046173\n",
      "Index 400 Loss 6.7926110172271725\n",
      "Index 450 Loss 6.170595767498017\n",
      "Index 500 Loss 7.195877566337585\n",
      "Index 550 Loss 5.659906105995178\n",
      "Predicting..\n",
      "Accuracy: 30.166666666666668 Max Accuracy 30.166666666666668\n",
      "---Epoch 8---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 7.739061007499695\n",
      "Index 100 Loss 5.485601670742035\n",
      "Index 150 Loss 6.5636135971546175\n",
      "Index 200 Loss 5.91296937584877\n",
      "Index 250 Loss 4.034381151199341\n",
      "Index 300 Loss 5.012361119985581\n",
      "Index 350 Loss 5.726536078453064\n",
      "Index 400 Loss 7.210514452457428\n",
      "Index 450 Loss 5.704657254219055\n",
      "Index 500 Loss 6.555588746070862\n",
      "Index 550 Loss 5.434487084150314\n",
      "Predicting..\n",
      "Accuracy: 31.666666666666664 Max Accuracy 31.666666666666664\n",
      "---Epoch 9---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 7.647528319358826\n",
      "Index 100 Loss 5.8975867176055905\n",
      "Index 150 Loss 6.228360922336578\n",
      "Index 200 Loss 5.000606050491333\n",
      "Index 250 Loss 3.545206694602966\n",
      "Index 300 Loss 4.751227479577064\n",
      "Index 350 Loss 5.140954294800759\n",
      "Index 400 Loss 6.3886591958999634\n",
      "Index 450 Loss 5.300329167246819\n",
      "Index 500 Loss 6.533467197418213\n",
      "Index 550 Loss 5.148468886613846\n",
      "Predicting..\n",
      "Accuracy: 35.333333333333336 Max Accuracy 35.333333333333336\n",
      "---Epoch 10---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 6.979099949598313\n",
      "Index 100 Loss 4.85679369866848\n",
      "Index 150 Loss 5.587205864191056\n",
      "Index 200 Loss 4.684293153285981\n",
      "Index 250 Loss 3.3167736929655076\n",
      "Index 300 Loss 4.57816503405571\n",
      "Index 350 Loss 4.780278795957566\n",
      "Index 400 Loss 5.892399115562439\n",
      "Index 450 Loss 4.674428453445435\n",
      "Index 500 Loss 6.079564547538757\n",
      "Index 550 Loss 4.684326211214065\n",
      "Predicting..\n",
      "Accuracy: 38.5 Max Accuracy 38.5\n",
      "---Epoch 11---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 6.534080842733383\n",
      "Index 100 Loss 4.1510934764146805\n",
      "Index 150 Loss 5.3443759298324585\n",
      "Index 200 Loss 4.510292053222656\n",
      "Index 250 Loss 3.364739925861359\n",
      "Index 300 Loss 4.485193781852722\n",
      "Index 350 Loss 4.176668517589569\n",
      "Index 400 Loss 5.532287223339081\n",
      "Index 450 Loss 4.389155763983727\n",
      "Index 500 Loss 5.787216160297394\n",
      "Index 550 Loss 4.324100303649902\n",
      "Predicting..\n",
      "Accuracy: 35.16666666666667 Max Accuracy 38.5\n",
      "---Epoch 12---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 7.003880072832107\n",
      "Index 100 Loss 4.39689329624176\n",
      "Index 150 Loss 5.246122734844684\n",
      "Index 200 Loss 4.137015378475189\n",
      "Index 250 Loss 2.9550247585773466\n",
      "Index 300 Loss 4.516846699714661\n",
      "Index 350 Loss 4.535589758455753\n",
      "Index 400 Loss 5.103932339549065\n",
      "Index 450 Loss 4.401574917435646\n",
      "Index 500 Loss 5.867600996494293\n",
      "Index 550 Loss 4.392401415407658\n",
      "Predicting..\n",
      "Accuracy: 41.0 Max Accuracy 41.0\n",
      "---Epoch 13---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 6.092484984099865\n",
      "Index 100 Loss 3.966562019586563\n",
      "Index 150 Loss 4.914186412096024\n",
      "Index 200 Loss 3.76590256690979\n",
      "Index 250 Loss 2.693270453512669\n",
      "Index 300 Loss 4.523272552490234\n",
      "Index 350 Loss 4.614921018481255\n",
      "Index 400 Loss 4.880753821730614\n",
      "Index 450 Loss 4.533455106019974\n",
      "Index 500 Loss 5.269677123427391\n",
      "Index 550 Loss 4.077225749492645\n",
      "Predicting..\n",
      "Accuracy: 46.33333333333333 Max Accuracy 46.33333333333333\n",
      "---Epoch 14---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 5.933054995536804\n",
      "Index 100 Loss 4.019444116353989\n",
      "Index 150 Loss 4.706274343729019\n",
      "Index 200 Loss 3.551965544223785\n",
      "Index 250 Loss 2.6407621839642523\n",
      "Index 300 Loss 4.493302505761385\n",
      "Index 350 Loss 4.200112400650978\n",
      "Index 400 Loss 5.258728782534599\n",
      "Index 450 Loss 4.0392155233025555\n",
      "Index 500 Loss 4.7805514240264895\n",
      "Index 550 Loss 4.20669287353754\n",
      "Predicting..\n",
      "Accuracy: 48.5 Max Accuracy 48.5\n",
      "---Epoch 15---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 5.342282300591469\n",
      "Index 100 Loss 4.050018026530743\n",
      "Index 150 Loss 4.3730569344758985\n",
      "Index 200 Loss 3.4617111882567406\n",
      "Index 250 Loss 2.3456653019785882\n",
      "Index 300 Loss 4.135253026485443\n",
      "Index 350 Loss 3.8385296738147736\n",
      "Index 400 Loss 4.51722748696804\n",
      "Index 450 Loss 4.342438499927521\n",
      "Index 500 Loss 4.718158223628998\n",
      "Index 550 Loss 4.071400525271892\n",
      "Predicting..\n",
      "Accuracy: 53.333333333333336 Max Accuracy 53.333333333333336\n",
      "---Epoch 16---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 5.117605655193329\n",
      "Index 100 Loss 3.7167483949661255\n",
      "Index 150 Loss 4.147134056091309\n",
      "Index 200 Loss 3.0878649240732194\n",
      "Index 250 Loss 2.205155021548271\n",
      "Index 300 Loss 3.3355593395233156\n",
      "Index 350 Loss 3.5183177170157434\n",
      "Index 400 Loss 4.635976088643074\n",
      "Index 450 Loss 3.5899868059158324\n",
      "Index 500 Loss 4.875471791327\n",
      "Index 550 Loss 3.4821089100837708\n",
      "Predicting..\n",
      "Accuracy: 51.33333333333333 Max Accuracy 53.333333333333336\n",
      "---Epoch 17---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.477556144893169\n",
      "Index 100 Loss 3.776754294037819\n",
      "Index 150 Loss 3.972694421708584\n",
      "Index 200 Loss 3.1358008685708048\n",
      "Index 250 Loss 2.2268336172401906\n",
      "Index 300 Loss 3.2579205387830736\n",
      "Index 350 Loss 3.5826830995082855\n",
      "Index 400 Loss 4.478993340730667\n",
      "Index 450 Loss 3.4755341240763666\n",
      "Index 500 Loss 4.7032785584032535\n",
      "Index 550 Loss 3.505510242283344\n",
      "Predicting..\n",
      "Accuracy: 53.333333333333336 Max Accuracy 53.333333333333336\n",
      "---Epoch 18---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.409316729009151\n",
      "Index 100 Loss 3.3938013960421087\n",
      "Index 150 Loss 4.001688786149025\n",
      "Index 200 Loss 2.622790248990059\n",
      "Index 250 Loss 2.4164934740960597\n",
      "Index 300 Loss 3.8575734433531763\n",
      "Index 350 Loss 3.4047252002358435\n",
      "Index 400 Loss 4.383933347165584\n",
      "Index 450 Loss 3.519405310750008\n",
      "Index 500 Loss 4.516950224637985\n",
      "Index 550 Loss 3.36240736939013\n",
      "Predicting..\n",
      "Accuracy: 56.00000000000001 Max Accuracy 56.00000000000001\n",
      "---Epoch 19---\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 50 Loss 4.326855003237724\n",
      "Index 100 Loss 3.574752473682165\n",
      "Index 150 Loss 3.507942192554474\n",
      "Index 200 Loss 2.6949082659184933\n",
      "Index 250 Loss 1.8945275038480758\n",
      "Index 300 Loss 3.363847492039204\n",
      "Index 350 Loss 3.372338815033436\n",
      "Index 400 Loss 4.008630764484406\n",
      "Index 450 Loss 3.795336416363716\n",
      "Index 500 Loss 4.250645526796579\n",
      "Index 550 Loss 3.123820932507515\n",
      "Predicting..\n",
      "Accuracy: 56.00000000000001 Max Accuracy 56.00000000000001\n",
      "---Epoch 20---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.40869882568717\n",
      "Index 100 Loss 3.251460372507572\n",
      "Index 150 Loss 3.6407403522729873\n",
      "Index 200 Loss 2.409482210576534\n",
      "Index 250 Loss 1.817229561805725\n",
      "Index 300 Loss 2.8694618052244185\n",
      "Index 350 Loss 3.2721267706155777\n",
      "Index 400 Loss 3.61155677318573\n",
      "Index 450 Loss 3.5079111662507056\n",
      "Index 500 Loss 4.188482012450695\n",
      "Index 550 Loss 2.8789446180686356\n",
      "Predicting..\n",
      "Accuracy: 56.99999999999999 Max Accuracy 56.99999999999999\n",
      "---Epoch 21---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.0348757691681385\n",
      "Index 100 Loss 3.4215333861112596\n",
      "Index 150 Loss 4.0282250130176545\n",
      "Index 200 Loss 2.6448871991038323\n",
      "Index 250 Loss 1.697449753805995\n",
      "Index 300 Loss 2.6125671058893203\n",
      "Index 350 Loss 2.761445670425892\n",
      "Index 400 Loss 3.4677173914015293\n",
      "Index 450 Loss 3.1804889321327208\n",
      "Index 500 Loss 4.3549911141395565\n",
      "Index 550 Loss 2.677516035735607\n",
      "Predicting..\n",
      "Accuracy: 54.50000000000001 Max Accuracy 56.99999999999999\n",
      "---Epoch 22---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.213813408315182\n",
      "Index 100 Loss 3.5101898077130316\n",
      "Index 150 Loss 3.873636813759804\n",
      "Index 200 Loss 2.167932368218899\n",
      "Index 250 Loss 1.8462441396713256\n",
      "Index 300 Loss 2.886722202003002\n",
      "Index 350 Loss 2.699796497821808\n",
      "Index 400 Loss 3.5670600689947607\n",
      "Index 450 Loss 2.831475532948971\n",
      "Index 500 Loss 3.722048064172268\n",
      "Index 550 Loss 3.212608123719692\n",
      "Predicting..\n",
      "Accuracy: 53.333333333333336 Max Accuracy 56.99999999999999\n",
      "---Epoch 23---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.0124486774206165\n",
      "Index 100 Loss 2.9601147615909578\n",
      "Index 150 Loss 3.3711455717682837\n",
      "Index 200 Loss 2.127226742208004\n",
      "Index 250 Loss 1.5653445928543805\n",
      "Index 300 Loss 3.1250040236115457\n",
      "Index 350 Loss 2.329477668851614\n",
      "Index 400 Loss 3.717887167930603\n",
      "Index 450 Loss 2.848792690038681\n",
      "Index 500 Loss 3.858537272810936\n",
      "Index 550 Loss 2.53838632106781\n",
      "Predicting..\n",
      "Accuracy: 56.49999999999999 Max Accuracy 56.99999999999999\n",
      "---Epoch 24---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.8965260183811186\n",
      "Index 100 Loss 2.799672772735357\n",
      "Index 150 Loss 3.8864447513222693\n",
      "Index 200 Loss 2.377156623452902\n",
      "Index 250 Loss 1.5014336866885423\n",
      "Index 300 Loss 2.502343909814954\n",
      "Index 350 Loss 2.7782593819499017\n",
      "Index 400 Loss 3.5553618766367436\n",
      "Index 450 Loss 2.894879388511181\n",
      "Index 500 Loss 3.6765895009040834\n",
      "Index 550 Loss 2.705464369058609\n",
      "Predicting..\n",
      "Accuracy: 61.0 Max Accuracy 61.0\n",
      "---Epoch 25---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.159223165139556\n",
      "Index 100 Loss 2.8944201086461545\n",
      "Index 150 Loss 3.1929821500182154\n",
      "Index 200 Loss 2.210899050757289\n",
      "Index 250 Loss 1.4840004448592663\n",
      "Index 300 Loss 2.949378459751606\n",
      "Index 350 Loss 2.7617997327446937\n",
      "Index 400 Loss 3.201374101340771\n",
      "Index 450 Loss 2.707542797327042\n",
      "Index 500 Loss 3.4112731620669363\n",
      "Index 550 Loss 2.7073674988746643\n",
      "Predicting..\n",
      "Accuracy: 61.16666666666667 Max Accuracy 61.16666666666667\n",
      "---Epoch 26---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.383105808198452\n",
      "Index 100 Loss 3.4112212412059306\n",
      "Index 150 Loss 3.5477167958021165\n",
      "Index 200 Loss 2.1824542085826395\n",
      "Index 250 Loss 1.395478807091713\n",
      "Index 300 Loss 2.230031455159187\n",
      "Index 350 Loss 2.72195841640234\n",
      "Index 400 Loss 3.5914174556732177\n",
      "Index 450 Loss 2.872408224195242\n",
      "Index 500 Loss 3.0946490702033045\n",
      "Index 550 Loss 2.549277727007866\n",
      "Predicting..\n",
      "Accuracy: 60.0 Max Accuracy 61.16666666666667\n",
      "---Epoch 27---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.169241707921028\n",
      "Index 100 Loss 2.8125124691426753\n",
      "Index 150 Loss 3.1442939507961274\n",
      "Index 200 Loss 2.125799501426518\n",
      "Index 250 Loss 1.3264203140139579\n",
      "Index 300 Loss 2.2486431780457496\n",
      "Index 350 Loss 2.35803485929966\n",
      "Index 400 Loss 3.0521920254826544\n",
      "Index 450 Loss 2.372013433724642\n",
      "Index 500 Loss 3.12596222281456\n",
      "Index 550 Loss 2.8115307718515394\n",
      "Predicting..\n",
      "Accuracy: 61.16666666666667 Max Accuracy 61.16666666666667\n",
      "---Epoch 28---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.328193565607071\n",
      "Index 100 Loss 3.0748594588041307\n",
      "Index 150 Loss 2.8530230593681334\n",
      "Index 200 Loss 2.238266179859638\n",
      "Index 250 Loss 1.2077652516961097\n",
      "Index 300 Loss 2.070435286015272\n",
      "Index 350 Loss 2.67626590013504\n",
      "Index 400 Loss 3.259041178524494\n",
      "Index 450 Loss 2.5353438133001327\n",
      "Index 500 Loss 2.812688386142254\n",
      "Index 550 Loss 2.761043099164963\n",
      "Predicting..\n",
      "Accuracy: 61.0 Max Accuracy 61.16666666666667\n",
      "---Epoch 29---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.5293480718135832\n",
      "Index 100 Loss 2.7531744891405108\n",
      "Index 150 Loss 2.7440879353880883\n",
      "Index 200 Loss 2.1729888579249383\n",
      "Index 250 Loss 1.2628630396723748\n",
      "Index 300 Loss 2.349631145596504\n",
      "Index 350 Loss 2.2450042018294334\n",
      "Index 400 Loss 3.3579804253578187\n",
      "Index 450 Loss 2.4351032176613807\n",
      "Index 500 Loss 2.7973285277187823\n",
      "Index 550 Loss 1.9370903696119786\n",
      "Predicting..\n",
      "Accuracy: 62.33333333333333 Max Accuracy 62.33333333333333\n",
      "---Epoch 30---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.2665683886408807\n",
      "Index 100 Loss 2.5172285678982735\n",
      "Index 150 Loss 3.136649358123541\n",
      "Index 200 Loss 1.656073316335678\n",
      "Index 250 Loss 1.4929111796617507\n",
      "Index 300 Loss 2.488471164405346\n",
      "Index 350 Loss 2.2317093005776405\n",
      "Index 400 Loss 3.3213797514140606\n",
      "Index 450 Loss 2.4908627691864966\n",
      "Index 500 Loss 2.676805533915758\n",
      "Index 550 Loss 2.14963836401701\n",
      "Predicting..\n",
      "Accuracy: 63.5 Max Accuracy 63.5\n",
      "---Epoch 31---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.48443957388401\n",
      "Index 100 Loss 2.5499444369971753\n",
      "Index 150 Loss 2.9266253018379214\n",
      "Index 200 Loss 1.7687686482071876\n",
      "Index 250 Loss 1.2190086722373963\n",
      "Index 300 Loss 2.2290119394659995\n",
      "Index 350 Loss 2.0825672936439514\n",
      "Index 400 Loss 3.5088255327939986\n",
      "Index 450 Loss 2.3161697122454643\n",
      "Index 500 Loss 3.108611274957657\n",
      "Index 550 Loss 2.4738554707169533\n",
      "Predicting..\n",
      "Accuracy: 62.0 Max Accuracy 63.5\n",
      "---Epoch 32---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.9521052062511446\n",
      "Index 100 Loss 2.8520460213720797\n",
      "Index 150 Loss 2.8255772852897643\n",
      "Index 200 Loss 1.766003296971321\n",
      "Index 250 Loss 0.8351442176103592\n",
      "Index 300 Loss 2.3962262612581253\n",
      "Index 350 Loss 2.1924585404992105\n",
      "Index 400 Loss 3.0072315448522566\n",
      "Index 450 Loss 2.3635137909650803\n",
      "Index 500 Loss 3.187992319762707\n",
      "Index 550 Loss 1.8376599660515784\n",
      "Predicting..\n",
      "Accuracy: 64.16666666666667 Max Accuracy 64.16666666666667\n",
      "---Epoch 33---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.93810577660799\n",
      "Index 100 Loss 2.5666909438371657\n",
      "Index 150 Loss 2.987074597775936\n",
      "Index 200 Loss 1.9178910961747169\n",
      "Index 250 Loss 0.8878326958417893\n",
      "Index 300 Loss 1.8363514262437821\n",
      "Index 350 Loss 1.9916339605301618\n",
      "Index 400 Loss 3.1246838416159153\n",
      "Index 450 Loss 2.287036617100239\n",
      "Index 500 Loss 2.755274640470743\n",
      "Index 550 Loss 1.9942647115886212\n",
      "Predicting..\n",
      "Accuracy: 67.33333333333333 Max Accuracy 67.33333333333333\n",
      "---Epoch 34---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.563620973750949\n",
      "Index 100 Loss 2.2176483860611915\n",
      "Index 150 Loss 2.7847363460063934\n",
      "Index 200 Loss 1.5481406354904175\n",
      "Index 250 Loss 0.981229697316885\n",
      "Index 300 Loss 2.1463670068979264\n",
      "Index 350 Loss 2.198315286040306\n",
      "Index 400 Loss 2.6177597349882125\n",
      "Index 450 Loss 2.2681086398661137\n",
      "Index 500 Loss 2.616196002215147\n",
      "Index 550 Loss 2.409025359749794\n",
      "Predicting..\n",
      "Accuracy: 65.66666666666666 Max Accuracy 67.33333333333333\n",
      "---Epoch 35---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.747619044929743\n",
      "Index 100 Loss 1.8852024208009244\n",
      "Index 150 Loss 2.722638215497136\n",
      "Index 200 Loss 1.7837736424803734\n",
      "Index 250 Loss 1.1181532041728497\n",
      "Index 300 Loss 2.391983515322208\n",
      "Index 350 Loss 2.3097059029340743\n",
      "Index 400 Loss 3.2437887324392793\n",
      "Index 450 Loss 2.4650335392355918\n",
      "Index 500 Loss 2.581224199384451\n",
      "Index 550 Loss 2.093418541550636\n",
      "Predicting..\n",
      "Accuracy: 67.83333333333333 Max Accuracy 67.83333333333333\n",
      "---Epoch 36---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.5808894336223602\n",
      "Index 100 Loss 2.169696689248085\n",
      "Index 150 Loss 2.293944551050663\n",
      "Index 200 Loss 1.6199092096090317\n",
      "Index 250 Loss 1.0890724746882916\n",
      "Index 300 Loss 2.1339775735139845\n",
      "Index 350 Loss 2.4875224617123606\n",
      "Index 400 Loss 3.3717928819358347\n",
      "Index 450 Loss 2.3434846004843712\n",
      "Index 500 Loss 2.605492449402809\n",
      "Index 550 Loss 1.8515247796475887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting..\n",
      "Accuracy: 68.5 Max Accuracy 68.5\n",
      "---Epoch 37---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.8895100378990173\n",
      "Index 100 Loss 2.048700543195009\n",
      "Index 150 Loss 2.3639625853300092\n",
      "Index 200 Loss 1.9277950072288512\n",
      "Index 250 Loss 1.3613172046840192\n",
      "Index 300 Loss 1.4654687881469726\n",
      "Index 350 Loss 2.0119307724013926\n",
      "Index 400 Loss 2.646899258643389\n",
      "Index 450 Loss 2.1706523153185846\n",
      "Index 500 Loss 2.404862190634012\n",
      "Index 550 Loss 1.799284826517105\n",
      "Predicting..\n",
      "Accuracy: 67.0 Max Accuracy 68.5\n",
      "---Epoch 38---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.286091637760401\n",
      "Index 100 Loss 1.965377458781004\n",
      "Index 150 Loss 1.9935125696659088\n",
      "Index 200 Loss 1.5432980056107044\n",
      "Index 250 Loss 1.011393016949296\n",
      "Index 300 Loss 1.7126077952980996\n",
      "Index 350 Loss 2.1806417142599823\n",
      "Index 400 Loss 2.505485379360616\n",
      "Index 450 Loss 2.234365695398301\n",
      "Index 500 Loss 2.616557237356901\n",
      "Index 550 Loss 1.9664887382090093\n",
      "Predicting..\n",
      "Accuracy: 67.5 Max Accuracy 68.5\n",
      "---Epoch 39---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.5537195575237273\n",
      "Index 100 Loss 1.919937391281128\n",
      "Index 150 Loss 2.181685897856951\n",
      "Index 200 Loss 1.572737159281969\n",
      "Index 250 Loss 0.9000436079502105\n",
      "Index 300 Loss 1.715166931077838\n",
      "Index 350 Loss 1.8027524811029434\n",
      "Index 400 Loss 2.541602885723114\n",
      "Index 450 Loss 2.3160176388919353\n",
      "Index 500 Loss 2.2270263630151748\n",
      "Index 550 Loss 2.280806639939547\n",
      "Predicting..\n",
      "Accuracy: 69.33333333333334 Max Accuracy 69.33333333333334\n",
      "---Epoch 40---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.052555323839188\n",
      "Index 100 Loss 1.7736946256458759\n",
      "Index 150 Loss 2.2013025775551798\n",
      "Index 200 Loss 1.4725356568954886\n",
      "Index 250 Loss 0.7819701910018921\n",
      "Index 300 Loss 1.6363115461915732\n",
      "Index 350 Loss 1.673323553726077\n",
      "Index 400 Loss 2.2571534314751625\n",
      "Index 450 Loss 1.9972845014929772\n",
      "Index 500 Loss 2.2937539184093474\n",
      "Index 550 Loss 1.8701524738967419\n",
      "Predicting..\n",
      "Accuracy: 67.33333333333333 Max Accuracy 69.33333333333334\n",
      "---Epoch 41---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.4265927606076003\n",
      "Index 100 Loss 1.9017230163514613\n",
      "Index 150 Loss 2.198798589557409\n",
      "Index 200 Loss 1.6696752060949802\n",
      "Index 250 Loss 0.8497589629143476\n",
      "Index 300 Loss 1.8345794597268104\n",
      "Index 350 Loss 1.570454409122467\n",
      "Index 400 Loss 2.219821297824383\n",
      "Index 450 Loss 2.2647710502147675\n",
      "Index 500 Loss 2.996595152169466\n",
      "Index 550 Loss 1.7438802942633629\n",
      "Predicting..\n",
      "Accuracy: 69.0 Max Accuracy 69.33333333333334\n",
      "---Epoch 42---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.4852469778060913\n",
      "Index 100 Loss 1.8832270362973214\n",
      "Index 150 Loss 2.147497962862253\n",
      "Index 200 Loss 1.709941576719284\n",
      "Index 250 Loss 0.838494474440813\n",
      "Index 300 Loss 1.9028499276936055\n",
      "Index 350 Loss 1.5175499254465104\n",
      "Index 400 Loss 2.723451821282506\n",
      "Index 450 Loss 2.212415059953928\n",
      "Index 500 Loss 2.1590254774689672\n",
      "Index 550 Loss 1.5130662535130979\n",
      "Predicting..\n",
      "Accuracy: 69.0 Max Accuracy 69.33333333333334\n",
      "---Epoch 43---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.339965377599001\n",
      "Index 100 Loss 1.750818127989769\n",
      "Index 150 Loss 2.349630783498287\n",
      "Index 200 Loss 1.6379159023985266\n",
      "Index 250 Loss 0.8546623276174068\n",
      "Index 300 Loss 1.815741766989231\n",
      "Index 350 Loss 1.6942010930180549\n",
      "Index 400 Loss 1.9268839640915394\n",
      "Index 450 Loss 1.7144116720557212\n",
      "Index 500 Loss 2.1628015978634356\n",
      "Index 550 Loss 1.7402870605140925\n",
      "Predicting..\n",
      "Accuracy: 73.33333333333333 Max Accuracy 73.33333333333333\n",
      "---Epoch 44---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.815252849459648\n",
      "Index 100 Loss 2.138721007704735\n",
      "Index 150 Loss 2.356882237195969\n",
      "Index 200 Loss 1.1567003843188286\n",
      "Index 250 Loss 0.5887383690476418\n",
      "Index 300 Loss 1.633411359488964\n",
      "Index 350 Loss 1.5979192465543748\n",
      "Index 400 Loss 2.239946643412113\n",
      "Index 450 Loss 1.9506414252519608\n",
      "Index 500 Loss 2.176508388966322\n",
      "Index 550 Loss 1.3317050111293793\n",
      "Predicting..\n",
      "Accuracy: 66.83333333333333 Max Accuracy 73.33333333333333\n",
      "---Epoch 45---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.3906197458133103\n",
      "Index 100 Loss 1.678893059641123\n",
      "Index 150 Loss 1.7128933103382586\n",
      "Index 200 Loss 1.0328207935392857\n",
      "Index 250 Loss 0.5171241486817598\n",
      "Index 300 Loss 1.3978189194947481\n",
      "Index 350 Loss 1.5201256009936333\n",
      "Index 400 Loss 2.5139227414131167\n",
      "Index 450 Loss 1.7106599994003773\n",
      "Index 500 Loss 2.1531547468900682\n",
      "Index 550 Loss 1.4263476526737213\n",
      "Predicting..\n",
      "Accuracy: 74.33333333333333 Max Accuracy 74.33333333333333\n",
      "---Epoch 46---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.983244826644659\n",
      "Index 100 Loss 1.577733189687133\n",
      "Index 150 Loss 2.1581401869654657\n",
      "Index 200 Loss 1.2651306244730949\n",
      "Index 250 Loss 0.5022389125265181\n",
      "Index 300 Loss 1.4522974217683078\n",
      "Index 350 Loss 1.8361129798740148\n",
      "Index 400 Loss 2.1882919219136236\n",
      "Index 450 Loss 1.7316785882413388\n",
      "Index 500 Loss 1.858655376434326\n",
      "Index 550 Loss 1.2647652357816697\n",
      "Predicting..\n",
      "Accuracy: 73.83333333333333 Max Accuracy 74.33333333333333\n",
      "---Epoch 47---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.9443726901710034\n",
      "Index 100 Loss 1.7886035573482513\n",
      "Index 150 Loss 1.816460574120283\n",
      "Index 200 Loss 1.2207947048544883\n",
      "Index 250 Loss 0.5386861748620868\n",
      "Index 300 Loss 1.3644324873387814\n",
      "Index 350 Loss 1.505035864636302\n",
      "Index 400 Loss 1.8852426759898662\n",
      "Index 450 Loss 1.572208085656166\n",
      "Index 500 Loss 1.69029118090868\n",
      "Index 550 Loss 1.382727864086628\n",
      "Predicting..\n",
      "Accuracy: 72.83333333333334 Max Accuracy 74.33333333333333\n",
      "---Epoch 48---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.8910684555768966\n",
      "Index 100 Loss 1.6169261516630649\n",
      "Index 150 Loss 1.6458385325968266\n",
      "Index 200 Loss 1.396221159696579\n",
      "Index 250 Loss 0.5903445208072662\n",
      "Index 300 Loss 1.0043352627754212\n",
      "Index 350 Loss 1.5756706330180168\n",
      "Index 400 Loss 2.3141849390417337\n",
      "Index 450 Loss 1.8640438449382781\n",
      "Index 500 Loss 2.0384167462587355\n",
      "Index 550 Loss 1.28286674618721\n",
      "Predicting..\n",
      "Accuracy: 73.83333333333333 Max Accuracy 74.33333333333333\n",
      "---Epoch 49---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.8521735098958017\n",
      "Index 100 Loss 1.5818545771762729\n",
      "Index 150 Loss 1.5794869926571846\n",
      "Index 200 Loss 1.183835127800703\n",
      "Index 250 Loss 0.590705881640315\n",
      "Index 300 Loss 1.2387745776772499\n",
      "Index 350 Loss 1.4398505149036647\n",
      "Index 400 Loss 1.9265760914608836\n",
      "Index 450 Loss 1.7286530059576035\n",
      "Index 500 Loss 1.5813621574640273\n",
      "Index 550 Loss 1.3928098952025174\n",
      "Predicting..\n",
      "Accuracy: 74.5 Max Accuracy 74.5\n",
      "---Epoch 50---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.662891376465559\n",
      "Index 100 Loss 1.528148250952363\n",
      "Index 150 Loss 1.7893990010395646\n",
      "Index 200 Loss 1.3887998181581498\n",
      "Index 250 Loss 0.5795765487849712\n",
      "Index 300 Loss 1.6258824495971202\n",
      "Index 350 Loss 1.8556519737839698\n",
      "Index 400 Loss 2.0596905343234537\n",
      "Index 450 Loss 1.773044076897204\n",
      "Index 500 Loss 1.6200780537724495\n",
      "Index 550 Loss 1.5571617351472378\n",
      "Predicting..\n",
      "Accuracy: 71.66666666666667 Max Accuracy 74.5\n",
      "---Epoch 51---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.079765067845583\n",
      "Index 100 Loss 1.4505722362548112\n",
      "Index 150 Loss 1.594474489465356\n",
      "Index 200 Loss 1.1186219562590123\n",
      "Index 250 Loss 0.5479254996776581\n",
      "Index 300 Loss 1.4132770001888275\n",
      "Index 350 Loss 1.735711563974619\n",
      "Index 400 Loss 1.9721150225400925\n",
      "Index 450 Loss 1.4291846923530103\n",
      "Index 500 Loss 1.7227704986929893\n",
      "Index 550 Loss 1.341690908074379\n",
      "Predicting..\n",
      "Accuracy: 73.83333333333333 Max Accuracy 74.5\n",
      "---Epoch 52---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4735658108443022\n",
      "Index 100 Loss 1.5167467211931944\n",
      "Index 150 Loss 1.6528904372826219\n",
      "Index 200 Loss 1.1351083916425706\n",
      "Index 250 Loss 0.7174184295535088\n",
      "Index 300 Loss 1.234891187250614\n",
      "Index 350 Loss 1.3861098640412093\n",
      "Index 400 Loss 1.766182342544198\n",
      "Index 450 Loss 1.3176855796575546\n",
      "Index 500 Loss 1.8155408319830895\n",
      "Index 550 Loss 1.0805082649737596\n",
      "Predicting..\n",
      "Accuracy: 76.33333333333333 Max Accuracy 76.33333333333333\n",
      "---Epoch 53---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.7684708119183778\n",
      "Index 100 Loss 1.5231570152193308\n",
      "Index 150 Loss 1.967364595234394\n",
      "Index 200 Loss 1.111413436830044\n",
      "Index 250 Loss 0.4176341477036476\n",
      "Index 300 Loss 1.204376479163766\n",
      "Index 350 Loss 1.3297591491043568\n",
      "Index 400 Loss 1.6477135241031646\n",
      "Index 450 Loss 1.5165406699478625\n",
      "Index 500 Loss 1.583251875936985\n",
      "Index 550 Loss 1.1627924805879593\n",
      "Predicting..\n",
      "Accuracy: 75.66666666666667 Max Accuracy 76.33333333333333\n",
      "---Epoch 54---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.6668315154314042\n",
      "Index 100 Loss 1.5658772384375335\n",
      "Index 150 Loss 1.4921031350269913\n",
      "Index 200 Loss 1.097992287352681\n",
      "Index 250 Loss 0.49269340869039296\n",
      "Index 300 Loss 1.1910880599170923\n",
      "Index 350 Loss 1.2102065593004228\n",
      "Index 400 Loss 1.7321104064583779\n",
      "Index 450 Loss 1.6902663025259972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 500 Loss 1.4515743459761143\n",
      "Index 550 Loss 1.2447323723882437\n",
      "Predicting..\n",
      "Accuracy: 75.33333333333333 Max Accuracy 76.33333333333333\n",
      "---Epoch 55---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.631635300256312\n",
      "Index 100 Loss 1.382250092625618\n",
      "Index 150 Loss 1.6392260468006135\n",
      "Index 200 Loss 1.0253857869654894\n",
      "Index 250 Loss 0.43124590400606394\n",
      "Index 300 Loss 1.140376991070807\n",
      "Index 350 Loss 1.176067685186863\n",
      "Index 400 Loss 1.3395071709901094\n",
      "Index 450 Loss 1.3286887465417385\n",
      "Index 500 Loss 1.929704193621874\n",
      "Index 550 Loss 1.2995143616199494\n",
      "Predicting..\n",
      "Accuracy: 75.66666666666667 Max Accuracy 76.33333333333333\n",
      "---Epoch 56---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.5402183204889297\n",
      "Index 100 Loss 1.4731886114180088\n",
      "Index 150 Loss 1.7782043355703354\n",
      "Index 200 Loss 0.911522022113204\n",
      "Index 250 Loss 0.4659833639860153\n",
      "Index 300 Loss 1.067187822163105\n",
      "Index 350 Loss 1.381802463978529\n",
      "Index 400 Loss 1.5719930894300342\n",
      "Index 450 Loss 1.707066018730402\n",
      "Index 500 Loss 1.8029854693636298\n",
      "Index 550 Loss 1.1755918051302432\n",
      "Predicting..\n",
      "Accuracy: 75.0 Max Accuracy 76.33333333333333\n",
      "---Epoch 57---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.8646778663247823\n",
      "Index 100 Loss 1.593051970154047\n",
      "Index 150 Loss 1.6977126568555831\n",
      "Index 200 Loss 0.9058621291816235\n",
      "Index 250 Loss 0.6013892854750157\n",
      "Index 300 Loss 0.9986858443915844\n",
      "Index 350 Loss 1.2954528261721134\n",
      "Index 400 Loss 1.4381067998334764\n",
      "Index 450 Loss 1.6201935911178589\n",
      "Index 500 Loss 1.946067310720682\n",
      "Index 550 Loss 0.9647438329458237\n",
      "Predicting..\n",
      "Accuracy: 77.66666666666666 Max Accuracy 77.66666666666666\n",
      "---Epoch 58---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.6381189918518066\n",
      "Index 100 Loss 1.3950007493048906\n",
      "Index 150 Loss 1.321219832971692\n",
      "Index 200 Loss 0.9345655071362853\n",
      "Index 250 Loss 0.3579632026702166\n",
      "Index 300 Loss 1.0422413400560617\n",
      "Index 350 Loss 1.3496151441335678\n",
      "Index 400 Loss 1.4202539654821158\n",
      "Index 450 Loss 1.8054034081101418\n",
      "Index 500 Loss 1.8236270454525947\n",
      "Index 550 Loss 0.9707527390122414\n",
      "Predicting..\n",
      "Accuracy: 76.33333333333333 Max Accuracy 77.66666666666666\n",
      "---Epoch 59---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.415536455065012\n",
      "Index 100 Loss 1.3059311143308878\n",
      "Index 150 Loss 1.7386359345167874\n",
      "Index 200 Loss 0.9002755872905255\n",
      "Index 250 Loss 0.4322144953906536\n",
      "Index 300 Loss 0.9222596769034862\n",
      "Index 350 Loss 1.6502096112072469\n",
      "Index 400 Loss 1.8213887380063534\n",
      "Index 450 Loss 1.728799535986036\n",
      "Index 500 Loss 2.1379065441340206\n",
      "Index 550 Loss 1.3971672230958938\n",
      "Predicting..\n",
      "Accuracy: 78.0 Max Accuracy 78.0\n",
      "---Epoch 60---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4218960221856833\n",
      "Index 100 Loss 1.2299201376736164\n",
      "Index 150 Loss 1.3725095397233964\n",
      "Index 200 Loss 0.735912731140852\n",
      "Index 250 Loss 0.2957360415160656\n",
      "Index 300 Loss 0.8290689720958472\n",
      "Index 350 Loss 1.1627716217190027\n",
      "Index 400 Loss 1.7684014001488686\n",
      "Index 450 Loss 1.7203375474736093\n",
      "Index 500 Loss 1.700514372587204\n",
      "Index 550 Loss 1.4553825767338275\n",
      "Predicting..\n",
      "Accuracy: 77.5 Max Accuracy 78.0\n",
      "---Epoch 61---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4099190489947795\n",
      "Index 100 Loss 1.4529815766215324\n",
      "Index 150 Loss 1.387397009730339\n",
      "Index 200 Loss 0.8362266631424426\n",
      "Index 250 Loss 0.3204058817028999\n",
      "Index 300 Loss 0.819153011017479\n",
      "Index 350 Loss 1.1189669089019298\n",
      "Index 400 Loss 1.655711227580905\n",
      "Index 450 Loss 1.234280935972929\n",
      "Index 500 Loss 1.6831026023626328\n",
      "Index 550 Loss 1.3436598720774056\n",
      "Predicting..\n",
      "Accuracy: 77.5 Max Accuracy 78.0\n",
      "---Epoch 62---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.863118873462081\n",
      "Index 100 Loss 1.3587136070616543\n",
      "Index 150 Loss 1.4108742755278945\n",
      "Index 200 Loss 0.9050085970759392\n",
      "Index 250 Loss 0.3824232668802142\n",
      "Index 300 Loss 0.9360190379992127\n",
      "Index 350 Loss 1.169670478925109\n",
      "Index 400 Loss 1.719837836176157\n",
      "Index 450 Loss 1.2507344188913703\n",
      "Index 500 Loss 1.2987103652954102\n",
      "Index 550 Loss 1.2901890254020691\n",
      "Predicting..\n",
      "Accuracy: 77.0 Max Accuracy 78.0\n",
      "---Epoch 63---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.5188806109875441\n",
      "Index 100 Loss 1.289600451681763\n",
      "Index 150 Loss 1.4330009657889604\n",
      "Index 200 Loss 0.7318871710449457\n",
      "Index 250 Loss 0.3947957903146744\n",
      "Index 300 Loss 0.9306881481409073\n",
      "Index 350 Loss 1.1032762444764375\n",
      "Index 400 Loss 1.4887829834222794\n",
      "Index 450 Loss 1.0598288233578206\n",
      "Index 500 Loss 1.297472047302872\n",
      "Index 550 Loss 1.049924268722534\n",
      "Predicting..\n",
      "Accuracy: 76.83333333333333 Max Accuracy 78.0\n",
      "---Epoch 64---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.8252149099484085\n",
      "Index 100 Loss 1.4839404314756393\n",
      "Index 150 Loss 1.2407502641528845\n",
      "Index 200 Loss 0.9539490473270417\n",
      "Index 250 Loss 0.47068923003971574\n",
      "Index 300 Loss 1.3071269266307355\n",
      "Index 350 Loss 0.9233970394730568\n",
      "Index 400 Loss 1.5192225749790669\n",
      "Index 450 Loss 1.0666078519821167\n",
      "Index 500 Loss 1.258929594270885\n",
      "Index 550 Loss 1.0299957233900203\n",
      "Predicting..\n",
      "Accuracy: 78.16666666666666 Max Accuracy 78.16666666666666\n",
      "---Epoch 65---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.3334328320622444\n",
      "Index 100 Loss 1.098012784421444\n",
      "Index 150 Loss 1.183542132154107\n",
      "Index 200 Loss 0.8277555863186717\n",
      "Index 250 Loss 0.31258949272334574\n",
      "Index 300 Loss 0.983445555344224\n",
      "Index 350 Loss 1.0958524083718657\n",
      "Index 400 Loss 1.4792767484486102\n",
      "Index 450 Loss 0.9974174617230892\n",
      "Index 500 Loss 1.288852994441986\n",
      "Index 550 Loss 0.8773361953347921\n",
      "Predicting..\n",
      "Accuracy: 80.0 Max Accuracy 80.0\n",
      "---Epoch 66---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.2524036446213722\n",
      "Index 100 Loss 1.1587808508425952\n",
      "Index 150 Loss 1.2359493576735259\n",
      "Index 200 Loss 0.776683611869812\n",
      "Index 250 Loss 0.3259881993383169\n",
      "Index 300 Loss 0.6916458640992641\n",
      "Index 350 Loss 0.9610445675440132\n",
      "Index 400 Loss 1.310243996679783\n",
      "Index 450 Loss 1.0539475079625844\n",
      "Index 500 Loss 1.135540650486946\n",
      "Index 550 Loss 1.0243262918293476\n",
      "Predicting..\n",
      "Accuracy: 78.33333333333333 Max Accuracy 80.0\n",
      "---Epoch 67---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.3577767118811608\n",
      "Index 100 Loss 1.0928340823948384\n",
      "Index 150 Loss 1.4875339621305466\n",
      "Index 200 Loss 0.8522145023941994\n",
      "Index 250 Loss 0.4206209276616573\n",
      "Index 300 Loss 0.6285661725699901\n",
      "Index 350 Loss 0.93614262573421\n",
      "Index 400 Loss 1.1120044664293527\n",
      "Index 450 Loss 1.2628122160956263\n",
      "Index 500 Loss 1.1303017112612723\n",
      "Index 550 Loss 0.8906748428195715\n",
      "Predicting..\n",
      "Accuracy: 79.5 Max Accuracy 80.0\n",
      "---Epoch 68---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.3639322622865437\n",
      "Index 100 Loss 1.3946634832024574\n",
      "Index 150 Loss 1.2243327824771404\n",
      "Index 200 Loss 0.7961344888806343\n",
      "Index 250 Loss 0.22433514133095742\n",
      "Index 300 Loss 0.8079966404289007\n",
      "Index 350 Loss 0.9185063168406487\n",
      "Index 400 Loss 1.2756938895583152\n",
      "Index 450 Loss 1.1219827301800251\n",
      "Index 500 Loss 1.305483876168728\n",
      "Index 550 Loss 0.8112328007817269\n",
      "Predicting..\n",
      "Accuracy: 81.83333333333334 Max Accuracy 81.83333333333334\n",
      "---Epoch 69---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.0736724741384387\n",
      "Index 100 Loss 1.0783549206703902\n",
      "Index 150 Loss 1.0734631118178368\n",
      "Index 200 Loss 0.8177164004743099\n",
      "Index 250 Loss 0.231791273355484\n",
      "Index 300 Loss 0.9577239422127605\n",
      "Index 350 Loss 0.9222880930453539\n",
      "Index 400 Loss 1.2897992897033692\n",
      "Index 450 Loss 1.034122724235058\n",
      "Index 500 Loss 1.0607315012812615\n",
      "Index 550 Loss 0.6474921020865441\n",
      "Predicting..\n",
      "Accuracy: 80.66666666666666 Max Accuracy 81.83333333333334\n",
      "---Epoch 70---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.9207589846849441\n",
      "Index 100 Loss 0.971385840177536\n",
      "Index 150 Loss 0.9212304317951202\n",
      "Index 200 Loss 0.6460598057880997\n",
      "Index 250 Loss 0.38223005771636964\n",
      "Index 300 Loss 0.5919995065778494\n",
      "Index 350 Loss 0.8389902070164681\n",
      "Index 400 Loss 1.1204239650815726\n",
      "Index 450 Loss 0.8477049103379249\n",
      "Index 500 Loss 1.0261463776230813\n",
      "Index 550 Loss 1.0155753856152296\n",
      "Predicting..\n",
      "Accuracy: 81.16666666666667 Max Accuracy 81.83333333333334\n",
      "---Epoch 71---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.214436329677701\n",
      "Index 100 Loss 1.2740694391727447\n",
      "Index 150 Loss 1.0803287912905217\n",
      "Index 200 Loss 0.6366595620010048\n",
      "Index 250 Loss 0.26073975808918476\n",
      "Index 300 Loss 0.6005285582691431\n",
      "Index 350 Loss 0.8565285012871027\n",
      "Index 400 Loss 1.1788179877400398\n",
      "Index 450 Loss 0.8861171944439411\n",
      "Index 500 Loss 0.9553557154536247\n",
      "Index 550 Loss 0.6012743103504181\n",
      "Predicting..\n",
      "Accuracy: 84.0 Max Accuracy 84.0\n",
      "---Epoch 72---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.8215798330307007\n",
      "Index 100 Loss 1.2189537805318833\n",
      "Index 150 Loss 0.9017075752047822\n",
      "Index 200 Loss 0.6994842426478862\n",
      "Index 250 Loss 0.20825678635388611\n",
      "Index 300 Loss 0.9396096317470074\n",
      "Index 350 Loss 1.034884197488427\n",
      "Index 400 Loss 1.428516187518835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 450 Loss 0.8058886916935444\n",
      "Index 500 Loss 1.0665354489535093\n",
      "Index 550 Loss 0.7910762571543455\n",
      "Predicting..\n",
      "Accuracy: 81.5 Max Accuracy 84.0\n",
      "---Epoch 73---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.0412812910974025\n",
      "Index 100 Loss 1.0181272365152836\n",
      "Index 150 Loss 0.9273949883133173\n",
      "Index 200 Loss 0.5626162414252758\n",
      "Index 250 Loss 0.3338226106017828\n",
      "Index 300 Loss 1.149529070854187\n",
      "Index 350 Loss 0.7832854217290879\n",
      "Index 400 Loss 1.1975147091597318\n",
      "Index 450 Loss 0.9325569921731949\n",
      "Index 500 Loss 1.0362485575675964\n",
      "Index 550 Loss 0.7196508722938597\n",
      "Predicting..\n",
      "Accuracy: 82.0 Max Accuracy 84.0\n",
      "---Epoch 74---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.9363411308825016\n",
      "Index 100 Loss 0.8997220373339951\n",
      "Index 150 Loss 1.1160902282595635\n",
      "Index 200 Loss 0.6125768936797976\n",
      "Index 250 Loss 0.23946116536855697\n",
      "Index 300 Loss 0.8997005689889193\n",
      "Index 350 Loss 1.071540941298008\n",
      "Index 400 Loss 1.1174194356799125\n",
      "Index 450 Loss 0.952515535056591\n",
      "Index 500 Loss 1.2168913081288337\n",
      "Index 550 Loss 0.6724256294965744\n",
      "Predicting..\n",
      "Accuracy: 83.16666666666667 Max Accuracy 84.0\n",
      "---Epoch 75---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.8247991833090782\n",
      "Index 100 Loss 0.8193637850880623\n",
      "Index 150 Loss 0.7290913935005665\n",
      "Index 200 Loss 0.6282161805033684\n",
      "Index 250 Loss 0.21495768509805202\n",
      "Index 300 Loss 0.5409056388586759\n",
      "Index 350 Loss 1.003515199869871\n",
      "Index 400 Loss 1.249662195444107\n",
      "Index 450 Loss 0.7683826990425586\n",
      "Index 500 Loss 1.1097313645482063\n",
      "Index 550 Loss 0.700302817672491\n",
      "Predicting..\n",
      "Accuracy: 84.66666666666667 Max Accuracy 84.66666666666667\n",
      "---Epoch 76---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.7511286824941635\n",
      "Index 100 Loss 0.7950486153364181\n",
      "Index 150 Loss 0.7059413734078407\n",
      "Index 200 Loss 0.5135768480598927\n",
      "Index 250 Loss 0.17132687717676162\n",
      "Index 300 Loss 0.6235016027837992\n",
      "Index 350 Loss 0.9334614223241806\n",
      "Index 400 Loss 1.0513835690915585\n",
      "Index 450 Loss 0.7913766577839851\n",
      "Index 500 Loss 1.0289540727436544\n",
      "Index 550 Loss 0.7375266774743795\n",
      "Predicting..\n",
      "Accuracy: 83.83333333333334 Max Accuracy 84.66666666666667\n",
      "---Epoch 77---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.219191326647997\n",
      "Index 100 Loss 0.8542726502567529\n",
      "Index 150 Loss 0.9150227946043015\n",
      "Index 200 Loss 0.48405353009700774\n",
      "Index 250 Loss 0.27685467004776\n",
      "Index 300 Loss 1.1343439458683133\n",
      "Index 350 Loss 0.6915036393329501\n",
      "Index 400 Loss 1.1718192917108536\n",
      "Index 450 Loss 1.0457590359449387\n",
      "Index 500 Loss 1.1788644230365752\n",
      "Index 550 Loss 0.6582949776947499\n",
      "Predicting..\n",
      "Accuracy: 85.16666666666667 Max Accuracy 85.16666666666667\n",
      "---Epoch 78---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.9192767487466336\n",
      "Index 100 Loss 0.9585155905783176\n",
      "Index 150 Loss 0.8089992222189903\n",
      "Index 200 Loss 0.538664935529232\n",
      "Index 250 Loss 0.6083365904539824\n",
      "Index 300 Loss 0.5304969412088394\n",
      "Index 350 Loss 0.604957853257656\n",
      "Index 400 Loss 0.89363464333117\n",
      "Index 450 Loss 0.5641793218255043\n",
      "Index 500 Loss 0.7692109598219394\n",
      "Index 550 Loss 0.746697053015232\n",
      "Predicting..\n",
      "Accuracy: 84.5 Max Accuracy 85.16666666666667\n",
      "---Epoch 79---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6052357263863086\n",
      "Index 100 Loss 0.8722197772562503\n",
      "Index 150 Loss 0.8941609137505293\n",
      "Index 200 Loss 0.5133433967828751\n",
      "Index 250 Loss 0.1320020252466202\n",
      "Index 300 Loss 0.5460016697645187\n",
      "Index 350 Loss 0.593101893872954\n",
      "Index 400 Loss 0.7662760808318854\n",
      "Index 450 Loss 0.7686585247516632\n",
      "Index 500 Loss 0.7891774106025696\n",
      "Index 550 Loss 0.5286049267649651\n",
      "Predicting..\n",
      "Accuracy: 85.66666666666667 Max Accuracy 85.66666666666667\n",
      "---Epoch 80---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.806442582309246\n",
      "Index 100 Loss 0.6691696333140135\n",
      "Index 150 Loss 0.7919376376271248\n",
      "Index 200 Loss 0.4853955149650574\n",
      "Index 250 Loss 0.1881065545231104\n",
      "Index 300 Loss 0.5668217644095421\n",
      "Index 350 Loss 0.6818156969547272\n",
      "Index 400 Loss 1.2189558541402221\n",
      "Index 450 Loss 0.7558811753615737\n",
      "Index 500 Loss 1.0331008446216583\n",
      "Index 550 Loss 0.4630924381315708\n",
      "Predicting..\n",
      "Accuracy: 87.16666666666667 Max Accuracy 87.16666666666667\n",
      "---Epoch 81---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6672806923091411\n",
      "Index 100 Loss 0.8411824465356768\n",
      "Index 150 Loss 0.6952769273519516\n",
      "Index 200 Loss 0.3930630734562874\n",
      "Index 250 Loss 0.16365248553454875\n",
      "Index 300 Loss 0.44191226720809934\n",
      "Index 350 Loss 0.7244288592040539\n",
      "Index 400 Loss 1.0922676250338554\n",
      "Index 450 Loss 0.7003298890590668\n",
      "Index 500 Loss 0.8624371545761824\n",
      "Index 550 Loss 0.4375274781882763\n",
      "Predicting..\n",
      "Accuracy: 87.33333333333333 Max Accuracy 87.33333333333333\n",
      "---Epoch 82---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6645840245485306\n",
      "Index 100 Loss 0.6979677125066519\n",
      "Index 150 Loss 0.5623852878063917\n",
      "Index 200 Loss 0.45649297297000885\n",
      "Index 250 Loss 0.1931349628418684\n",
      "Index 300 Loss 0.4068120213225484\n",
      "Index 350 Loss 0.5502176574617624\n",
      "Index 400 Loss 0.8661523598432541\n",
      "Index 450 Loss 0.7452077841758729\n",
      "Index 500 Loss 0.8149718964099884\n",
      "Index 550 Loss 0.577604207098484\n",
      "Predicting..\n",
      "Accuracy: 84.5 Max Accuracy 87.33333333333333\n",
      "---Epoch 83---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.7536273396015167\n",
      "Index 100 Loss 0.6229816353321076\n",
      "Index 150 Loss 0.5927846840769052\n",
      "Index 200 Loss 0.5146088158339261\n",
      "Index 250 Loss 0.12065572530031204\n",
      "Index 300 Loss 0.28553502276539805\n",
      "Index 350 Loss 0.6262720626220107\n",
      "Index 400 Loss 1.06328601077199\n",
      "Index 450 Loss 0.6959147214889526\n",
      "Index 500 Loss 0.7671305104345083\n",
      "Index 550 Loss 0.5177143989503383\n",
      "Predicting..\n",
      "Accuracy: 87.33333333333333 Max Accuracy 87.33333333333333\n",
      "---Epoch 84---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.5489396797865629\n",
      "Index 100 Loss 0.5838062199950218\n",
      "Index 150 Loss 0.6765567363053561\n",
      "Index 200 Loss 0.4563062101602554\n",
      "Index 250 Loss 0.0867925164848566\n",
      "Index 300 Loss 0.3047143232822418\n",
      "Index 350 Loss 0.8105035777390003\n",
      "Index 400 Loss 0.9468316227197647\n",
      "Index 450 Loss 0.8764318591356277\n",
      "Index 500 Loss 0.965090990960598\n",
      "Index 550 Loss 0.42862039551138875\n",
      "Predicting..\n",
      "Accuracy: 86.66666666666667 Max Accuracy 87.33333333333333\n",
      "---Epoch 85---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6826020959019661\n",
      "Index 100 Loss 0.742657944560051\n",
      "Index 150 Loss 0.8034444432705641\n",
      "Index 200 Loss 0.3870984864234924\n",
      "Index 250 Loss 0.10330497831106186\n",
      "Index 300 Loss 0.3129314036667347\n",
      "Index 350 Loss 0.5845522410050035\n",
      "Index 400 Loss 0.7646388275921345\n",
      "Index 450 Loss 0.5403027813136577\n",
      "Index 500 Loss 0.9686009261012077\n",
      "Index 550 Loss 0.4570914667844772\n",
      "Predicting..\n",
      "Accuracy: 88.16666666666667 Max Accuracy 88.16666666666667\n",
      "---Epoch 86---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6593513918668031\n",
      "Index 100 Loss 0.7187660551071167\n",
      "Index 150 Loss 0.8635647410154342\n",
      "Index 200 Loss 0.4215538707375526\n",
      "Index 250 Loss 0.09250119388103485\n",
      "Index 300 Loss 0.44560969112440946\n",
      "Index 350 Loss 0.5754233425855637\n",
      "Index 400 Loss 0.8353415575716645\n",
      "Index 450 Loss 0.7255085894465446\n",
      "Index 500 Loss 0.6218992602825165\n",
      "Index 550 Loss 0.3759663727506995\n",
      "Predicting..\n",
      "Accuracy: 85.83333333333333 Max Accuracy 88.16666666666667\n",
      "---Epoch 87---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6454650218784809\n",
      "Index 100 Loss 0.6855488193035125\n",
      "Index 150 Loss 0.6378694106638432\n",
      "Index 200 Loss 0.40615496270358564\n",
      "Index 250 Loss 0.1207833893597126\n",
      "Index 300 Loss 0.44340434804558754\n",
      "Index 350 Loss 0.6003644758462906\n",
      "Index 400 Loss 1.1236163827776908\n",
      "Index 450 Loss 0.6379121953248977\n",
      "Index 500 Loss 0.5726312619447708\n",
      "Index 550 Loss 0.49833430141210555\n",
      "Predicting..\n",
      "Accuracy: 89.66666666666666 Max Accuracy 89.66666666666666\n",
      "---Epoch 88---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.5404517089296133\n",
      "Index 100 Loss 0.54514832213521\n",
      "Index 150 Loss 0.6157512724399566\n",
      "Index 200 Loss 0.39715232871472833\n",
      "Index 250 Loss 0.13548137836158275\n",
      "Index 300 Loss 0.2986131897568703\n",
      "Index 350 Loss 0.43151751428842544\n",
      "Index 400 Loss 0.7472034192085266\n",
      "Index 450 Loss 0.48965902216732504\n",
      "Index 500 Loss 0.7220559546351433\n",
      "Index 550 Loss 0.5346785843372345\n",
      "Predicting..\n",
      "Accuracy: 88.16666666666667 Max Accuracy 89.66666666666666\n",
      "---Epoch 89---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6973357039410621\n",
      "Index 100 Loss 0.636869600713253\n",
      "Index 150 Loss 0.503999050706625\n",
      "Index 200 Loss 0.36420540638267995\n",
      "Index 250 Loss 0.06926602602005005\n",
      "Index 300 Loss 0.4667384262336418\n",
      "Index 350 Loss 0.40031286239624025\n",
      "Index 400 Loss 0.8371962292119861\n",
      "Index 450 Loss 0.622282432615757\n",
      "Index 500 Loss 0.5624733734130859\n",
      "Index 550 Loss 0.35122932761907577\n",
      "Predicting..\n",
      "Accuracy: 88.83333333333333 Max Accuracy 89.66666666666666\n",
      "---Epoch 90---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.5826477116346359\n",
      "Index 100 Loss 0.5211330616474151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 150 Loss 0.48626781195402147\n",
      "Index 200 Loss 0.5822588342428208\n",
      "Index 250 Loss 0.21947176933288573\n",
      "Index 300 Loss 0.3068792118877173\n",
      "Index 350 Loss 0.39048449993133544\n",
      "Index 400 Loss 0.6295893357694149\n",
      "Index 450 Loss 0.5188748905062676\n",
      "Index 500 Loss 0.6390524123609066\n",
      "Index 550 Loss 0.27665542270988225\n",
      "Predicting..\n",
      "Accuracy: 90.16666666666666 Max Accuracy 90.16666666666666\n",
      "---Epoch 91---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6129041120409966\n",
      "Index 100 Loss 0.5023269996792078\n",
      "Index 150 Loss 0.5330218122154474\n",
      "Index 200 Loss 0.36090585559606553\n",
      "Index 250 Loss 0.11604600310325623\n",
      "Index 300 Loss 0.4246287904307246\n",
      "Index 350 Loss 0.5221255350112916\n",
      "Index 400 Loss 0.7066303116083145\n",
      "Index 450 Loss 0.5293475347012282\n",
      "Index 500 Loss 0.6839321202039719\n",
      "Index 550 Loss 0.2238583093881607\n",
      "Predicting..\n",
      "Accuracy: 90.5 Max Accuracy 90.5\n",
      "---Epoch 92---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.36333993980661033\n",
      "Index 100 Loss 0.7295299792289733\n",
      "Index 150 Loss 0.6189747361838818\n",
      "Index 200 Loss 0.3580424251407385\n",
      "Index 250 Loss 0.10894061014056206\n",
      "Index 300 Loss 0.5091015735268593\n",
      "Index 350 Loss 0.44670565545558927\n",
      "Index 400 Loss 0.7918740126490593\n",
      "Index 450 Loss 0.5075509926129598\n",
      "Index 500 Loss 0.6128269210457802\n",
      "Index 550 Loss 0.42367096230387685\n",
      "Predicting..\n",
      "Accuracy: 89.33333333333333 Max Accuracy 90.5\n",
      "---Epoch 93---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.4032217264175415\n",
      "Index 100 Loss 0.7207904522120953\n",
      "Index 150 Loss 0.6198643708229065\n",
      "Index 200 Loss 0.34544595509767534\n",
      "Index 250 Loss 0.115959193110466\n",
      "Index 300 Loss 0.2763073305040598\n",
      "Index 350 Loss 0.37755268707871437\n",
      "Index 400 Loss 0.8398397150635719\n",
      "Index 450 Loss 0.4663649436831474\n",
      "Index 500 Loss 0.740281423330307\n",
      "Index 550 Loss 0.3517426645755768\n",
      "Predicting..\n",
      "Accuracy: 89.0 Max Accuracy 90.5\n",
      "---Epoch 94---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.4612229809165001\n",
      "Index 100 Loss 0.5166502922773362\n",
      "Index 150 Loss 0.5092599448934197\n",
      "Index 200 Loss 0.29670898377895355\n",
      "Index 250 Loss 0.058392519578337666\n",
      "Index 300 Loss 0.5021568241715432\n",
      "Index 350 Loss 0.7018683066219091\n",
      "Index 400 Loss 0.6447081452608109\n",
      "Index 450 Loss 0.6210833850502968\n",
      "Index 500 Loss 0.8605932313203811\n",
      "Index 550 Loss 0.4264608170837164\n",
      "Predicting..\n",
      "Accuracy: 90.0 Max Accuracy 90.5\n",
      "---Epoch 95---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.4069482532143593\n",
      "Index 100 Loss 0.5067922233045101\n",
      "Index 150 Loss 0.6351590349897742\n",
      "Index 200 Loss 0.2569591671228409\n",
      "Index 250 Loss 0.05458763748407364\n",
      "Index 300 Loss 0.19012151554226875\n",
      "Index 350 Loss 0.577161248922348\n",
      "Index 400 Loss 0.7381163963675499\n",
      "Index 450 Loss 0.4256221529841423\n",
      "Index 500 Loss 0.8036782875657081\n",
      "Index 550 Loss 0.30802993558347225\n",
      "Predicting..\n",
      "Accuracy: 89.83333333333333 Max Accuracy 90.5\n",
      "---Epoch 96---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.37588048189878465\n",
      "Index 100 Loss 0.6698986729979515\n",
      "Index 150 Loss 0.5617318780906498\n",
      "Index 200 Loss 0.2996473501622677\n",
      "Index 250 Loss 0.0931539099663496\n",
      "Index 300 Loss 0.16977796524763109\n",
      "Index 350 Loss 0.414071954600513\n",
      "Index 400 Loss 0.5138156222365796\n",
      "Index 450 Loss 0.6494025510549545\n",
      "Index 500 Loss 0.7519252166152001\n",
      "Index 550 Loss 0.27343181788921356\n",
      "Predicting..\n",
      "Accuracy: 91.33333333333333 Max Accuracy 91.33333333333333\n",
      "---Epoch 97---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.3213006201386452\n",
      "Index 100 Loss 0.48641916662454604\n",
      "Index 150 Loss 0.7541505721211433\n",
      "Index 200 Loss 0.26899662379175426\n",
      "Index 250 Loss 0.08476288996636867\n",
      "Index 300 Loss 0.19282399266958236\n",
      "Index 350 Loss 0.44623866541311147\n",
      "Index 400 Loss 0.5729583869501949\n",
      "Index 450 Loss 0.45583980441093447\n",
      "Index 500 Loss 0.5912647799029946\n",
      "Index 550 Loss 0.41589442268013954\n",
      "Predicting..\n",
      "Accuracy: 89.33333333333333 Max Accuracy 91.33333333333333\n",
      "---Epoch 98---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.3443204428255558\n",
      "Index 100 Loss 0.6539512932673097\n",
      "Index 150 Loss 0.637905253469944\n",
      "Index 200 Loss 0.33995758116245267\n",
      "Index 250 Loss 0.10523575756698847\n",
      "Index 300 Loss 0.6478008302673698\n",
      "Index 350 Loss 0.5712887479364872\n",
      "Index 400 Loss 0.4959129546582699\n",
      "Index 450 Loss 0.44623690158128737\n",
      "Index 500 Loss 0.47169148564338687\n",
      "Index 550 Loss 0.31712878540158274\n",
      "Predicting..\n",
      "Accuracy: 92.5 Max Accuracy 92.5\n",
      "---Epoch 99---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.2585802306234837\n",
      "Index 100 Loss 0.37179977893829347\n",
      "Index 150 Loss 0.4096317668259144\n",
      "Index 200 Loss 0.22239661261439322\n",
      "Index 250 Loss 0.16015918489545583\n",
      "Index 300 Loss 0.1549828454479575\n",
      "Index 350 Loss 0.4708949446678162\n",
      "Index 400 Loss 0.7223439237475395\n",
      "Index 450 Loss 0.5731268298625946\n",
      "Index 500 Loss 0.6559341073036193\n",
      "Index 550 Loss 0.4051952490955591\n",
      "Predicting..\n",
      "Accuracy: 92.83333333333333 Max Accuracy 92.83333333333333\n",
      "---Epoch 100---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.30682700157165527\n",
      "Index 100 Loss 0.3803631423786282\n",
      "Index 150 Loss 0.4127884015440941\n",
      "Index 200 Loss 0.3255984252691269\n",
      "Index 250 Loss 0.2300740297138691\n",
      "Index 300 Loss 0.22616963669657708\n",
      "Index 350 Loss 0.3533185186982155\n",
      "Index 400 Loss 0.6312823939323425\n",
      "Index 450 Loss 0.36138426199555396\n",
      "Index 500 Loss 0.5558450052002445\n",
      "Index 550 Loss 0.2614341878145933\n",
      "Predicting..\n",
      "Accuracy: 91.83333333333333 Max Accuracy 92.83333333333333\n"
     ]
    }
   ],
   "source": [
    "train_and_test(100, \"out/WithGradientClippingAndLearningRateDecay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maximum Accuracy 2.79 at epoch 10'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Maximum Accuracy {0:.2f} at epoch {1}\".format(2.7888, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
