{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#files\n",
    "TEST_FILE = \"data/test.txt\"\n",
    "TRAIN_FILE = \"data/train.txt\"\n",
    "F_VOCAB_FILE = \"data/vocab.f.txt\"\n",
    "Q_VOCAB_FILE = \"data/vocab.q.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dynet_config\n",
    "# Declare GPU as the default device type\n",
    "dynet_config.set_gpu()\n",
    "# Set some parameters manualy\n",
    "dynet_config.set(mem=400, random_seed=123456789)\n",
    "# Initialize dynet import using above configuration in the current scope\n",
    "import dynet as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnnl import RNNSequencePredictor\n",
    "import random\n",
    "random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fh):\n",
    "    for line in fh:\n",
    "        sentence, lf = line.strip().split(\"\\t\")\n",
    "        sentence = sentence.split()\n",
    "        lf = lf.split()\n",
    "        yield sentence, lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(filename):\n",
    "    t2i = {\"_UNK\": 0, \"<s>\": 1, \"</s>\":2}\n",
    "    with open(filename) as target:\n",
    "        for line in target:\n",
    "            token = line.strip().split()[0]\n",
    "            if token not in t2i:\n",
    "                t2i[token] = len(t2i)\n",
    "    return t2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self, w2i, lf2i, options):\n",
    "        self.options = options\n",
    "        self.w2i = w2i\n",
    "        self.lf2i = lf2i\n",
    "        self.i2lf = {lf2i[lf]:lf for lf in lf2i}\n",
    "        self.wdims = options.wembedding_dims\n",
    "        self.lfdims = options.lfembedding_dims\n",
    "        self.ldims = options.lstm_dims\n",
    "        self.ext_embeddings = None\n",
    "        \n",
    "        self.model = dy.ParameterCollection()\n",
    "        self.trainer = dy.AdamTrainer(self.model)\n",
    "        self.__load_model()\n",
    "        self.wlookup = self.model.add_lookup_parameters((len(w2i), self.wdims))\n",
    "        self.lflookup = self.model.add_lookup_parameters((len(lf2i), self.lfdims))\n",
    "\n",
    "        self.context_encoder = [dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model)]\n",
    "        self.logical_form_decoder = dy.VanillaLSTMBuilder(1, self.lfdims, self.ldims, self.model)\n",
    "        \n",
    "        self.W_s = self.model.add_parameters((len(self.lf2i), self.ldims))\n",
    "        self.W_sb = self.model.add_parameters((len(self.lf2i)))\n",
    "    \n",
    "    def __load_model(self):\n",
    "        if self.options.external_embedding is not None:\n",
    "            if os.path.isfile(os.path.join(self.options.saved_parameters_dir,\n",
    "                                           self.options.saved_prevectors)):\n",
    "                self.__load_external_embeddings(os.path.join(self.options.saved_parameters_dir,\n",
    "                                                             self.options.saved_prevectors),\n",
    "                                                \"pickle\")\n",
    "            else:\n",
    "                self.__load_external_embeddings(self.options.external_embedding,\n",
    "                                                self.options.external_embedding_type)\n",
    "                self.__save_model()\n",
    "    \n",
    "    def __save_model(self):\n",
    "        IOUtils.save_embeddings(os.path.join(self.options.saved_parameters_dir,\n",
    "                                             self.options.saved_prevectors),\n",
    "                                self.ext_embeddings)\n",
    "\n",
    "    def __load_external_embeddings(self, embedding_file, embedding_file_type):\n",
    "        ext_embeddings, ext_emb_dim = IOUtils.load_embeddings_file(\n",
    "            embedding_file,\n",
    "            embedding_file_type,\n",
    "            lower=True)\n",
    "        assert ext_emb_dim == self.wdims\n",
    "        self.ext_embeddings = {}\n",
    "        print(\"Initializing word embeddings by pre-trained vectors\")\n",
    "        count = 0\n",
    "        for word in self.w2i:\n",
    "            if word in ext_embeddings:\n",
    "                count += 1\n",
    "                self.ext_embeddings[word] = ext_embeddings[word]\n",
    "                self.wlookup.init_row(self.w2i[word], ext_embeddings[word])\n",
    "        print(\"Vocab size: %d; #words having pretrained vectors: %d\" % (len(self.w2i), count))\n",
    "    \n",
    "    \n",
    "    def predict(self, test_path, test_num):\n",
    "        with open(test_path, 'r') as test:\n",
    "            for _, (iPair, (sentence, lf)) in zip(range(test_num), enumerate(read_data(test))):\n",
    "                dy.renew_cg() \n",
    "                print(iPair, sentence)\n",
    "                state = self.context_encoder[0].initial_state()\n",
    "            \n",
    "                for entry in sentence:\n",
    "                    if entry not in self.w2i:\n",
    "                        print(\"Entry {} does not exist\\n\".format(entry))\n",
    "                    state = state.add_input(self.wlookup[self.w2i[entry] if entry in self.w2i else self.w2i['_UNK']])                                          \n",
    "                hidden_context = state.h()\n",
    "                state = self.logical_form_decoder.initial_state()\n",
    "                state.set_h(hidden_context)\n",
    "                predicted_sequence = []\n",
    "                next_input = self.lf2i[\"<s>\"]\n",
    "                counter = 0\n",
    "                while True:\n",
    "                    counter += 1\n",
    "                    state = state.add_input(self.lflookup[next_input])\n",
    "                    probs = dy.softmax(self.W_s * state.output() + self.W_sb)\n",
    "                    next_input = probs.npvalue().argmax()\n",
    "                    if next_input != self.lf2i[\"</s>\"] and counter < 50:\n",
    "                        predicted_sequence.append(next_input)\n",
    "                    else:\n",
    "                        break\n",
    "                print(\"Index {}\\nOriginal : {}\\nPrediction {}\\n\\n\\n\".format(iPair, lf, \" \".join(self.i2lf[c] for c in predicted_sequence)))\n",
    "                \n",
    "                    \n",
    "                    \n",
    "    def train(self, train_path):\n",
    "        total_loss = 0\n",
    "        with open(train_path, 'r') as train:\n",
    "            shuffledData = list(read_data(train))\n",
    "            random.shuffle(shuffledData)\n",
    "            \n",
    "            for iPair, (sentence, lf) in enumerate(shuffledData):\n",
    "                #I-Context Encoding\n",
    "                state = self.context_encoder[0].initial_state()\n",
    "            \n",
    "                for entry in sentence:\n",
    "                    state = state.add_input(self.wlookup[self.w2i[entry] if entry in self.w2i else self.w2i['_UNK']])                                          \n",
    "                hidden_context = state.h()\n",
    "                \n",
    "                state = self.logical_form_decoder.initial_state()\n",
    "                state.set_h(hidden_context)\n",
    "                decoder_in = [self.lf2i[\"<s>\"]] + [self.lf2i[i] if i in self.lf2i else self.lf2i['_UNK'] for i in lf]\n",
    "                decoder_out = [self.lf2i[i] if i in self.lf2i else self.lf2i['_UNK'] for i in lf] + [self.lf2i[\"</s>\"]]\n",
    "                probs = []\n",
    "                for i in decoder_in:\n",
    "                    state = state.add_input(self.lflookup[i])\n",
    "                    p = dy.softmax(self.W_s * state.output() + self.W_sb)\n",
    "                    probs.append(p)\n",
    "                loss = [-dy.log(dy.pick(p, o)) for p, o in zip(probs, decoder_out)]\n",
    "                loss = dy.esum(loss)\n",
    "                cur_loss = loss.scalar_value()\n",
    "                total_loss += cur_loss\n",
    "                loss.backward()\n",
    "                self.trainer.update()\n",
    "                if iPair != 0 and iPair % 10 == 0:\n",
    "                    print(\"Pair:\" + str(iPair) + \" Loss:\" + str(total_loss / (iPair + 1)))\n",
    "                \n",
    "                dy.renew_cg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.wembedding_dims = 300\n",
    "        self.lfembedding_dims = 64\n",
    "        self.lstm_dims = 128\n",
    "        self.external_embedding = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = read_vocab(Q_VOCAB_FILE)\n",
    "lf2i = read_vocab(F_VOCAB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair:10 Loss:68.7444014115767\n",
      "Pair:20 Loss:65.63372811816987\n",
      "Pair:30 Loss:58.14587789966214\n",
      "Pair:40 Loss:57.88414987703649\n",
      "Pair:50 Loss:54.927369342130774\n",
      "Pair:60 Loss:54.656258786310914\n",
      "Pair:70 Loss:52.05173723462602\n",
      "Pair:80 Loss:52.03498049135561\n",
      "Pair:90 Loss:49.68558443509615\n",
      "Pair:100 Loss:48.604320866046564\n",
      "Pair:110 Loss:47.90536575489216\n",
      "Pair:120 Loss:47.7429783561013\n",
      "Pair:130 Loss:47.51488952054322\n",
      "Pair:140 Loss:46.770583632989975\n",
      "Pair:150 Loss:45.58440130120081\n",
      "Pair:160 Loss:44.25736822993119\n",
      "Pair:170 Loss:43.01433369709037\n",
      "Pair:180 Loss:42.18116620100664\n",
      "Pair:190 Loss:41.62635757785817\n",
      "Pair:200 Loss:40.54232901008568\n",
      "Pair:210 Loss:41.046242754606276\n",
      "Pair:220 Loss:40.91912695293513\n",
      "Pair:230 Loss:40.36715181152542\n",
      "Pair:240 Loss:40.26017418145144\n",
      "Pair:250 Loss:39.67378628111456\n",
      "Pair:260 Loss:39.07234614288213\n",
      "Pair:270 Loss:38.29354243964727\n",
      "Pair:280 Loss:37.73374922165243\n",
      "Pair:290 Loss:37.422832788880335\n",
      "Pair:300 Loss:37.09688743642002\n",
      "Pair:310 Loss:36.582490873490116\n",
      "Pair:320 Loss:35.99867677540051\n",
      "Pair:330 Loss:35.69315563443924\n",
      "Pair:340 Loss:35.2218801982242\n",
      "Pair:350 Loss:34.66665973011245\n",
      "Pair:360 Loss:34.16532256134329\n",
      "Pair:370 Loss:33.76422187003164\n",
      "Pair:380 Loss:33.37140998126954\n",
      "Pair:390 Loss:32.9035020807515\n",
      "Pair:400 Loss:32.6808602512626\n",
      "Pair:410 Loss:32.39309182190257\n",
      "Pair:420 Loss:31.999647475195044\n",
      "Pair:430 Loss:31.719957183242673\n",
      "Pair:440 Loss:31.314525918084748\n",
      "Pair:450 Loss:30.888285220330147\n",
      "Pair:460 Loss:30.588795715454086\n",
      "Pair:470 Loss:30.245231614244464\n",
      "Pair:480 Loss:30.022429852872282\n",
      "Pair:490 Loss:29.68224977767152\n",
      "Pair:500 Loss:29.52509786268908\n",
      "Pair:510 Loss:29.34137477380189\n",
      "Pair:520 Loss:29.07690066659748\n",
      "Pair:530 Loss:28.881315038253582\n",
      "Pair:540 Loss:28.7242680155636\n",
      "Pair:550 Loss:28.683664123289383\n",
      "Pair:560 Loss:28.42563122840276\n",
      "Pair:570 Loss:28.14504076532641\n",
      "Pair:580 Loss:28.143049716333923\n",
      "Pair:590 Loss:28.136685866591492\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "model = Seq2Seq(w2i, lf2i, options)\n",
    "model.train(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['where', 'is', 'c0']\n",
      "Index 0\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'loc:t', 'c0', '$0', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "1 ['river', 'in', 's0']\n",
      "Index 1\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'river:t', '$0', ')', '(', 'loc:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "2 ['where', 'are', 'mountain']\n",
      "Index 2\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'exists', '$1', '(', 'and', '(', 'mountain:t', '$1', ')', '(', 'loc:t', '$1', '$0', ')', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "3 ['where', 'is', 'c0']\n",
      "Index 3\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'loc:t', 'c0', '$0', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "4 ['what', 'state', 'border', 's0']\n",
      "Index 4\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "5 ['what', 'state', 'border', 's0']\n",
      "Index 5\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "6 ['what', 'state', 'border', 's0']\n",
      "Index 6\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "7 ['which', 'state', 'border', 's0']\n",
      "Index 7\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "8 ['what', 'state', 'border', 's0']\n",
      "Index 8\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "9 ['how', 'high', 'is', 'm0']\n",
      "Index 9\n",
      "Original : ['(', 'elevation:i', 'm0', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "10 ['what', 'state', 'border', 's0']\n",
      "Index 10\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "11 ['which', 'state', 'border', 's0']\n",
      "Index 11\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "12 ['how', 'big', 'is', 's0']\n",
      "Index 12\n",
      "Original : ['(', 'size:i', 's0', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "13 ['what', 'state', 'border', 's0']\n",
      "Index 13\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "14 ['how', 'high', 'is', 'm0']\n",
      "Index 14\n",
      "Original : ['(', 'elevation:i', 'm0', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "15 ['which', 'state', 'border', 's0']\n",
      "Index 15\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "16 ['what', 'state', 'border', 's0']\n",
      "Index 16\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'and', '(', 'state:t', '$0', ')', '(', 'next_to:t', '$0', 's0', ')', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "17 ['where', 'is', 'the', 'r0']\n",
      "Index 17\n",
      "Original : ['(', 'lambda', '$0', 'e', '(', 'loc:t', 'r0', '$0', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "18 ['how', 'big', 'is', 's0']\n",
      "Index 18\n",
      "Original : ['(', 'size:i', 's0', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n",
      "19 ['which', 'state', 'is', 'the', 'smallest']\n",
      "Index 19\n",
      "Original : ['(', 'argmin', '$0', '(', 'state:t', '$0', ')', '(', 'size:i', '$0', ')', ')']\n",
      "Prediction ( lambda $0 e ( and ( state:t $0 ) ( loc:t $0 s0 ) ) )\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.predict(TEST_FILE, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
