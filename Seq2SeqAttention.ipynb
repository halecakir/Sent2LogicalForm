{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_FILE = \"data/test.txt\"\n",
    "TRAIN_FILE = \"data/train.txt\"\n",
    "WHOLE_FILE = \"data/whole.txt\"\n",
    "F_VOCAB_FILE = \"data/vocab.f.txt\"\n",
    "Q_VOCAB_FILE = \"data/vocab.q.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.rnn_size = 50\n",
    "        self.init_weight = 0.08\n",
    "        self.decay_rate = 0.985\n",
    "        self.learning_rate = 0.01\n",
    "        self.plot_every = 10\n",
    "        self.print_every = 50\n",
    "        self.grad_clip = 5\n",
    "        self.dropout = 0\n",
    "        self.dropoutrec = 0\n",
    "        self.learning_rate_decay =  0.985\n",
    "        self.learning_rate_decay_after = 5\n",
    "        \n",
    "        \n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.i2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "        self.h2h = nn.Linear(opt.rnn_size, 4 * opt.rnn_size)\n",
    "        if opt.dropoutrec > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropoutrec)\n",
    "            \n",
    "    def forward(self, x, prev_c, prev_h):\n",
    "        gates = self.i2h(x) + self.h2h(prev_h)\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        ingate = torch.sigmoid(ingate)\n",
    "        forgetgate = torch.sigmoid(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = torch.sigmoid(outgate)\n",
    "        if self.opt.dropoutrec > 0:\n",
    "            cellgate = self.dropout(cellgate)\n",
    "        cy = (forgetgate * prev_c) + (ingate * cellgate)\n",
    "        hy = outgate * torch.tanh(cy)  # n_b x hidden_dim\n",
    "        return cy, hy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, opt, input_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        self.lstm = LSTM(self.opt)\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.__initParameters()\n",
    "\n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "                \n",
    "    def forward(self, input_src, prev_c, prev_h):\n",
    "        src_emb = self.embedding(input_src) # batch_size x src_length x emb_size\n",
    "        if self.opt.dropout > 0:\n",
    "            src_emb = self.dropout(src_emb)\n",
    "        prev_cy, prev_hy = self.lstm(src_emb, prev_c, prev_h)\n",
    "        return prev_cy, prev_hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, opt, output_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.rnn_size\n",
    "\n",
    "        self.linear_att = nn.Linear(2*self.hidden_size, self.hidden_size)\n",
    "        self.linear_out = nn.Linear(self.hidden_size, output_size)\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.__initParameters()\n",
    "    \n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -opt.init_weight, opt.init_weight)\n",
    "\n",
    "    def forward(self, enc_s_top, dec_s_top):\n",
    "        dot = torch.bmm(enc_s_top, dec_s_top.unsqueeze(2))\n",
    "        attention = self.softmax(dot.squeeze(2)).unsqueeze(2)\n",
    "        enc_attention = torch.bmm(enc_s_top.permute(0,2,1), attention)\n",
    "        hid = torch.tanh(self.linear_att(torch.cat((enc_attention.squeeze(2),dec_s_top), 1)))\n",
    "        h2y_in = hid\n",
    "        if self.opt.dropout > 0:\n",
    "            h2y_in = self.dropout(h2y_in)\n",
    "        h2y = self.linear_out(h2y_in)\n",
    "        pred = self.logsoftmax(h2y)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fh):\n",
    "    for line in fh:\n",
    "        sentence, lf = line.strip().split(\"\\t\")\n",
    "        sentence = sentence.split()\n",
    "        lf = lf.split()\n",
    "        yield sentence, lf\n",
    "\n",
    "def read_vocab(filename):\n",
    "    t2i = {\"<s>\": 0, \"</s>\":1, \"UNK\": 2}\n",
    "    with open(filename) as target:\n",
    "        for line in target:\n",
    "            token = line.strip().split()[0]\n",
    "            if token not in t2i:\n",
    "                t2i[token] = len(t2i)\n",
    "    return t2i\n",
    "\n",
    "def is_equal(gold, predictions):\n",
    "    total_correct = 0.0\n",
    "    if len(gold) == len(predictions):\n",
    "        equal = True\n",
    "        for g, p in zip(gold, predictions):\n",
    "            if g != p:\n",
    "                equal = False\n",
    "        return equal\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprare_data(file_name):\n",
    "    shuffledData = None\n",
    "    with open(TRAIN_FILE, 'r') as train:\n",
    "        shuffledData = list(read_data(train))\n",
    "        random.shuffle(shuffledData)\n",
    "    sentence_index_tensors = []\n",
    "    form_index_tensors = []\n",
    "    for sentence in shuffledData:\n",
    "        text_tensor = torch.zeros((1, len(sentence[0]) + 2), dtype=torch.long)\n",
    "        text_tensor[0][0] = w2i[\"<s>\"]\n",
    "        for idx, word in enumerate(sentence[0]):\n",
    "            word_index = w2i[word] if word in w2i else w2i[\"UNK\"]\n",
    "            text_tensor[0][idx+1] = word_index\n",
    "        text_tensor[0][-1] = w2i[\"</s>\"]\n",
    "        sentence_index_tensors.append(text_tensor)\n",
    "        form_tensor = torch.zeros((1, len(sentence[1]) + 2), dtype=torch.long)\n",
    "        form_tensor[0][0] = lf2i[\"<s>\"]\n",
    "        for idx, form in enumerate(sentence[1]):\n",
    "            form_index = lf2i[form] if form in lf2i else lf2i[\"UNK\"]\n",
    "            form_tensor[0][idx+1] = form_index\n",
    "        form_tensor[0][-1] = lf2i[\"</s>\"]\n",
    "        form_index_tensors.append(form_tensor)\n",
    "    return shuffledData, sentence_index_tensors, form_index_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(opt, criterion, encoder_optimizer, decoder_optimizer, attention_optimizer, encoder, decoder, attention, s1, f1):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    attention_optimizer.zero_grad()\n",
    "\n",
    "    outputs = torch.zeros((1, s1.size(1), opt.rnn_size), dtype=torch.float, requires_grad=False)\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "        outputs[:,i, :] = h\n",
    "        \n",
    "    loss = 0\n",
    "    for i in range(f1.size(1)-1):\n",
    "        c, h = decoder(f1[:, i], c, h)\n",
    "        pred = attention(outputs, h)\n",
    "        loss += criterion(pred, f1[:, i+1])\n",
    "        \n",
    "    loss.backward()\n",
    "    if opt.grad_clip != -1:\n",
    "        torch.nn.utils.clip_grad_value_(encoder.parameters(),opt.grad_clip)\n",
    "        torch.nn.utils.clip_grad_value_(decoder.parameters(),opt.grad_clip)\n",
    "        torch.nn.utils.clip_grad_value_(attention.parameters(),opt.grad_clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    attention_optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(opt, s1, lf2i, encoder, decoder, attention):\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    outputs = torch.zeros((1, s1.size(1), opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    for i in range(s1.size(1)):\n",
    "        c, h = encoder(s1[:, i], c, h)\n",
    "        outputs[:,i, :] = h\n",
    "            \n",
    "    prev = torch.tensor([lf2i['<s>']], dtype=torch.long)\n",
    "    predicted_form = []\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        c, h = decoder(prev, c, h)\n",
    "        pred = attention(outputs, h)\n",
    "        form_id = pred.argmax().item()\n",
    "        prev = torch.tensor([form_id], dtype=torch.long)\n",
    "        if form_id == lf2i[\"</s>\"] or counter >= 100:\n",
    "            break\n",
    "        predicted_form.append(form_id)\n",
    "    return predicted_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "def showPlot(points, fig_name, extra_info):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.title(extra_info) \n",
    "    plt.plot(points)\n",
    "    plt.savefig(\"{}.png\".format(fig_name))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = read_vocab(Q_VOCAB_FILE)\n",
    "lf2i = read_vocab(F_VOCAB_FILE)\n",
    "i2lf = {lf2i[i] : i for i in lf2i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(epoch_num, directory):\n",
    "    train_data, sentence_index_tensors_train, form_index_tensors_train = preprare_data(TRAIN_FILE)\n",
    "    test_data, sentence_index_tensors_test, form_index_tensors_test = preprare_data(TEST_FILE)\n",
    "    \n",
    "    encoder = RNN(opt, len(w2i))\n",
    "    decoder = RNN(opt, len(lf2i))\n",
    "    attention = Attention(opt, len(lf2i))\n",
    "    optim_state = {\"learningRate\" : opt.learning_rate, \"alpha\" :  opt.decay_rate}\n",
    "    encoder_optimizer = optim.RMSprop(encoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "    decoder_optimizer = optim.RMSprop(decoder.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "    attention_optimizer = optim.RMSprop(attention.parameters(),  lr=optim_state[\"learningRate\"], alpha=optim_state[\"alpha\"])\n",
    "\n",
    "    criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "    losses = []\n",
    "    max_acc = 0\n",
    "    maxAccEpochId = 0\n",
    "    accuracies = []\n",
    "    chunkend_losses = []\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"---Epoch {}---\\n\".format(epoch+1))\n",
    "        print(\"Training...\")\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        attention.train()\n",
    "        plot_data = []\n",
    "        for index, (sentence, form) in enumerate(zip(sentence_index_tensors_train, form_index_tensors_train)):\n",
    "            loss = train(opt, criterion, encoder_optimizer, decoder_optimizer, attention_optimizer, encoder, decoder, attention, sentence, form)\n",
    "            if index != 0:\n",
    "                if index % opt.plot_every == 0:     \n",
    "                    plot_data.append(np.mean(losses[epoch*len(train_data)+index-opt.plot_every:]))\n",
    "                    chunkend_losses.append(np.mean(plot_data))\n",
    "                if index % opt.print_every == 0:\n",
    "                    print(\"Index {} Loss {}\".format(index, np.mean(losses[epoch*len(train_data)+index-opt.print_every:])))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if opt.learning_rate_decay < 1:\n",
    "            if epoch >= opt.learning_rate_decay_after:\n",
    "                decay_factor = opt.learning_rate_decay\n",
    "                optim_state[\"learningRate\"] = optim_state[\"learningRate\"] * decay_factor #decay it\n",
    "                for param_group in encoder_optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "                for param_group in decoder_optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "                for param_group in attention_optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "\n",
    "        print(\"Predicting..\")\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        attention.eval()\n",
    "        correct = 0.0\n",
    "        with torch.no_grad():\n",
    "            for index, (sentence, form) in enumerate(zip(sentence_index_tensors_test, form_index_tensors_test)):\n",
    "                prediction = predict(opt, sentence, lf2i, encoder, decoder, attention)\n",
    "                prediction = [i2lf[p] for p in prediction]\n",
    "                #print(test_data[index][1])\n",
    "                #print(prediction)\n",
    "                if len(test_data[index][1]) == len(prediction):\n",
    "                    same = True\n",
    "                    for g, p in zip(test_data[index][1], prediction):\n",
    "                        if g != p:\n",
    "                            same = False\n",
    "                    if same:\n",
    "                        correct += 1\n",
    "\n",
    "        accuracy = 100*(correct/len(test_data))\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > max_acc:\n",
    "            max_acc = accuracy\n",
    "            maxAccEpochId = epoch\n",
    "\n",
    "        print(\"Accuracy: {} Max Accuracy {}\".format(accuracy, max_acc))\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        file_name = \"{}/epoch.{}\".format(directory, epoch)\n",
    "        extra = \"Mean Loss {0:.2f}\".format(np.mean(plot_data))\n",
    "        showPlot(plot_data, file_name, extra)\n",
    "\n",
    "    file_name = \"{}/{}\".format(directory, \"accuracies\")\n",
    "    extra = \"Maximum Accuracy {0:.2f} at epoch {1}\".format(np.max(accuracies), maxAccEpochId)\n",
    "    showPlot(accuracies, file_name, extra)\n",
    "    file_name = \"{}/{}\".format(directory, \"all_losses\") \n",
    "    extra = \"Mean Loss {0:.2f}\".format(np.mean(chunkend_losses))\n",
    "    showPlot(chunkend_losses, file_name, extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_and_test(100, \"out/Attention/BaseExperiment.required_grad_false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 41.97954932212829\n",
      "Index 100 Loss 20.482985944747924\n",
      "Index 150 Loss 19.88434991836548\n",
      "Index 200 Loss 16.688602333068847\n",
      "Index 250 Loss 11.353065056800842\n",
      "Index 300 Loss 14.88828067779541\n",
      "Index 350 Loss 14.386179599761963\n",
      "Index 400 Loss 17.627456607818605\n",
      "Index 450 Loss 13.326656484603882\n",
      "Index 500 Loss 14.242035932540894\n",
      "Index 550 Loss 9.719332494735717\n",
      "Predicting..\n",
      "Accuracy: 7.166666666666667 Max Accuracy 7.166666666666667\n",
      "---Epoch 2---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 13.416100749969482\n",
      "Index 100 Loss 9.839723510742187\n",
      "Index 150 Loss 10.965814399719239\n",
      "Index 200 Loss 9.418815460205078\n",
      "Index 250 Loss 6.330221309661865\n",
      "Index 300 Loss 9.345489149093629\n",
      "Index 350 Loss 8.623284606933593\n",
      "Index 400 Loss 11.425954694747924\n",
      "Index 450 Loss 8.220655422210694\n",
      "Index 500 Loss 9.958322334289551\n",
      "Index 550 Loss 6.825116271972656\n",
      "Predicting..\n",
      "Accuracy: 31.5 Max Accuracy 31.5\n",
      "---Epoch 3---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 10.03083477973938\n",
      "Index 100 Loss 6.705715613365173\n",
      "Index 150 Loss 8.333084163665772\n",
      "Index 200 Loss 5.777803039550781\n",
      "Index 250 Loss 3.5546973609924315\n",
      "Index 300 Loss 6.493654775619507\n",
      "Index 350 Loss 6.022953720092773\n",
      "Index 400 Loss 7.706476831436158\n",
      "Index 450 Loss 5.717089595794678\n",
      "Index 500 Loss 6.558235621452331\n",
      "Index 550 Loss 5.5757268524169925\n",
      "Predicting..\n",
      "Accuracy: 54.50000000000001 Max Accuracy 54.50000000000001\n",
      "---Epoch 4---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 7.600649194717407\n",
      "Index 100 Loss 4.880201330184937\n",
      "Index 150 Loss 5.702730321884156\n",
      "Index 200 Loss 4.129467105865478\n",
      "Index 250 Loss 2.6266997718811034\n",
      "Index 300 Loss 5.357551231384277\n",
      "Index 350 Loss 4.221536707878113\n",
      "Index 400 Loss 5.495190553665161\n",
      "Index 450 Loss 4.5524924373626705\n",
      "Index 500 Loss 5.599759798049927\n",
      "Index 550 Loss 3.219701175689697\n",
      "Predicting..\n",
      "Accuracy: 56.833333333333336 Max Accuracy 56.833333333333336\n",
      "---Epoch 5---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 6.32594518661499\n",
      "Index 100 Loss 3.581637783050537\n",
      "Index 150 Loss 5.203527641296387\n",
      "Index 200 Loss 3.537843065261841\n",
      "Index 250 Loss 2.0918451023101805\n",
      "Index 300 Loss 4.506000232696533\n",
      "Index 350 Loss 3.9424327850341796\n",
      "Index 400 Loss 4.7349246215820315\n",
      "Index 450 Loss 3.669369773864746\n",
      "Index 500 Loss 4.593624215126038\n",
      "Index 550 Loss 2.9404938125610354\n",
      "Predicting..\n",
      "Accuracy: 58.666666666666664 Max Accuracy 58.666666666666664\n",
      "---Epoch 6---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 5.5830910205841064\n",
      "Index 100 Loss 3.370588436126709\n",
      "Index 150 Loss 3.933994483947754\n",
      "Index 200 Loss 2.9103582096099854\n",
      "Index 250 Loss 1.838810110092163\n",
      "Index 300 Loss 3.487635126113892\n",
      "Index 350 Loss 2.7686831092834474\n",
      "Index 400 Loss 3.8538125705718995\n",
      "Index 450 Loss 2.7583273696899413\n",
      "Index 500 Loss 3.7208208084106444\n",
      "Index 550 Loss 2.2049839687347412\n",
      "Predicting..\n",
      "Accuracy: 63.66666666666667 Max Accuracy 63.66666666666667\n",
      "---Epoch 7---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 5.213714923858642\n",
      "Index 100 Loss 2.640810947418213\n",
      "Index 150 Loss 3.9194318008422853\n",
      "Index 200 Loss 2.25217866897583\n",
      "Index 250 Loss 1.5417025566101075\n",
      "Index 300 Loss 2.851585211753845\n",
      "Index 350 Loss 3.2269602966308595\n",
      "Index 400 Loss 3.779079055786133\n",
      "Index 450 Loss 2.2459927654266356\n",
      "Index 500 Loss 3.3658901119232176\n",
      "Index 550 Loss 1.8979198455810546\n",
      "Predicting..\n",
      "Accuracy: 68.33333333333333 Max Accuracy 68.33333333333333\n",
      "---Epoch 8---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.911689119338989\n",
      "Index 100 Loss 2.4421502780914306\n",
      "Index 150 Loss 4.066005506515503\n",
      "Index 200 Loss 2.657159538269043\n",
      "Index 250 Loss 1.2160441875457764\n",
      "Index 300 Loss 2.3423314094543457\n",
      "Index 350 Loss 2.0456695461273195\n",
      "Index 400 Loss 2.4771070957183836\n",
      "Index 450 Loss 2.429019422531128\n",
      "Index 500 Loss 3.296416597366333\n",
      "Index 550 Loss 2.1308594608306883\n",
      "Predicting..\n",
      "Accuracy: 68.0 Max Accuracy 68.33333333333333\n",
      "---Epoch 9---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.304317350387573\n",
      "Index 100 Loss 2.224978513717651\n",
      "Index 150 Loss 2.819541530609131\n",
      "Index 200 Loss 2.1018490982055664\n",
      "Index 250 Loss 1.2681450939178467\n",
      "Index 300 Loss 2.8047294330596926\n",
      "Index 350 Loss 1.6014020729064942\n",
      "Index 400 Loss 2.597573690414429\n",
      "Index 450 Loss 2.283370714187622\n",
      "Index 500 Loss 2.6463563346862795\n",
      "Index 550 Loss 1.9517276287078857\n",
      "Predicting..\n",
      "Accuracy: 70.5 Max Accuracy 70.5\n",
      "---Epoch 10---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.9606388282775877\n",
      "Index 100 Loss 2.1607290172576903\n",
      "Index 150 Loss 2.6296932888031006\n",
      "Index 200 Loss 2.0528113079071044\n",
      "Index 250 Loss 0.9400418281555176\n",
      "Index 300 Loss 2.260518741607666\n",
      "Index 350 Loss 2.635674238204956\n",
      "Index 400 Loss 2.442270288467407\n",
      "Index 450 Loss 2.0251892948150636\n",
      "Index 500 Loss 2.121740655899048\n",
      "Index 550 Loss 1.4566444396972655\n",
      "Predicting..\n",
      "Accuracy: 73.83333333333333 Max Accuracy 73.83333333333333\n",
      "---Epoch 11---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 4.539487953186035\n",
      "Index 100 Loss 2.2531716442108154\n",
      "Index 150 Loss 2.6291402912139894\n",
      "Index 200 Loss 1.581084861755371\n",
      "Index 250 Loss 0.9752664756774903\n",
      "Index 300 Loss 1.4868122959136962\n",
      "Index 350 Loss 2.490278730392456\n",
      "Index 400 Loss 2.876550178527832\n",
      "Index 450 Loss 1.9079936599731446\n",
      "Index 500 Loss 2.3293017196655272\n",
      "Index 550 Loss 1.312898826599121\n",
      "Predicting..\n",
      "Accuracy: 79.66666666666666 Max Accuracy 79.66666666666666\n",
      "---Epoch 12---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.402023363113403\n",
      "Index 100 Loss 2.2866741275787352\n",
      "Index 150 Loss 2.6358554649353025\n",
      "Index 200 Loss 1.33902268409729\n",
      "Index 250 Loss 0.7294341278076172\n",
      "Index 300 Loss 1.5892834186553955\n",
      "Index 350 Loss 1.409451322555542\n",
      "Index 400 Loss 2.3257684993743895\n",
      "Index 450 Loss 1.7782997608184814\n",
      "Index 500 Loss 2.412429189682007\n",
      "Index 550 Loss 1.747537031173706\n",
      "Predicting..\n",
      "Accuracy: 77.83333333333333 Max Accuracy 79.66666666666666\n",
      "---Epoch 13---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 3.23221661567688\n",
      "Index 100 Loss 1.9860411930084227\n",
      "Index 150 Loss 2.4007557106018065\n",
      "Index 200 Loss 1.3058007144927979\n",
      "Index 250 Loss 0.5794109439849854\n",
      "Index 300 Loss 1.6803744792938233\n",
      "Index 350 Loss 1.096052770614624\n",
      "Index 400 Loss 2.2041080665588377\n",
      "Index 450 Loss 1.7153560543060302\n",
      "Index 500 Loss 2.122758321762085\n",
      "Index 550 Loss 1.7734608459472656\n",
      "Predicting..\n",
      "Accuracy: 80.16666666666666 Max Accuracy 80.16666666666666\n",
      "---Epoch 14---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.666298761367798\n",
      "Index 100 Loss 1.8353900146484374\n",
      "Index 150 Loss 1.7503522109985352\n",
      "Index 200 Loss 1.171633996963501\n",
      "Index 250 Loss 0.7840825462341309\n",
      "Index 300 Loss 1.628913450241089\n",
      "Index 350 Loss 1.2708810138702393\n",
      "Index 400 Loss 1.7643922090530395\n",
      "Index 450 Loss 1.534061632156372\n",
      "Index 500 Loss 2.213324546813965\n",
      "Index 550 Loss 0.9439463233947754\n",
      "Predicting..\n",
      "Accuracy: 83.0 Max Accuracy 83.0\n",
      "---Epoch 15---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.785490045547485\n",
      "Index 100 Loss 1.4191648387908935\n",
      "Index 150 Loss 1.3772554588317871\n",
      "Index 200 Loss 1.106782274246216\n",
      "Index 250 Loss 0.3639006996154785\n",
      "Index 300 Loss 1.4601704692840576\n",
      "Index 350 Loss 1.4541773223876953\n",
      "Index 400 Loss 1.5777294921875\n",
      "Index 450 Loss 1.1016958141326905\n",
      "Index 500 Loss 1.798302116394043\n",
      "Index 550 Loss 0.8609223937988282\n",
      "Predicting..\n",
      "Accuracy: 83.5 Max Accuracy 83.5\n",
      "---Epoch 16---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.2965472602844237\n",
      "Index 100 Loss 1.157516098022461\n",
      "Index 150 Loss 2.038847484588623\n",
      "Index 200 Loss 1.2419479179382324\n",
      "Index 250 Loss 0.8709425449371337\n",
      "Index 300 Loss 1.5318010330200196\n",
      "Index 350 Loss 1.3497644138336182\n",
      "Index 400 Loss 1.7128347492218017\n",
      "Index 450 Loss 1.530692729949951\n",
      "Index 500 Loss 1.8382067584991455\n",
      "Index 550 Loss 1.777612943649292\n",
      "Predicting..\n",
      "Accuracy: 83.83333333333334 Max Accuracy 83.83333333333334\n",
      "---Epoch 17---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.400416765213013\n",
      "Index 100 Loss 1.6263248443603515\n",
      "Index 150 Loss 1.9507370281219483\n",
      "Index 200 Loss 1.4032827091217042\n",
      "Index 250 Loss 0.509026117324829\n",
      "Index 300 Loss 1.3599442768096923\n",
      "Index 350 Loss 1.3469289207458497\n",
      "Index 400 Loss 1.034193410873413\n",
      "Index 450 Loss 0.7868952083587647\n",
      "Index 500 Loss 1.7417892265319823\n",
      "Index 550 Loss 1.4058945178985596\n",
      "Predicting..\n",
      "Accuracy: 80.5 Max Accuracy 83.83333333333334\n",
      "---Epoch 18---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.313672285079956\n",
      "Index 100 Loss 0.9245860576629639\n",
      "Index 150 Loss 1.2153454971313478\n",
      "Index 200 Loss 0.9656431198120117\n",
      "Index 250 Loss 0.6620161724090576\n",
      "Index 300 Loss 1.1258210277557372\n",
      "Index 350 Loss 0.8781110858917236\n",
      "Index 400 Loss 1.5029416751861573\n",
      "Index 450 Loss 0.9397519111633301\n",
      "Index 500 Loss 1.829044017791748\n",
      "Index 550 Loss 1.1700904273986816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting..\n",
      "Accuracy: 78.83333333333333 Max Accuracy 83.83333333333334\n",
      "---Epoch 19---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.1990102195739745\n",
      "Index 100 Loss 1.4025133323669434\n",
      "Index 150 Loss 1.3063645267486572\n",
      "Index 200 Loss 0.6221094608306885\n",
      "Index 250 Loss 0.6473284530639648\n",
      "Index 300 Loss 1.5741555404663086\n",
      "Index 350 Loss 1.071119375228882\n",
      "Index 400 Loss 1.456754903793335\n",
      "Index 450 Loss 1.0423159313201904\n",
      "Index 500 Loss 1.6220253658294679\n",
      "Index 550 Loss 0.6622550868988037\n",
      "Predicting..\n",
      "Accuracy: 79.16666666666666 Max Accuracy 83.83333333333334\n",
      "---Epoch 20---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.572121057510376\n",
      "Index 100 Loss 1.3988638496398926\n",
      "Index 150 Loss 1.1362424182891846\n",
      "Index 200 Loss 0.9564263534545898\n",
      "Index 250 Loss 0.28587471961975097\n",
      "Index 300 Loss 0.94455979347229\n",
      "Index 350 Loss 0.8909911632537841\n",
      "Index 400 Loss 1.2073979187011719\n",
      "Index 450 Loss 1.0104517650604248\n",
      "Index 500 Loss 1.4400315380096436\n",
      "Index 550 Loss 0.9718067169189453\n",
      "Predicting..\n",
      "Accuracy: 80.5 Max Accuracy 83.83333333333334\n",
      "---Epoch 21---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.012401876449585\n",
      "Index 100 Loss 1.2758968830108643\n",
      "Index 150 Loss 1.3796389865875245\n",
      "Index 200 Loss 0.8179730606079102\n",
      "Index 250 Loss 0.20094467163085938\n",
      "Index 300 Loss 0.8501684856414795\n",
      "Index 350 Loss 1.1294796085357666\n",
      "Index 400 Loss 1.0536045551300048\n",
      "Index 450 Loss 1.389720687866211\n",
      "Index 500 Loss 1.4604672813415527\n",
      "Index 550 Loss 1.2616778087615967\n",
      "Predicting..\n",
      "Accuracy: 88.83333333333333 Max Accuracy 88.83333333333333\n",
      "---Epoch 22---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.6387624549865722\n",
      "Index 100 Loss 0.8836240196228027\n",
      "Index 150 Loss 1.0392787265777588\n",
      "Index 200 Loss 1.0467898178100585\n",
      "Index 250 Loss 0.28408958435058596\n",
      "Index 300 Loss 1.1874323177337647\n",
      "Index 350 Loss 0.8488133716583252\n",
      "Index 400 Loss 1.465533399581909\n",
      "Index 450 Loss 1.4252222347259522\n",
      "Index 500 Loss 1.6276478958129883\n",
      "Index 550 Loss 1.2623945665359497\n",
      "Predicting..\n",
      "Accuracy: 86.16666666666667 Max Accuracy 88.83333333333333\n",
      "---Epoch 23---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.8134446811676026\n",
      "Index 100 Loss 1.1134914875030517\n",
      "Index 150 Loss 1.2614364624023438\n",
      "Index 200 Loss 0.7943314456939697\n",
      "Index 250 Loss 0.4023803520202637\n",
      "Index 300 Loss 1.0836385917663574\n",
      "Index 350 Loss 0.6223695087432861\n",
      "Index 400 Loss 0.9587129783630371\n",
      "Index 450 Loss 1.0458928108215333\n",
      "Index 500 Loss 1.8290349674224853\n",
      "Index 550 Loss 0.7085924720764161\n",
      "Predicting..\n",
      "Accuracy: 88.83333333333333 Max Accuracy 88.83333333333333\n",
      "---Epoch 24---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.3563563919067383\n",
      "Index 100 Loss 1.1728945922851564\n",
      "Index 150 Loss 1.2012219047546386\n",
      "Index 200 Loss 0.8189435195922852\n",
      "Index 250 Loss 0.6785608005523681\n",
      "Index 300 Loss 1.0804141235351563\n",
      "Index 350 Loss 1.0475099754333497\n",
      "Index 400 Loss 1.1285861492156983\n",
      "Index 450 Loss 0.93961519241333\n",
      "Index 500 Loss 1.2472630500793458\n",
      "Index 550 Loss 0.8230681896209717\n",
      "Predicting..\n",
      "Accuracy: 90.0 Max Accuracy 90.0\n",
      "---Epoch 25---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.2001152324676514\n",
      "Index 100 Loss 0.7439156913757324\n",
      "Index 150 Loss 0.9240179443359375\n",
      "Index 200 Loss 0.6683231163024902\n",
      "Index 250 Loss 0.256947717666626\n",
      "Index 300 Loss 0.7999185466766358\n",
      "Index 350 Loss 0.6735231494903564\n",
      "Index 400 Loss 1.3269500589370729\n",
      "Index 450 Loss 0.9216944789886474\n",
      "Index 500 Loss 0.7107959651947021\n",
      "Index 550 Loss 1.0196317386627198\n",
      "Predicting..\n",
      "Accuracy: 87.5 Max Accuracy 90.0\n",
      "---Epoch 26---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.083425464630127\n",
      "Index 100 Loss 0.7273662185668945\n",
      "Index 150 Loss 1.0066416263580322\n",
      "Index 200 Loss 0.46676591873168943\n",
      "Index 250 Loss 0.21635862350463866\n",
      "Index 300 Loss 0.6596899127960205\n",
      "Index 350 Loss 0.3780571937561035\n",
      "Index 400 Loss 0.5909919261932373\n",
      "Index 450 Loss 0.8234212493896484\n",
      "Index 500 Loss 1.469252758026123\n",
      "Index 550 Loss 1.1746348667144775\n",
      "Predicting..\n",
      "Accuracy: 91.0 Max Accuracy 91.0\n",
      "---Epoch 27---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.8145970249176026\n",
      "Index 100 Loss 0.7230073642730713\n",
      "Index 150 Loss 1.2085472393035888\n",
      "Index 200 Loss 0.5147503566741943\n",
      "Index 250 Loss 0.6401209831237793\n",
      "Index 300 Loss 0.3241544532775879\n",
      "Index 350 Loss 0.754264497756958\n",
      "Index 400 Loss 0.7063391590118409\n",
      "Index 450 Loss 0.5837163257598877\n",
      "Index 500 Loss 1.3186264991760255\n",
      "Index 550 Loss 0.5716233539581299\n",
      "Predicting..\n",
      "Accuracy: 92.16666666666666 Max Accuracy 92.16666666666666\n",
      "---Epoch 28---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4367648315429689\n",
      "Index 100 Loss 0.7141368293762207\n",
      "Index 150 Loss 0.7314127159118652\n",
      "Index 200 Loss 0.49301794052124026\n",
      "Index 250 Loss 0.42044599533081056\n",
      "Index 300 Loss 0.5251284599304199\n",
      "Index 350 Loss 0.5116158962249756\n",
      "Index 400 Loss 1.0624164199829103\n",
      "Index 450 Loss 0.6013603019714355\n",
      "Index 500 Loss 1.356021795272827\n",
      "Index 550 Loss 0.8824316787719727\n",
      "Predicting..\n",
      "Accuracy: 86.66666666666667 Max Accuracy 92.16666666666666\n",
      "---Epoch 29---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4890600776672362\n",
      "Index 100 Loss 0.9904325389862061\n",
      "Index 150 Loss 0.7056403732299805\n",
      "Index 200 Loss 0.6141390037536621\n",
      "Index 250 Loss 0.06746326446533203\n",
      "Index 300 Loss 0.4158051109313965\n",
      "Index 350 Loss 0.4835333824157715\n",
      "Index 400 Loss 0.8894124794006347\n",
      "Index 450 Loss 0.533329496383667\n",
      "Index 500 Loss 0.8333889484405518\n",
      "Index 550 Loss 1.0114653968811036\n",
      "Predicting..\n",
      "Accuracy: 86.5 Max Accuracy 92.16666666666666\n",
      "---Epoch 30---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 2.0601951694488525\n",
      "Index 100 Loss 0.812899284362793\n",
      "Index 150 Loss 1.1097093868255614\n",
      "Index 200 Loss 0.42059223175048827\n",
      "Index 250 Loss 0.09337064743041992\n",
      "Index 300 Loss 0.6688906192779541\n",
      "Index 350 Loss 0.4053960132598877\n",
      "Index 400 Loss 0.48803766250610353\n",
      "Index 450 Loss 0.7331901597976684\n",
      "Index 500 Loss 1.749038486480713\n",
      "Index 550 Loss 0.5922510242462158\n",
      "Predicting..\n",
      "Accuracy: 88.16666666666667 Max Accuracy 92.16666666666666\n",
      "---Epoch 31---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.2819087600708008\n",
      "Index 100 Loss 0.6316695022583008\n",
      "Index 150 Loss 1.3702652549743652\n",
      "Index 200 Loss 0.753728084564209\n",
      "Index 250 Loss 0.178206148147583\n",
      "Index 300 Loss 0.44502106189727786\n",
      "Index 350 Loss 0.36228824615478517\n",
      "Index 400 Loss 0.8220220375061035\n",
      "Index 450 Loss 0.4860408878326416\n",
      "Index 500 Loss 1.088765344619751\n",
      "Index 550 Loss 0.22154991149902345\n",
      "Predicting..\n",
      "Accuracy: 92.83333333333333 Max Accuracy 92.83333333333333\n",
      "---Epoch 32---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.156344976425171\n",
      "Index 100 Loss 0.6352492904663086\n",
      "Index 150 Loss 0.8266018581390381\n",
      "Index 200 Loss 0.49052933692932127\n",
      "Index 250 Loss 0.17508878707885742\n",
      "Index 300 Loss 0.4894923400878906\n",
      "Index 350 Loss 0.06861103057861329\n",
      "Index 400 Loss 0.26577206611633303\n",
      "Index 450 Loss 0.5344660758972168\n",
      "Index 500 Loss 0.9451908779144287\n",
      "Index 550 Loss 0.8953797531127929\n",
      "Predicting..\n",
      "Accuracy: 93.16666666666666 Max Accuracy 93.16666666666666\n",
      "---Epoch 33---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.2931706809997559\n",
      "Index 100 Loss 0.6086826801300049\n",
      "Index 150 Loss 0.42147141456604004\n",
      "Index 200 Loss 0.18910744667053223\n",
      "Index 250 Loss 0.39777699470520017\n",
      "Index 300 Loss 0.5609607553482056\n",
      "Index 350 Loss 0.31632122993469236\n",
      "Index 400 Loss 0.5911732578277588\n",
      "Index 450 Loss 0.7657025098800659\n",
      "Index 500 Loss 0.9980627536773682\n",
      "Index 550 Loss 0.552953634262085\n",
      "Predicting..\n",
      "Accuracy: 91.66666666666666 Max Accuracy 93.16666666666666\n",
      "---Epoch 34---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.1584679222106933\n",
      "Index 100 Loss 0.2991160774230957\n",
      "Index 150 Loss 0.6343802356719971\n",
      "Index 200 Loss 0.5855718040466309\n",
      "Index 250 Loss 0.1887238883972168\n",
      "Index 300 Loss 0.4461695671081543\n",
      "Index 350 Loss 0.18389307975769043\n",
      "Index 400 Loss 0.4418282842636108\n",
      "Index 450 Loss 0.5099851417541504\n",
      "Index 500 Loss 0.6078880023956299\n",
      "Index 550 Loss 0.579142017364502\n",
      "Predicting..\n",
      "Accuracy: 91.66666666666666 Max Accuracy 93.16666666666666\n",
      "---Epoch 35---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.4539267539978027\n",
      "Index 100 Loss 0.28946155548095703\n",
      "Index 150 Loss 0.3955861282348633\n",
      "Index 200 Loss 0.2859608936309814\n",
      "Index 250 Loss 0.1729841423034668\n",
      "Index 300 Loss 0.2903734302520752\n",
      "Index 350 Loss 0.20951662063598633\n",
      "Index 400 Loss 0.33876644134521483\n",
      "Index 450 Loss 0.21153965950012207\n",
      "Index 500 Loss 0.5402254390716553\n",
      "Index 550 Loss 0.6484946441650391\n",
      "Predicting..\n",
      "Accuracy: 93.33333333333333 Max Accuracy 93.33333333333333\n",
      "---Epoch 36---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.021855459213257\n",
      "Index 100 Loss 0.7225849151611328\n",
      "Index 150 Loss 0.6927238750457764\n",
      "Index 200 Loss 0.40171668052673337\n",
      "Index 250 Loss 0.12568564414978028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 300 Loss 0.35222079515457155\n",
      "Index 350 Loss 0.0894132137298584\n",
      "Index 400 Loss 0.5227732276916504\n",
      "Index 450 Loss 0.4157846403121948\n",
      "Index 500 Loss 0.6021114826202393\n",
      "Index 550 Loss 0.219708890914917\n",
      "Predicting..\n",
      "Accuracy: 94.16666666666667 Max Accuracy 94.16666666666667\n",
      "---Epoch 37---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6854583263397217\n",
      "Index 100 Loss 0.46393558502197263\n",
      "Index 150 Loss 0.6090233802795411\n",
      "Index 200 Loss 0.5767447853088379\n",
      "Index 250 Loss 0.10915672302246093\n",
      "Index 300 Loss 0.21147939682006836\n",
      "Index 350 Loss 0.1313382625579834\n",
      "Index 400 Loss 0.5821598243713378\n",
      "Index 450 Loss 0.33011043548583985\n",
      "Index 500 Loss 0.7743584537506103\n",
      "Index 550 Loss 0.3640983867645264\n",
      "Predicting..\n",
      "Accuracy: 92.83333333333333 Max Accuracy 94.16666666666667\n",
      "---Epoch 38---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 1.3162111568450927\n",
      "Index 100 Loss 0.7639776992797852\n",
      "Index 150 Loss 0.6088557243347168\n",
      "Index 200 Loss 0.3641281032562256\n",
      "Index 250 Loss 0.017347488403320312\n",
      "Index 300 Loss 0.30410518646240237\n",
      "Index 350 Loss 0.11648387908935547\n",
      "Index 400 Loss 0.19563440322875977\n",
      "Index 450 Loss 0.5788821792602539\n",
      "Index 500 Loss 0.3693410587310791\n",
      "Index 550 Loss 0.4122574615478516\n",
      "Predicting..\n",
      "Accuracy: 95.0 Max Accuracy 95.0\n",
      "---Epoch 39---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6642532253265381\n",
      "Index 100 Loss 0.26126792907714846\n",
      "Index 150 Loss 0.575056095123291\n",
      "Index 200 Loss 0.17554429054260254\n",
      "Index 250 Loss 0.061166572570800784\n",
      "Index 300 Loss 0.5506127262115479\n",
      "Index 350 Loss 0.21839518547058107\n",
      "Index 400 Loss 0.7846522998809814\n",
      "Index 450 Loss 0.5837011241912842\n",
      "Index 500 Loss 0.5722470760345459\n",
      "Index 550 Loss 0.6269437217712402\n",
      "Predicting..\n",
      "Accuracy: 95.83333333333334 Max Accuracy 95.83333333333334\n",
      "---Epoch 40---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.9454677677154542\n",
      "Index 100 Loss 0.2514631271362305\n",
      "Index 150 Loss 0.38376717567443847\n",
      "Index 200 Loss 0.21644511222839355\n",
      "Index 250 Loss 0.0457887077331543\n",
      "Index 300 Loss 0.4135016536712646\n",
      "Index 350 Loss 0.13629060745239258\n",
      "Index 400 Loss 0.10079666137695313\n",
      "Index 450 Loss 0.31085308074951173\n",
      "Index 500 Loss 0.3389533042907715\n",
      "Index 550 Loss 0.17517074346542358\n",
      "Predicting..\n",
      "Accuracy: 96.16666666666667 Max Accuracy 96.16666666666667\n",
      "---Epoch 41---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.5436412715911865\n",
      "Index 100 Loss 0.3215160655975342\n",
      "Index 150 Loss 0.7440727138519287\n",
      "Index 200 Loss 0.0723966121673584\n",
      "Index 250 Loss 0.012008533477783204\n",
      "Index 300 Loss 0.10838107109069824\n",
      "Index 350 Loss 0.06881901741027832\n",
      "Index 400 Loss 0.13273046493530274\n",
      "Index 450 Loss 0.20492782592773437\n",
      "Index 500 Loss 0.36144754409790036\n",
      "Index 550 Loss 0.5801729393005371\n",
      "Predicting..\n",
      "Accuracy: 94.0 Max Accuracy 96.16666666666667\n",
      "---Epoch 42---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6309142208099365\n",
      "Index 100 Loss 0.46688499450683596\n",
      "Index 150 Loss 0.8396998977661133\n",
      "Index 200 Loss 0.39161201477050783\n",
      "Index 250 Loss 0.1448325538635254\n",
      "Index 300 Loss 0.2814562511444092\n",
      "Index 350 Loss 0.07688061714172363\n",
      "Index 400 Loss 0.2718974208831787\n",
      "Index 450 Loss 0.1720041799545288\n",
      "Index 500 Loss 0.6147081279754638\n",
      "Index 550 Loss 0.1805858325958252\n",
      "Predicting..\n",
      "Accuracy: 96.5 Max Accuracy 96.5\n",
      "---Epoch 43---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.7942090225219727\n",
      "Index 100 Loss 0.39015625\n",
      "Index 150 Loss 0.6934464168548584\n",
      "Index 200 Loss 0.12976890563964844\n",
      "Index 250 Loss 0.040834274291992184\n",
      "Index 300 Loss 0.23557072639465332\n",
      "Index 350 Loss 0.0912728500366211\n",
      "Index 400 Loss 0.4118634128570557\n",
      "Index 450 Loss 0.19505775451660157\n",
      "Index 500 Loss 0.3831093883514404\n",
      "Index 550 Loss 0.3357898426055908\n",
      "Predicting..\n",
      "Accuracy: 96.16666666666667 Max Accuracy 96.5\n",
      "---Epoch 44---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6000625228881836\n",
      "Index 100 Loss 0.13327668190002442\n",
      "Index 150 Loss 0.541586446762085\n",
      "Index 200 Loss 0.16676876068115234\n",
      "Index 250 Loss 0.010341968536376953\n",
      "Index 300 Loss 0.12168782234191894\n",
      "Index 350 Loss 0.040057735443115236\n",
      "Index 400 Loss 0.310639910697937\n",
      "Index 450 Loss 0.15579912185668945\n",
      "Index 500 Loss 0.8007890319824219\n",
      "Index 550 Loss 0.44027029037475585\n",
      "Predicting..\n",
      "Accuracy: 97.16666666666667 Max Accuracy 97.16666666666667\n",
      "---Epoch 45---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.5228229522705078\n",
      "Index 100 Loss 0.17818312644958495\n",
      "Index 150 Loss 0.8744365692138671\n",
      "Index 200 Loss 0.1938219404220581\n",
      "Index 250 Loss 0.0788426399230957\n",
      "Index 300 Loss 0.2802116584777832\n",
      "Index 350 Loss 0.030156660079956054\n",
      "Index 400 Loss 0.3348039388656616\n",
      "Index 450 Loss 0.15969753742218018\n",
      "Index 500 Loss 0.5418386602401734\n",
      "Index 550 Loss 0.13986230850219727\n",
      "Predicting..\n",
      "Accuracy: 95.33333333333334 Max Accuracy 97.16666666666667\n",
      "---Epoch 46---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.9866348457336426\n",
      "Index 100 Loss 0.13988442420959474\n",
      "Index 150 Loss 0.49550877571105956\n",
      "Index 200 Loss 0.1670664691925049\n",
      "Index 250 Loss 0.04910262107849121\n",
      "Index 300 Loss 0.10191483497619629\n",
      "Index 350 Loss 0.021387834548950196\n",
      "Index 400 Loss 0.5293540668487549\n",
      "Index 450 Loss 0.19834829807281495\n",
      "Index 500 Loss 0.30841196060180665\n",
      "Index 550 Loss 0.18338950395584105\n",
      "Predicting..\n",
      "Accuracy: 95.16666666666667 Max Accuracy 97.16666666666667\n",
      "---Epoch 47---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.4964838695526123\n",
      "Index 100 Loss 0.19745512962341308\n",
      "Index 150 Loss 0.21135364532470702\n",
      "Index 200 Loss 0.12408988952636718\n",
      "Index 250 Loss 0.07081329345703125\n",
      "Index 300 Loss 0.1669883918762207\n",
      "Index 350 Loss 0.25193756103515624\n",
      "Index 400 Loss 0.1403359842300415\n",
      "Index 450 Loss 0.26908817768096926\n",
      "Index 500 Loss 0.6956000900268555\n",
      "Index 550 Loss 0.08203603506088257\n",
      "Predicting..\n",
      "Accuracy: 96.66666666666667 Max Accuracy 97.16666666666667\n",
      "---Epoch 48---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.55077392578125\n",
      "Index 100 Loss 0.24860273361206053\n",
      "Index 150 Loss 0.649599494934082\n",
      "Index 200 Loss 0.2892870330810547\n",
      "Index 250 Loss 0.010406532287597657\n",
      "Index 300 Loss 0.23724403977394104\n",
      "Index 350 Loss 0.07297036170959473\n",
      "Index 400 Loss 0.22459195137023927\n",
      "Index 450 Loss 0.18618754386901856\n",
      "Index 500 Loss 0.42473957061767575\n",
      "Index 550 Loss 0.2854044628143311\n",
      "Predicting..\n",
      "Accuracy: 96.33333333333334 Max Accuracy 97.16666666666667\n",
      "---Epoch 49---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.3400489330291748\n",
      "Index 100 Loss 0.1764943504333496\n",
      "Index 150 Loss 0.32882351875305177\n",
      "Index 200 Loss 0.34693902015686034\n",
      "Index 250 Loss 0.21250560760498047\n",
      "Index 300 Loss 0.2252844476699829\n",
      "Index 350 Loss 0.1298687982559204\n",
      "Index 400 Loss 0.20470547676086426\n",
      "Index 450 Loss 0.16007325649261475\n",
      "Index 500 Loss 0.2974238872528076\n",
      "Index 550 Loss 0.21209732055664063\n",
      "Predicting..\n",
      "Accuracy: 96.16666666666667 Max Accuracy 97.16666666666667\n",
      "---Epoch 50---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.7225501060485839\n",
      "Index 100 Loss 0.26817017555236816\n",
      "Index 150 Loss 0.5063525581359863\n",
      "Index 200 Loss 0.24907879829406737\n",
      "Index 250 Loss 0.01701202392578125\n",
      "Index 300 Loss 0.018603310585021973\n",
      "Index 350 Loss 0.06370992183685303\n",
      "Index 400 Loss 0.05934171199798584\n",
      "Index 450 Loss 0.23816351890563964\n",
      "Index 500 Loss 0.43148294448852537\n",
      "Index 550 Loss 0.23738238334655762\n",
      "Predicting..\n",
      "Accuracy: 96.0 Max Accuracy 97.16666666666667\n",
      "---Epoch 51---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.4932945156097412\n",
      "Index 100 Loss 0.29977739334106446\n",
      "Index 150 Loss 0.3023468208312988\n",
      "Index 200 Loss 0.0640192985534668\n",
      "Index 250 Loss 0.005322017669677734\n",
      "Index 300 Loss 0.04935433626174927\n",
      "Index 350 Loss 0.020732536315917968\n",
      "Index 400 Loss 0.0837208366394043\n",
      "Index 450 Loss 0.0643056297302246\n",
      "Index 500 Loss 0.40151330947875974\n",
      "Index 550 Loss 0.05692998886108398\n",
      "Predicting..\n",
      "Accuracy: 96.83333333333334 Max Accuracy 97.16666666666667\n",
      "---Epoch 52---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.7491213989257812\n",
      "Index 100 Loss 0.12138615608215332\n",
      "Index 150 Loss 0.33678351402282714\n",
      "Index 200 Loss 0.05205498695373535\n",
      "Index 250 Loss 0.015024681091308594\n",
      "Index 300 Loss 0.0858658242225647\n",
      "Index 350 Loss 0.13274434089660644\n",
      "Index 400 Loss 0.038733291625976565\n",
      "Index 450 Loss 0.16300568342208863\n",
      "Index 500 Loss 0.2939602279663086\n",
      "Index 550 Loss 0.15217556953430175\n",
      "Predicting..\n",
      "Accuracy: 96.33333333333334 Max Accuracy 97.16666666666667\n",
      "---Epoch 53---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.3071561622619629\n",
      "Index 100 Loss 0.11127097129821778\n",
      "Index 150 Loss 0.551837511062622\n",
      "Index 200 Loss 0.4363755512237549\n",
      "Index 250 Loss 0.10399049758911133\n",
      "Index 300 Loss 0.0694326639175415\n",
      "Index 350 Loss 0.10690737009048462\n",
      "Index 400 Loss 0.04070749282836914\n",
      "Index 450 Loss 0.1886336612701416\n",
      "Index 500 Loss 0.37594765663146973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 550 Loss 0.6380233287811279\n",
      "Predicting..\n",
      "Accuracy: 97.5 Max Accuracy 97.5\n",
      "---Epoch 54---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.24075490951538087\n",
      "Index 100 Loss 0.10400729179382324\n",
      "Index 150 Loss 0.291354808807373\n",
      "Index 200 Loss 0.2694266891479492\n",
      "Index 250 Loss 0.06679290771484375\n",
      "Index 300 Loss 0.08801857948303222\n",
      "Index 350 Loss 0.1389940357208252\n",
      "Index 400 Loss 0.09743263244628907\n",
      "Index 450 Loss 0.07249117136001587\n",
      "Index 500 Loss 0.1531997060775757\n",
      "Index 550 Loss 0.11463861703872681\n",
      "Predicting..\n",
      "Accuracy: 97.83333333333334 Max Accuracy 97.83333333333334\n",
      "---Epoch 55---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.13407788276672364\n",
      "Index 100 Loss 0.17035475730895996\n",
      "Index 150 Loss 0.6904112625122071\n",
      "Index 200 Loss 0.056035614013671874\n",
      "Index 250 Loss 0.019073867797851564\n",
      "Index 300 Loss 0.15106025218963623\n",
      "Index 350 Loss 0.038874607086181644\n",
      "Index 400 Loss 0.08158164501190185\n",
      "Index 450 Loss 0.16020237922668457\n",
      "Index 500 Loss 0.2753929805755615\n",
      "Index 550 Loss 0.07304740905761718\n",
      "Predicting..\n",
      "Accuracy: 95.0 Max Accuracy 97.83333333333334\n",
      "---Epoch 56---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.37825056076049807\n",
      "Index 100 Loss 0.09680328369140626\n",
      "Index 150 Loss 0.3397472667694092\n",
      "Index 200 Loss 0.20444883346557619\n",
      "Index 250 Loss 0.2585186576843262\n",
      "Index 300 Loss 0.2461151123046875\n",
      "Index 350 Loss 0.04577970504760742\n",
      "Index 400 Loss 0.10296597480773925\n",
      "Index 450 Loss 0.08727923154830933\n",
      "Index 500 Loss 0.226490535736084\n",
      "Index 550 Loss 0.09362068176269531\n",
      "Predicting..\n",
      "Accuracy: 96.16666666666667 Max Accuracy 97.83333333333334\n",
      "---Epoch 57---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.3451067447662354\n",
      "Index 100 Loss 0.28108731269836423\n",
      "Index 150 Loss 0.40265923500061035\n",
      "Index 200 Loss 0.17531320571899414\n",
      "Index 250 Loss 0.2350478172302246\n",
      "Index 300 Loss 0.1978565502166748\n",
      "Index 350 Loss 0.08005350112915038\n",
      "Index 400 Loss 0.04481339454650879\n",
      "Index 450 Loss 0.13076083183288575\n",
      "Index 500 Loss 0.4177802085876465\n",
      "Index 550 Loss 0.15343921661376952\n",
      "Predicting..\n",
      "Accuracy: 98.0 Max Accuracy 98.0\n",
      "---Epoch 58---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.11649424552917481\n",
      "Index 100 Loss 0.04030027389526367\n",
      "Index 150 Loss 0.2738274383544922\n",
      "Index 200 Loss 0.14540859222412109\n",
      "Index 250 Loss 0.011400871276855469\n",
      "Index 300 Loss 0.04155056476593018\n",
      "Index 350 Loss 0.03895550727844238\n",
      "Index 400 Loss 0.1413555145263672\n",
      "Index 450 Loss 0.41666927814483645\n",
      "Index 500 Loss 0.339660005569458\n",
      "Index 550 Loss 0.13104486465454102\n",
      "Predicting..\n",
      "Accuracy: 96.66666666666667 Max Accuracy 98.0\n",
      "---Epoch 59---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.17090494632720948\n",
      "Index 100 Loss 0.09483549118041992\n",
      "Index 150 Loss 0.12747682571411134\n",
      "Index 200 Loss 0.07626262664794922\n",
      "Index 250 Loss 0.005973186492919922\n",
      "Index 300 Loss 0.012226259708404541\n",
      "Index 350 Loss 0.04539641380310058\n",
      "Index 400 Loss 0.02411283493041992\n",
      "Index 450 Loss 0.06617268085479737\n",
      "Index 500 Loss 0.23523128509521485\n",
      "Index 550 Loss 0.009320247173309325\n",
      "Predicting..\n",
      "Accuracy: 96.5 Max Accuracy 98.0\n",
      "---Epoch 60---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.2993208694458008\n",
      "Index 100 Loss 0.04789108276367188\n",
      "Index 150 Loss 0.23270804405212403\n",
      "Index 200 Loss 0.07697350502014161\n",
      "Index 250 Loss 0.03741074562072754\n",
      "Index 300 Loss 0.011667203903198243\n",
      "Index 350 Loss 0.011262893676757812\n",
      "Index 400 Loss 0.05432754516601562\n",
      "Index 450 Loss 0.06950541496276856\n",
      "Index 500 Loss 0.43769675254821777\n",
      "Index 550 Loss 0.0892628526687622\n",
      "Predicting..\n",
      "Accuracy: 96.33333333333334 Max Accuracy 98.0\n",
      "---Epoch 61---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.259201135635376\n",
      "Index 100 Loss 0.061140584945678714\n",
      "Index 150 Loss 0.24662464141845702\n",
      "Index 200 Loss 0.04637155532836914\n",
      "Index 250 Loss 0.015788173675537108\n",
      "Index 300 Loss 0.1513005542755127\n",
      "Index 350 Loss 0.0057762241363525394\n",
      "Index 400 Loss 0.04127732276916504\n",
      "Index 450 Loss 0.06481855869293213\n",
      "Index 500 Loss 0.30454504013061523\n",
      "Index 550 Loss 0.02525362491607666\n",
      "Predicting..\n",
      "Accuracy: 97.83333333333334 Max Accuracy 98.0\n",
      "---Epoch 62---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.1549155330657959\n",
      "Index 100 Loss 0.009583654403686524\n",
      "Index 150 Loss 0.13166823863983154\n",
      "Index 200 Loss 0.10425939559936523\n",
      "Index 250 Loss 0.10945295333862305\n",
      "Index 300 Loss 0.011408867835998536\n",
      "Index 350 Loss 0.11335962295532226\n",
      "Index 400 Loss 0.017183334827423097\n",
      "Index 450 Loss 0.08784918785095215\n",
      "Index 500 Loss 0.23642558097839356\n",
      "Index 550 Loss 0.002722306251525879\n",
      "Predicting..\n",
      "Accuracy: 98.5 Max Accuracy 98.5\n",
      "---Epoch 63---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.1625271511077881\n",
      "Index 100 Loss 0.0562129020690918\n",
      "Index 150 Loss 0.2476335906982422\n",
      "Index 200 Loss 0.04517154693603516\n",
      "Index 250 Loss 0.006132888793945313\n",
      "Index 300 Loss 0.033583240509033205\n",
      "Index 350 Loss 0.008684539794921875\n",
      "Index 400 Loss 0.058686046600341796\n",
      "Index 450 Loss 0.21818641185760498\n",
      "Index 500 Loss 0.16328088760375978\n",
      "Index 550 Loss 0.01934901237487793\n",
      "Predicting..\n",
      "Accuracy: 98.33333333333333 Max Accuracy 98.5\n",
      "---Epoch 64---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.6487115859985352\n",
      "Index 100 Loss 0.3928814220428467\n",
      "Index 150 Loss 0.21510461807250977\n",
      "Index 200 Loss 0.08077201843261719\n",
      "Index 250 Loss 0.033411989212036135\n",
      "Index 300 Loss 0.009680342674255372\n",
      "Index 350 Loss 0.007196483612060547\n",
      "Index 400 Loss 0.012658309936523438\n",
      "Index 450 Loss 0.0538144302368164\n",
      "Index 500 Loss 0.17137314796447753\n",
      "Index 550 Loss 0.01549534797668457\n",
      "Predicting..\n",
      "Accuracy: 98.0 Max Accuracy 98.5\n",
      "---Epoch 65---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.20200435638427736\n",
      "Index 100 Loss 0.08083855152130127\n",
      "Index 150 Loss 0.19757892608642577\n",
      "Index 200 Loss 0.01673638343811035\n",
      "Index 250 Loss 0.01062662124633789\n",
      "Index 300 Loss 0.17952318191528321\n",
      "Index 350 Loss 0.02636138916015625\n",
      "Index 400 Loss 0.04354313850402832\n",
      "Index 450 Loss 0.06553324192762375\n",
      "Index 500 Loss 0.21533203125\n",
      "Index 550 Loss 0.01583571434020996\n",
      "Predicting..\n",
      "Accuracy: 98.83333333333333 Max Accuracy 98.83333333333333\n",
      "---Epoch 66---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.03427324771881104\n",
      "Index 100 Loss 0.053611774444580075\n",
      "Index 150 Loss 0.09880232810974121\n",
      "Index 200 Loss 0.0722286033630371\n",
      "Index 250 Loss 0.004007282257080078\n",
      "Index 300 Loss 0.006502895355224609\n",
      "Index 350 Loss 0.001646146774291992\n",
      "Index 400 Loss 0.01748318672180176\n",
      "Index 450 Loss 0.05532160758972168\n",
      "Index 500 Loss 0.3480148124694824\n",
      "Index 550 Loss 0.40704132080078126\n",
      "Predicting..\n",
      "Accuracy: 98.66666666666667 Max Accuracy 98.83333333333333\n",
      "---Epoch 67---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.10324069261550903\n",
      "Index 100 Loss 0.10405145168304443\n",
      "Index 150 Loss 0.1334357500076294\n",
      "Index 200 Loss 0.06701836585998536\n",
      "Index 250 Loss 0.0018842887878417968\n",
      "Index 300 Loss 0.0767593002319336\n",
      "Index 350 Loss 0.1682419204711914\n",
      "Index 400 Loss 0.020014352798461914\n",
      "Index 450 Loss 0.026289477348327636\n",
      "Index 500 Loss 0.18087687492370605\n",
      "Index 550 Loss 0.3820731925964356\n",
      "Predicting..\n",
      "Accuracy: 98.83333333333333 Max Accuracy 98.83333333333333\n",
      "---Epoch 68---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.14463551044464112\n",
      "Index 100 Loss 0.07161592483520508\n",
      "Index 150 Loss 0.13516218185424805\n",
      "Index 200 Loss 0.024920530319213867\n",
      "Index 250 Loss 0.008617038726806641\n",
      "Index 300 Loss 0.003279914855957031\n",
      "Index 350 Loss 0.004671783447265625\n",
      "Index 400 Loss 0.00423318862915039\n",
      "Index 450 Loss 0.060611662864685056\n",
      "Index 500 Loss 0.20263396263122557\n",
      "Index 550 Loss 0.12015126228332519\n",
      "Predicting..\n",
      "Accuracy: 97.33333333333334 Max Accuracy 98.83333333333333\n",
      "---Epoch 69---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.05566502332687378\n",
      "Index 100 Loss 0.04504591941833496\n",
      "Index 150 Loss 0.1561582851409912\n",
      "Index 200 Loss 0.033030242919921876\n",
      "Index 250 Loss 0.0013141822814941406\n",
      "Index 300 Loss 0.026977033615112306\n",
      "Index 350 Loss 0.001861562728881836\n",
      "Index 400 Loss 0.005892410278320313\n",
      "Index 450 Loss 0.011812734603881835\n",
      "Index 500 Loss 0.19004035949707032\n",
      "Index 550 Loss 0.07239064216613769\n",
      "Predicting..\n",
      "Accuracy: 99.16666666666667 Max Accuracy 99.16666666666667\n",
      "---Epoch 70---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.012492890357971192\n",
      "Index 100 Loss 0.04822122097015381\n",
      "Index 150 Loss 0.06282556533813477\n",
      "Index 200 Loss 0.03576069831848144\n",
      "Index 250 Loss 0.0012494468688964845\n",
      "Index 300 Loss 0.009039359092712402\n",
      "Index 350 Loss 0.04902673244476318\n",
      "Index 400 Loss 0.032398133277893065\n",
      "Index 450 Loss 0.06889371871948242\n",
      "Index 500 Loss 0.16295190811157226\n",
      "Index 550 Loss 0.23459555625915526\n",
      "Predicting..\n",
      "Accuracy: 98.83333333333333 Max Accuracy 99.16666666666667\n",
      "---Epoch 71---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.033608894348144534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 100 Loss 0.014113454818725587\n",
      "Index 150 Loss 0.10284672737121582\n",
      "Index 200 Loss 0.06603322982788086\n",
      "Index 250 Loss 0.005804805755615234\n",
      "Index 300 Loss 0.0071156883239746095\n",
      "Index 350 Loss 0.014759678840637207\n",
      "Index 400 Loss 0.006152191162109375\n",
      "Index 450 Loss 0.038515617847442625\n",
      "Index 500 Loss 0.2814496421813965\n",
      "Index 550 Loss 0.043446893692016604\n",
      "Predicting..\n",
      "Accuracy: 99.0 Max Accuracy 99.16666666666667\n",
      "---Epoch 72---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.22654109001159667\n",
      "Index 100 Loss 0.018632688522338868\n",
      "Index 150 Loss 0.08878922462463379\n",
      "Index 200 Loss 0.014737939834594727\n",
      "Index 250 Loss 0.006326980590820312\n",
      "Index 300 Loss 0.009355564117431641\n",
      "Index 350 Loss 0.002128705978393555\n",
      "Index 400 Loss 0.010801048278808593\n",
      "Index 450 Loss 0.07330493927001953\n",
      "Index 500 Loss 0.11248868942260742\n",
      "Index 550 Loss 0.15038013458251953\n",
      "Predicting..\n",
      "Accuracy: 97.83333333333334 Max Accuracy 99.16666666666667\n",
      "---Epoch 73---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.2273752498626709\n",
      "Index 100 Loss 0.056521663665771486\n",
      "Index 150 Loss 0.1389053249359131\n",
      "Index 200 Loss 0.232101993560791\n",
      "Index 250 Loss 0.0034891891479492186\n",
      "Index 300 Loss 0.0035277605056762695\n",
      "Index 350 Loss 0.004670419692993164\n",
      "Index 400 Loss 0.03824922561645508\n",
      "Index 450 Loss 0.03239156246185303\n",
      "Index 500 Loss 0.22428104400634766\n",
      "Index 550 Loss 0.009459958076477051\n",
      "Predicting..\n",
      "Accuracy: 99.16666666666667 Max Accuracy 99.16666666666667\n",
      "---Epoch 74---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.08630849838256836\n",
      "Index 100 Loss 0.06313827037811279\n",
      "Index 150 Loss 0.1306109619140625\n",
      "Index 200 Loss 0.0107391357421875\n",
      "Index 250 Loss 0.008052330017089843\n",
      "Index 300 Loss 0.026945066452026368\n",
      "Index 350 Loss 0.003044757843017578\n",
      "Index 400 Loss 0.030296211242675782\n",
      "Index 450 Loss 0.04039277553558349\n",
      "Index 500 Loss 0.21350260734558105\n",
      "Index 550 Loss 0.0034479522705078126\n",
      "Predicting..\n",
      "Accuracy: 99.16666666666667 Max Accuracy 99.16666666666667\n",
      "---Epoch 75---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.10836472511291503\n",
      "Index 100 Loss 0.0034788227081298828\n",
      "Index 150 Loss 0.1252095127105713\n",
      "Index 200 Loss 0.0021327590942382814\n",
      "Index 250 Loss 0.0016453170776367188\n",
      "Index 300 Loss 0.01718249320983887\n",
      "Index 350 Loss 0.055342674255371094\n",
      "Index 400 Loss 0.018154916763305665\n",
      "Index 450 Loss 0.023962187767028808\n",
      "Index 500 Loss 0.1432418155670166\n",
      "Index 550 Loss 0.0009335803985595703\n",
      "Predicting..\n",
      "Accuracy: 98.66666666666667 Max Accuracy 99.16666666666667\n",
      "---Epoch 76---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.010000258684158325\n",
      "Index 100 Loss 0.003876752853393555\n",
      "Index 150 Loss 0.08695314407348632\n",
      "Index 200 Loss 0.0026786994934082033\n",
      "Index 250 Loss 0.0006907844543457032\n",
      "Index 300 Loss 0.01000171661376953\n",
      "Index 350 Loss 0.0013670635223388672\n",
      "Index 400 Loss 0.006812143325805664\n",
      "Index 450 Loss 0.04170584678649902\n",
      "Index 500 Loss 0.1775858211517334\n",
      "Index 550 Loss 0.00443643569946289\n",
      "Predicting..\n",
      "Accuracy: 99.0 Max Accuracy 99.16666666666667\n",
      "---Epoch 77---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.012058119773864746\n",
      "Index 100 Loss 0.0029961585998535155\n",
      "Index 150 Loss 0.07208248138427735\n",
      "Index 200 Loss 0.001661510467529297\n",
      "Index 250 Loss 0.00016193389892578126\n",
      "Index 300 Loss 0.0025190305709838867\n",
      "Index 350 Loss 0.00030805587768554686\n",
      "Index 400 Loss 0.0021939468383789062\n",
      "Index 450 Loss 0.0186968994140625\n",
      "Index 500 Loss 0.19107301712036132\n",
      "Index 550 Loss 0.002754669189453125\n",
      "Predicting..\n",
      "Accuracy: 99.33333333333333 Max Accuracy 99.33333333333333\n",
      "---Epoch 78---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.005603084564208985\n",
      "Index 100 Loss 0.00105438232421875\n",
      "Index 150 Loss 0.05591772079467774\n",
      "Index 200 Loss 0.001813812255859375\n",
      "Index 250 Loss 0.0008701515197753906\n",
      "Index 300 Loss 0.0013619518280029296\n",
      "Index 350 Loss 0.0029946708679199218\n",
      "Index 400 Loss 0.0015835285186767579\n",
      "Index 450 Loss 0.06305787086486817\n",
      "Index 500 Loss 0.2085222816467285\n",
      "Index 550 Loss 0.10734533309936524\n",
      "Predicting..\n",
      "Accuracy: 99.0 Max Accuracy 99.33333333333333\n",
      "---Epoch 79---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.022176058292388917\n",
      "Index 100 Loss 0.0025131702423095703\n",
      "Index 150 Loss 0.04459150314331055\n",
      "Index 200 Loss 0.0069119930267333984\n",
      "Index 250 Loss 0.0001880645751953125\n",
      "Index 300 Loss 0.07463263750076293\n",
      "Index 350 Loss 0.0003184700012207031\n",
      "Index 400 Loss 0.0007222938537597656\n",
      "Index 450 Loss 0.010833230018615723\n",
      "Index 500 Loss 0.16268085479736327\n",
      "Index 550 Loss 0.17897144317626953\n",
      "Predicting..\n",
      "Accuracy: 99.5 Max Accuracy 99.5\n",
      "---Epoch 80---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.03617929220199585\n",
      "Index 100 Loss 0.0004737377166748047\n",
      "Index 150 Loss 0.04981098175048828\n",
      "Index 200 Loss 0.014353008270263671\n",
      "Index 250 Loss 0.0002204132080078125\n",
      "Index 300 Loss 0.01636077880859375\n",
      "Index 350 Loss 0.0003481864929199219\n",
      "Index 400 Loss 0.001047506332397461\n",
      "Index 450 Loss 0.08805063247680664\n",
      "Index 500 Loss 0.11718402862548828\n",
      "Index 550 Loss 0.018922834396362304\n",
      "Predicting..\n",
      "Accuracy: 99.16666666666667 Max Accuracy 99.5\n",
      "---Epoch 81---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.009872965812683106\n",
      "Index 100 Loss 0.0010878562927246094\n",
      "Index 150 Loss 0.05643807411193848\n",
      "Index 200 Loss 0.009859752655029298\n",
      "Index 250 Loss 0.0001506805419921875\n",
      "Index 300 Loss 0.0029899120330810548\n",
      "Index 350 Loss 0.0005175304412841796\n",
      "Index 400 Loss 0.0006286239624023437\n",
      "Index 450 Loss 0.05144509315490722\n",
      "Index 500 Loss 0.11369121551513672\n",
      "Index 550 Loss 0.0042408561706542966\n",
      "Predicting..\n",
      "Accuracy: 99.0 Max Accuracy 99.5\n",
      "---Epoch 82---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.2767351531982422\n",
      "Index 100 Loss 0.0012277793884277344\n",
      "Index 150 Loss 0.008241539001464843\n",
      "Index 200 Loss 0.0017151832580566406\n",
      "Index 250 Loss 0.00011119842529296874\n",
      "Index 300 Loss 0.0009389686584472657\n",
      "Index 350 Loss 0.0008827781677246093\n",
      "Index 400 Loss 0.0008427715301513672\n",
      "Index 450 Loss 0.0400934910774231\n",
      "Index 500 Loss 0.1806354808807373\n",
      "Index 550 Loss 0.0006141471862792969\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.66666666666667\n",
      "---Epoch 83---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0031482791900634766\n",
      "Index 100 Loss 0.02785655975341797\n",
      "Index 150 Loss 0.01985428810119629\n",
      "Index 200 Loss 0.048620138168334964\n",
      "Index 250 Loss 0.00019540786743164063\n",
      "Index 300 Loss 0.000562744140625\n",
      "Index 350 Loss 0.004670925140380859\n",
      "Index 400 Loss 0.0005269908905029297\n",
      "Index 450 Loss 0.02281158447265625\n",
      "Index 500 Loss 0.12613096237182617\n",
      "Index 550 Loss 0.0003544139862060547\n",
      "Predicting..\n",
      "Accuracy: 99.5 Max Accuracy 99.66666666666667\n",
      "---Epoch 84---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0024248504638671874\n",
      "Index 100 Loss 0.020917768478393554\n",
      "Index 150 Loss 0.003065948486328125\n",
      "Index 200 Loss 0.03360034942626953\n",
      "Index 250 Loss 0.00017728805541992188\n",
      "Index 300 Loss 0.002007608413696289\n",
      "Index 350 Loss 0.00011308670043945312\n",
      "Index 400 Loss 0.00048529624938964844\n",
      "Index 450 Loss 0.012416417598724366\n",
      "Index 500 Loss 0.15946146011352538\n",
      "Index 550 Loss 0.0010312175750732421\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.66666666666667\n",
      "---Epoch 85---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.30715346336364746\n",
      "Index 100 Loss 0.0032728767395019532\n",
      "Index 150 Loss 0.12244844436645508\n",
      "Index 200 Loss 0.006818094253540039\n",
      "Index 250 Loss 0.00032716751098632813\n",
      "Index 300 Loss 0.00026449203491210935\n",
      "Index 350 Loss 0.0002631950378417969\n",
      "Index 400 Loss 0.003781290054321289\n",
      "Index 450 Loss 0.014602072238922119\n",
      "Index 500 Loss 0.12958910942077637\n",
      "Index 550 Loss 0.0024281597137451173\n",
      "Predicting..\n",
      "Accuracy: 99.5 Max Accuracy 99.66666666666667\n",
      "---Epoch 86---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.07343316555023194\n",
      "Index 100 Loss 0.010211238861083985\n",
      "Index 150 Loss 0.04934178352355957\n",
      "Index 200 Loss 0.0020493316650390626\n",
      "Index 250 Loss 0.0001464653015136719\n",
      "Index 300 Loss 0.0006041812896728515\n",
      "Index 350 Loss 0.0009596633911132812\n",
      "Index 400 Loss 0.04464095592498779\n",
      "Index 450 Loss 0.017866404056549073\n",
      "Index 500 Loss 0.11293519020080567\n",
      "Index 550 Loss 0.04498220443725586\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 99.83333333333333\n",
      "---Epoch 87---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.002098560333251953\n",
      "Index 100 Loss 0.001768479347229004\n",
      "Index 150 Loss 0.0022005844116210938\n",
      "Index 200 Loss 0.00026956558227539065\n",
      "Index 250 Loss 0.0002580833435058594\n",
      "Index 300 Loss 0.0005264663696289062\n",
      "Index 350 Loss 0.00015264511108398438\n",
      "Index 400 Loss 0.040915002822875975\n",
      "Index 450 Loss 0.01572021484375\n",
      "Index 500 Loss 0.12356023788452149\n",
      "Index 550 Loss 0.006883974075317383\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.83333333333333\n",
      "---Epoch 88---\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 50 Loss 0.03648658752441406\n",
      "Index 100 Loss 0.02005523681640625\n",
      "Index 150 Loss 0.004096012115478515\n",
      "Index 200 Loss 0.0002939414978027344\n",
      "Index 250 Loss 0.00011381149291992188\n",
      "Index 300 Loss 0.0003295421600341797\n",
      "Index 350 Loss 0.00023969650268554688\n",
      "Index 400 Loss 0.00035937309265136717\n",
      "Index 450 Loss 0.013740291595458984\n",
      "Index 500 Loss 0.1297918128967285\n",
      "Index 550 Loss 0.0005522537231445313\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.83333333333333\n",
      "---Epoch 89---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0009208393096923829\n",
      "Index 100 Loss 0.00028606414794921873\n",
      "Index 150 Loss 0.14298168182373047\n",
      "Index 200 Loss 0.0003307723999023437\n",
      "Index 250 Loss 6.959915161132813e-05\n",
      "Index 300 Loss 0.0001576995849609375\n",
      "Index 350 Loss 0.00010250091552734375\n",
      "Index 400 Loss 0.0001356983184814453\n",
      "Index 450 Loss 0.012747316360473633\n",
      "Index 500 Loss 0.13955438613891602\n",
      "Index 550 Loss 9.207725524902343e-05\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 99.83333333333333\n",
      "---Epoch 90---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.00045703887939453126\n",
      "Index 100 Loss 0.0003162288665771484\n",
      "Index 150 Loss 0.0007588005065917968\n",
      "Index 200 Loss 0.00037099838256835936\n",
      "Index 250 Loss 2.4852752685546874e-05\n",
      "Index 300 Loss 0.0013695526123046874\n",
      "Index 350 Loss 0.00024417877197265627\n",
      "Index 400 Loss 0.0001267242431640625\n",
      "Index 450 Loss 0.013447952270507813\n",
      "Index 500 Loss 0.11967410564422608\n",
      "Index 550 Loss 5.2623748779296875e-05\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.83333333333333\n",
      "---Epoch 91---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.04005902767181396\n",
      "Index 100 Loss 0.0005935859680175781\n",
      "Index 150 Loss 0.0004038429260253906\n",
      "Index 200 Loss 0.0016674041748046876\n",
      "Index 250 Loss 0.0008725929260253906\n",
      "Index 300 Loss 0.00016930580139160156\n",
      "Index 350 Loss 3.107070922851562e-05\n",
      "Index 400 Loss 0.00030457496643066407\n",
      "Index 450 Loss 0.01573260307312012\n",
      "Index 500 Loss 0.13961261749267578\n",
      "Index 550 Loss 6.33525848388672e-05\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 99.83333333333333\n",
      "---Epoch 92---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0007151365280151367\n",
      "Index 100 Loss 0.00014432907104492188\n",
      "Index 150 Loss 0.00018598556518554688\n",
      "Index 200 Loss 0.00022716522216796874\n",
      "Index 250 Loss 3.376007080078125e-05\n",
      "Index 300 Loss 9.486198425292969e-05\n",
      "Index 350 Loss 3.80706787109375e-05\n",
      "Index 400 Loss 7.299423217773438e-05\n",
      "Index 450 Loss 0.008387203216552735\n",
      "Index 500 Loss 0.12413004875183105\n",
      "Index 550 Loss 4.902839660644531e-05\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.83333333333333\n",
      "---Epoch 93---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.00033406734466552736\n",
      "Index 100 Loss 5.794525146484375e-05\n",
      "Index 150 Loss 0.0001129913330078125\n",
      "Index 200 Loss 8.167266845703125e-05\n",
      "Index 250 Loss 1.1348724365234375e-05\n",
      "Index 300 Loss 5.916595458984375e-05\n",
      "Index 350 Loss 2.60162353515625e-05\n",
      "Index 400 Loss 4.415512084960937e-05\n",
      "Index 450 Loss 0.008479709625244141\n",
      "Index 500 Loss 0.118197021484375\n",
      "Index 550 Loss 2.892494201660156e-05\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 99.83333333333333\n",
      "---Epoch 94---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.004509646892547608\n",
      "Index 100 Loss 4.3745040893554685e-05\n",
      "Index 150 Loss 0.00012298583984375\n",
      "Index 200 Loss 0.00010519027709960937\n",
      "Index 250 Loss 3.648757934570312e-05\n",
      "Index 300 Loss 0.0057631111145019535\n",
      "Index 350 Loss 8.449554443359374e-05\n",
      "Index 400 Loss 6.612777709960938e-05\n",
      "Index 450 Loss 0.0247994327545166\n",
      "Index 500 Loss 0.12044459342956543\n",
      "Index 550 Loss 4.1446685791015626e-05\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 99.83333333333333\n",
      "---Epoch 95---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0002838468551635742\n",
      "Index 100 Loss 4.5347213745117185e-05\n",
      "Index 150 Loss 5.178451538085937e-05\n",
      "Index 200 Loss 4.133224487304688e-05\n",
      "Index 250 Loss 6.40869140625e-06\n",
      "Index 300 Loss 0.0009449005126953125\n",
      "Index 350 Loss 1.491546630859375e-05\n",
      "Index 400 Loss 4.453659057617188e-05\n",
      "Index 450 Loss 0.006192030906677246\n",
      "Index 500 Loss 0.12789962768554688\n",
      "Index 550 Loss 3.139495849609375e-05\n",
      "Predicting..\n",
      "Accuracy: 99.66666666666667 Max Accuracy 99.83333333333333\n",
      "---Epoch 96---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0001667022705078125\n",
      "Index 100 Loss 2.3946762084960937e-05\n",
      "Index 150 Loss 3.467559814453125e-05\n",
      "Index 200 Loss 2.26593017578125e-05\n",
      "Index 250 Loss 0.014068870544433594\n",
      "Index 300 Loss 7.307052612304688e-05\n",
      "Index 350 Loss 0.00025789260864257814\n",
      "Index 400 Loss 2.788543701171875e-05\n",
      "Index 450 Loss 0.01209127426147461\n",
      "Index 500 Loss 0.088128080368042\n",
      "Index 550 Loss 1.6613006591796877e-05\n",
      "Predicting..\n",
      "Accuracy: 100.0 Max Accuracy 100.0\n",
      "---Epoch 97---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.0004621124267578125\n",
      "Index 100 Loss 8.740425109863282e-05\n",
      "Index 150 Loss 7.127761840820312e-05\n",
      "Index 200 Loss 3.2634735107421874e-05\n",
      "Index 250 Loss 0.000160369873046875\n",
      "Index 300 Loss 2.90679931640625e-05\n",
      "Index 350 Loss 9.899139404296876e-06\n",
      "Index 400 Loss 2.231597900390625e-05\n",
      "Index 450 Loss 0.009708833694458009\n",
      "Index 500 Loss 0.08960007667541504\n",
      "Index 550 Loss 2.6788711547851562e-05\n",
      "Predicting..\n",
      "Accuracy: 100.0 Max Accuracy 100.0\n",
      "---Epoch 98---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.00031980514526367185\n",
      "Index 100 Loss 1.9598007202148438e-05\n",
      "Index 150 Loss 4.728317260742187e-05\n",
      "Index 200 Loss 4.9285888671875e-05\n",
      "Index 250 Loss 6.7138671875e-06\n",
      "Index 300 Loss 2.4890899658203126e-05\n",
      "Index 350 Loss 2.51007080078125e-05\n",
      "Index 400 Loss 4.695892333984375e-05\n",
      "Index 450 Loss 0.011251811981201171\n",
      "Index 500 Loss 0.25842575073242186\n",
      "Index 550 Loss 2.0914077758789062e-05\n",
      "Predicting..\n",
      "Accuracy: 100.0 Max Accuracy 100.0\n",
      "---Epoch 99---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 8.275032043457031e-05\n",
      "Index 100 Loss 2.1457672119140625e-05\n",
      "Index 150 Loss 5.1975250244140625e-05\n",
      "Index 200 Loss 2.99835205078125e-05\n",
      "Index 250 Loss 5.5694580078125e-06\n",
      "Index 300 Loss 1.834869384765625e-05\n",
      "Index 350 Loss 2.2373199462890626e-05\n",
      "Index 400 Loss 7.160186767578125e-05\n",
      "Index 450 Loss 0.011322498321533203\n",
      "Index 500 Loss 0.03262776374816895\n",
      "Index 550 Loss 0.001211833953857422\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 100.0\n",
      "---Epoch 100---\n",
      "\n",
      "Training...\n",
      "Index 50 Loss 0.00017747879028320312\n",
      "Index 100 Loss 1.3647079467773438e-05\n",
      "Index 150 Loss 4.543304443359375e-05\n",
      "Index 200 Loss 2.4261474609375e-05\n",
      "Index 250 Loss 6.103515625e-06\n",
      "Index 300 Loss 0.00013513565063476561\n",
      "Index 350 Loss 7.20977783203125e-06\n",
      "Index 400 Loss 4.119873046875e-05\n",
      "Index 450 Loss 0.005219850540161133\n",
      "Index 500 Loss 0.05655032157897949\n",
      "Index 550 Loss 1.6307830810546876e-05\n",
      "Predicting..\n",
      "Accuracy: 99.83333333333333 Max Accuracy 100.0\n"
     ]
    }
   ],
   "source": [
    "train_and_test(100, \"out/Attention/WithGradientClippingAndLearningRateDecay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
